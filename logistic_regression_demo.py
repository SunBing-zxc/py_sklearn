# streamlit run logistic_regression_demo.py
# C:\Users\å­™å†°\Desktop\AIåŠ©æ•™25-12-07

# logistic_regression_demo.py
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
import time
from datetime import datetime
import io
from api_deepseek import client, ask_ai_assistant
import logistic_regression_step_by_step
from learning_report import generate_evaluation

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="é€»è¾‘å›å½’äº¤äº’å¼å­¦ä¹ å¹³å°", layout="wide")
st.title("ğŸ“š é€»è¾‘å›å½’äº¤äº’å¼å­¦ä¹ å¹³å°")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

def display_chat_interface(context=""):
    """æ˜¾ç¤ºèŠå¤©ç•Œé¢"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¬ AIåŠ©æ•™å·²å°±ç»ª")
    
    # é¢„è®¾é—®é¢˜å¿«æ·æŒ‰é’®
    st.sidebar.markdown("**å¿«æ·é—®é¢˜:**")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        btn1 = st.button("ä»€ä¹ˆæ˜¯sigmoidå‡½æ•°?")
        btn2 = st.button("é€»è¾‘å›å½’ä¸çº¿æ€§å›å½’çš„åŒºåˆ«")
    
    with col2:
        btn3 = st.button("åˆ†ç±»é˜ˆå€¼å¦‚ä½•é€‰æ‹©")
        btn4 = st.button("äº¤å‰ç†µæŸå¤±åŸç†")
    
    # å¤„ç†å¿«æ·é—®é¢˜
    question = ""
    if btn1:
        question = "ä»€ä¹ˆæ˜¯sigmoidå‡½æ•°?å®ƒåœ¨é€»è¾‘å›å½’ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆ?"
    elif btn2:
        question = "é€»è¾‘å›å½’ä¸çº¿æ€§å›å½’æœ‰ä»€ä¹ˆä¸»è¦åŒºåˆ«?åˆ†åˆ«é€‚ç”¨äºä»€ä¹ˆåœºæ™¯?"
    elif btn3:
        question = "é€»è¾‘å›å½’ä¸­åˆ†ç±»é˜ˆå€¼(é˜ˆå€¼)å¦‚ä½•é€‰æ‹©?ä¸åŒé˜ˆå€¼æœ‰ä»€ä¹ˆå½±å“?"
    elif btn4:
        question = "è¯·è§£é‡Šäº¤å‰ç†µæŸå¤±å‡½æ•°çš„åŸç†ï¼Œä¸ºä»€ä¹ˆé€»è¾‘å›å½’ä¸ç”¨å‡æ–¹è¯¯å·®?"
    
    # æé—®è¾“å…¥æ¡†
    user_input = st.sidebar.text_input("è¾“å…¥ä½ çš„é—®é¢˜:", key="question_input")
    if user_input:
        question = user_input
    
    # å¤„ç†æé—®
    if question:

        # è®°å½•AIäº¤äº’ï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
        if "ai_interactions" not in st.session_state.logistic_records:
            st.session_state.logistic_records["ai_interactions"] = []
        st.session_state.logistic_records["ai_interactions"].append({
            "question": question,
            "timestamp": datetime.now().timestamp()
        })

        # æ˜¾ç¤ºå½“å‰é—®é¢˜
        st.sidebar.markdown(f"**ä½ :** {question}")
        
        # è·å–å›ç­”
        with st.spinner("åŠ©æ•™æ€è€ƒä¸­..."):
            answer = ask_ai_assistant(question, context)
        
        # æ˜¾ç¤ºå½“å‰å›ç­”
        st.sidebar.markdown(f"**åŠ©æ•™:** {answer}")
        st.sidebar.markdown("---")

# Sigmoidå‡½æ•°å®šä¹‰ä¸å¯è§†åŒ–
def sigmoid(x):
    """Sigmoidæ¿€æ´»å‡½æ•°"""
    return 1 / (1 + np.exp(-x))

def plot_sigmoid_function(z_value):
    """ç»˜åˆ¶sigmoidå‡½æ•°å›¾åƒ"""
    x = np.linspace(-10, 10, 1000)
    y = sigmoid(x)
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(x, y, 'b-', linewidth=2)
    ax.grid(True, linestyle='-', alpha=0.3)  # å®çº¿ç½‘æ ¼ï¼Œé€‚å½“é™ä½é€æ˜åº¦
    ax.set_axisbelow(True)  # ç½‘æ ¼æ˜¾ç¤ºåœ¨æ›²çº¿ä¸‹æ–¹
    ax.axhline(y=0.5, color='r', linestyle='--', label='é˜ˆå€¼=0.5')
    ax.axvline(x=0, color='g', linestyle=':', label='x=0')
    # æ ‡æ³¨å½“å‰zå€¼ä¸å‡½æ•°çš„äº¤ç‚¹
    z_prob = sigmoid(z_value)  # è®¡ç®—å½“å‰zå€¼å¯¹åº”çš„æ¦‚ç‡
    ax.plot(z_value, z_prob, 'ro', markersize=10)  # ç»˜åˆ¶äº¤ç‚¹ï¼ˆé»‘è‰²åœ†ç‚¹ï¼‰
    
    # æ·»åŠ äº¤ç‚¹çš„åæ ‡æ ‡æ³¨
    ax.annotate(
        f'z={z_value:.1f}\næ¦‚ç‡={z_prob:.4f}',  # æ ‡æ³¨æ–‡æœ¬
        xy=(z_value, z_prob),  # æ ‡æ³¨ç‚¹åæ ‡
        xytext=(10, 10),  # æ–‡æœ¬ä½ç½®ï¼ˆç›¸å¯¹äºæ ‡æ³¨ç‚¹çš„åç§»ï¼‰
        textcoords='offset points',
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8)
    )
    
    # æ·»åŠ ç«–çº¿å’Œæ°´å¹³çº¿è¿æ¥åˆ°åæ ‡è½´
    ax.axvline(x=z_value, color='orange', linestyle='-', alpha=0.7)
    ax.axhline(y=z_prob, color='orange', linestyle='-', alpha=0.7)
    
    # è®¾ç½®åæ ‡è½´æ ‡ç­¾å’Œæ ‡é¢˜
    ax.set_xlabel('zå€¼')
    ax.set_ylabel('sigmoid(z) æ¦‚ç‡å€¼')
    ax.set_title('Sigmoidå‡½æ•°ä¸å½“å‰zå€¼ä½ç½®')
    ax.legend()
    return fig

# æ•°æ®ç”Ÿæˆå‡½æ•°ï¼ˆäºŒåˆ†ç±»æ•°æ®ï¼‰
@st.cache_data
def generate_classification_data(data_type, n_samples, separation):
    """ç”Ÿæˆåˆ†ç±»æ•°æ®"""
    np.random.seed(42)
    
    if data_type == "çº¿æ€§å¯åˆ†":
        # ç”Ÿæˆä¸¤ä¸ªçº¿æ€§å¯åˆ†çš„ç±»åˆ«
        n_class1 = n_samples // 2
        n_class2 = n_samples - n_class1  
        X1 = np.random.randn(n_class1, 2) * 0.8 + np.array([separation, separation])
        X2 = np.random.randn(n_class2, 2) * 0.8 - np.array([separation, separation])
        X = np.vstack((X1, X2))
        y = np.hstack((np.zeros(n_class1), np.ones(n_class2)))
    
    elif data_type == "çº¿æ€§ä¸å¯åˆ†":
        # ç”Ÿæˆçº¿æ€§ä¸å¯åˆ†çš„æ•°æ®
        X = np.random.randn(n_samples, 2) * 1.2
        # åŸºäºäºŒæ¬¡å‡½æ•°ç”Ÿæˆæ ‡ç­¾ï¼Œåˆ¶é€ éçº¿æ€§è¾¹ç•Œ
        y = (X[:, 0]**2 + X[:, 1]** 2 < 1.5).astype(int)
    
    elif data_type == "ä¸å¹³è¡¡æ•°æ®":
        # ç”Ÿæˆä¸å¹³è¡¡æ•°æ®
        n_minority = int(n_samples * 0.2)  # 20%ä¸ºå°‘æ•°ç±»
        n_majority = n_samples - n_minority  # 80%ä¸ºå¤šæ•°ç±»ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        X_majority = np.random.randn(n_majority, 2) * 0.8 - np.array([separation/2, separation/2])
        X_minority = np.random.randn(n_minority, 2) * 0.8 + np.array([separation/2, separation/2])
        X = np.vstack((X_majority, X_minority))
        y = np.hstack((np.zeros(n_majority), np.ones(n_minority)))
    
    # æ‰“ä¹±æ•°æ®é¡ºåº
    indices = np.random.permutation(n_samples)
    return X[indices], y[indices]

# ç»˜åˆ¶åˆ†ç±»æ•°æ®
def plot_classification_data(X, y, title):
    """ç»˜åˆ¶åˆ†ç±»æ•°æ®æ•£ç‚¹å›¾"""
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.scatter(X[y==0, 0], X[y==0, 1], alpha=0.7, label='ç±»åˆ« 0')
    ax.scatter(X[y==1, 0], X[y==1, 1], alpha=0.7, label='ç±»åˆ« 1')
    ax.set_xlabel('ç‰¹å¾ 1')
    ax.set_ylabel('ç‰¹å¾ 2')
    ax.set_title(title)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.7)
    return fig

# é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ¨¡æ‹Ÿ
def logistic_regression_gradient_descent(X, y, learning_rate, n_iterations):
    """æ‰‹åŠ¨å®ç°é€»è¾‘å›å½’çš„æ¢¯åº¦ä¸‹é™"""
    n_samples, n_features = X.shape
    weights = np.zeros(n_features)
    bias = 0
    costs = []
    
    for _ in range(n_iterations):
        # è®¡ç®—çº¿æ€§è¾“å‡º
        linear_model = np.dot(X, weights) + bias
        # åº”ç”¨sigmoidå‡½æ•°
        y_pred = sigmoid(linear_model)
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        cost = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))
        costs.append(cost)
        
        # è®¡ç®—æ¢¯åº¦
        dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))
        db = (1 / n_samples) * np.sum(y_pred - y)
        
        # æ›´æ–°å‚æ•°
        weights -= learning_rate * dw
        bias -= learning_rate * db
    
    return weights, bias, costs

# ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
def plot_decision_boundary(X, y, weights, bias, threshold=0.5, title="å†³ç­–è¾¹ç•Œ"):
    """ç»˜åˆ¶é€»è¾‘å›å½’çš„å†³ç­–è¾¹ç•Œ"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ç»˜åˆ¶æ•°æ®ç‚¹
    ax.scatter(X[y==0, 0], X[y==0, 1], alpha=0.7, label='ç±»åˆ« 0')
    ax.scatter(X[y==1, 0], X[y==1, 1], alpha=0.7, label='ç±»åˆ« 1')
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                         np.arange(y_min, y_max, 0.01))
    
    Z = sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], weights) + bias)
    Z = (Z >= threshold).astype(int)
    Z = Z.reshape(xx.shape)
    
    ax.contourf(xx, yy, Z, alpha=0.2, cmap=plt.cm.Paired)
    ax.set_xlabel('ç‰¹å¾ 1')
    ax.set_ylabel('ç‰¹å¾ 2')
    ax.set_title(title)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.7)
    return fig

# ç»˜åˆ¶sigmoidæ›²çº¿ä¸åˆ†ç±»é˜ˆå€¼
def plot_sigmoid_threshold():
    """å±•ç¤ºsigmoidå‡½æ•°ä¸ä¸åŒé˜ˆå€¼çš„å…³ç³»"""
    x = np.linspace(-10, 10, 1000)
    y = sigmoid(x)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(x, y, 'b-', linewidth=2, label='sigmoidå‡½æ•°')
    
    # ç»˜åˆ¶ä¸åŒé˜ˆå€¼çº¿
    thresholds = [0.3, 0.5, 0.7]
    colors = ['g', 'r', 'purple']
    for threshold, color in zip(thresholds, colors):
        # æ‰¾åˆ°å¯¹åº”é˜ˆå€¼çš„xå€¼
        x_threshold = np.log(threshold / (1 - threshold))
        ax.axhline(y=threshold, color=color, linestyle='--', 
                  label=f'é˜ˆå€¼={threshold} (x={x_threshold:.2f})')
        ax.axvline(x=x_threshold, color=color, linestyle=':')
    
    ax.set_xlabel('çº¿æ€§è¾“å‡º (z = wx + b)')
    ax.set_ylabel('æ¦‚ç‡ p(y=1)')
    ax.set_title('Sigmoidå‡½æ•°ä¸ä¸åŒåˆ†ç±»é˜ˆå€¼')
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.legend()
    return fig

# æ•°æ®ç”Ÿæˆä¸æ¢ç´¢æ¨¡å—
def data_generation_section():
    st.header("ğŸ“Š åˆ†ç±»æ•°æ®ç”Ÿæˆä¸æ¢ç´¢")
    
    col1, col2 = st.columns(2)
    
    with col1:
        data_type = st.selectbox("é€‰æ‹©æ•°æ®ç±»å‹", 
                               ["çº¿æ€§å¯åˆ†", "çº¿æ€§ä¸å¯åˆ†", "ä¸å¹³è¡¡æ•°æ®"])
        n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 500, 200)
        separation = st.slider("ç±»åˆ«åˆ†ç¦»ç¨‹åº¦", 0.5, 5.0, 2.0, 0.5)
        
        X, y = generate_classification_data(data_type, n_samples, separation)
        
        st.write(f"æ•°æ®ç»Ÿè®¡:")
        st.write(f"- ç±»åˆ«0æ•°é‡: {np.sum(y == 0)}")
        st.write(f"- ç±»åˆ«1æ•°é‡: {np.sum(y == 1)}")
        st.write(f"- ç‰¹å¾1å‡å€¼: {np.mean(X[:, 0]):.2f}, æ ‡å‡†å·®: {np.std(X[:, 0]):.2f}")
        st.write(f"- ç‰¹å¾2å‡å€¼: {np.mean(X[:, 1]):.2f}, æ ‡å‡†å·®: {np.std(X[:, 1]):.2f}")

        # è®°å½•æ“ä½œï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
        st.session_state.logistic_records["data_generation"].append({
            "data_type": data_type,
            "n_samples": n_samples,
            "separation": separation,
            "timestamp": datetime.now().timestamp()
        })
    
    with col2:
        fig = plot_classification_data(X, y, f'{data_type}æ•°æ®åˆ†å¸ƒ')
        st.pyplot(fig)
    
    st.info("""
    **åˆ†ç±»æ•°æ®æ¢ç´¢è¦ç‚¹:**
    - çº¿æ€§å¯åˆ†æ•°æ®: å¯ä»¥ç”¨ä¸€æ¡ç›´çº¿å®Œç¾åˆ†éš”ä¸¤ä¸ªç±»åˆ«
    - çº¿æ€§ä¸å¯åˆ†æ•°æ®: æ— æ³•ç”¨ä¸€æ¡ç›´çº¿å®Œç¾åˆ†éš”
    - ä¸å¹³è¡¡æ•°æ®: ä¸€ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡è¿œå¤šäºå¦ä¸€ä¸ªç±»åˆ«
    - ç±»åˆ«åˆ†ç¦»ç¨‹åº¦å½±å“åˆ†ç±»éš¾åº¦ï¼Œåˆ†ç¦»è¶Šå¥½è¶Šå®¹æ˜“åˆ†ç±»
    """)
    
    # å­˜å‚¨æ•°æ®ä¾›åç»­æ¨¡å—ä½¿ç”¨
    #st.session_state.X = X
    #st.session_state.y = y
    
    return f"æ•°æ®ç”Ÿæˆæ¨¡å—: åˆ›å»ºäº†{data_type}æ•°æ®ï¼Œæ ·æœ¬æ•°={n_samples}ï¼Œåˆ†ç¦»ç¨‹åº¦={separation}"

# Sigmoidå‡½æ•°äº¤äº’æ¨¡å—
def sigmoid_interactive_section():
    st.header("ğŸ”„ Sigmoidå‡½æ•°äº¤äº’æ¼”ç¤º")
    st.markdown("""
        **Sigmoidå‡½æ•°å…¬å¼ï¼š**
        $$\sigma(z) = \\frac{1}{1 + e^{-z}}$$  ï¼Œå…¶ä¸­ $z = w_1x_1 + w_2x_2 + ... + w_nx_n + b$ æ˜¯çº¿æ€§ç»„åˆ
        
        **Sigmoidå‡½æ•°çš„ç‰¹ç‚¹ï¼šè¾“å‡ºå€¼èŒƒå›´åœ¨(0, 1)ä¹‹é—´ï¼Œå¯è§£é‡Šä¸ºæ¦‚ç‡ï¼›å‡½æ•°å…‰æ»‘ä¸”å¯å¯¼ï¼Œé€‚åˆæ¢¯åº¦ä¸‹é™ä¼˜åŒ–**
        - å½“zâ†’+âˆæ—¶ï¼ŒÏƒ(z)â†’1
        - å½“zâ†’-âˆæ—¶ï¼ŒÏƒ(z)â†’0
        - å½“z=0æ—¶ï¼ŒÏƒ(z)=0.5
        """)    
    col1, col2 = st.columns([2,3])
    
    with col1:        
        z_value = st.slider("é€‰æ‹©zå€¼", -10.0, 10.0, 0.0, 0.1)
        sigmoid_value = sigmoid(z_value)
        st.metric("sigmoid(z)å€¼", f"{sigmoid_value:.4f}")
        
        if sigmoid_value >= 0.5:
            st.success(f"å½“z={z_value:.1f}æ—¶ï¼Œé¢„æµ‹ä¸ºç±»åˆ«1ï¼ˆæ¦‚ç‡={sigmoid_value:.4f}ï¼‰")
        else:
            st.info(f"å½“z={z_value:.1f}æ—¶ï¼Œé¢„æµ‹ä¸ºç±»åˆ«0ï¼ˆæ¦‚ç‡={1-sigmoid_value:.4f}ï¼‰")

        # è®°å½•æ“ä½œï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
        st.session_state.logistic_records["sig_function"].append({
            "z_value": z_value,
            "timestamp": datetime.now().timestamp()
        })
    
    with col2:
        # ç»˜åˆ¶sigmoidå‡½æ•°
        fig1 = plot_sigmoid_function(z_value)
        st.pyplot(fig1)
 
    return f"Sigmoidå‡½æ•°æ¨¡å—: æ¢ç´¢äº†z={z_value:.1f}æ—¶çš„å‡½æ•°å€¼"

# æ‰‹åŠ¨è°ƒæ•´å‚æ•°æ¨¡å—ï¼ˆå­¦ç”Ÿè€ƒè¯•åœºæ™¯ä¼˜åŒ–ç‰ˆï¼‰
def manual_tuning_section():
    st.header("ğŸ›ï¸ é€»è¾‘å›å½’å‚æ•°æ‰‹åŠ¨è°ƒæ•´ï¼ˆå­¦ç”Ÿè€ƒè¯•åœºæ™¯ï¼‰")
    st.info("åŸºäºã€Œè€ƒè¯•æˆç»©ã€å’Œã€Œç¼ºå‹¤æ¬¡æ•°ã€é¢„æµ‹æ˜¯å¦é€šè¿‡æœŸæœ«è€ƒè¯•")
    
    # ç”Ÿæˆå­¦ç”Ÿæ•°æ®ï¼ˆä¸¤ä¸ªç‰¹å¾ï¼šæˆç»©[0-100]ã€ç¼ºå‹¤æ¬¡æ•°[0-15]ï¼‰
    np.random.seed(42)
    n_samples = 200
    
    # ç”Ÿæˆé€šè¿‡å’Œæœªé€šè¿‡çš„å­¦ç”Ÿæ•°æ®
    pass_scores = np.random.normal(75, 10, n_samples//2)
    pass_absences = np.random.normal(2, 1, n_samples//2)
    pass_absences = np.clip(pass_absences, 0, 15)
    
    fail_scores = np.random.normal(40, 15, n_samples//2)
    fail_absences = np.random.normal(10, 3, n_samples//2)
    fail_absences = np.clip(fail_absences, 0, 15)
    
    # åˆå¹¶æ•°æ®
    X = np.vstack([
        np.column_stack((pass_scores, pass_absences)),
        np.column_stack((fail_scores, fail_absences))
    ])
    y = np.hstack([np.ones(n_samples//2), np.zeros(n_samples//2)])
    
    # æ‰“ä¹±é¡ºåº
    indices = np.random.permutation(n_samples)
    X, y = X[indices], y[indices]
    
    # ç‰¹å¾åˆ†ç¦»
    scores = X[:, 0]
    absences = X[:, 1]
    st.subheader("è°ƒæ•´æ¨¡å‹å‚æ•°")    
    col1, col2 = st.columns([2,3])    
    with col1:        
        # æˆç»©æƒé‡ï¼ˆæ­£å‘ç‰¹å¾ï¼Œæ‰©å¤§æ­£å‘èŒƒå›´ï¼‰
        score_weight = st.slider(
            "æˆç»©æƒé‡ (w1)", 
            -1.0,  # æœ€å°è´Ÿå‘å€¼ï¼ˆç¼©å°è´Ÿå‘èŒƒå›´ï¼‰
            1.0,   # æœ€å¤§æ­£å‘å€¼ï¼ˆæ‰©å¤§æ­£å‘èŒƒå›´ï¼‰
            0.4,   # é»˜è®¤å€¼
            0.05   # æ­¥é•¿
        )
        # æˆç»©æƒé‡è§£é‡Šï¼ˆæ»‘å—ä¸‹æ–¹å³æ—¶è¯´æ˜ï¼‰
        st.write(f"æˆç»©åº”ä¸ºæ­£å‘æƒé‡ï¼Œå³æˆç»©è¶Šé«˜ï¼Œé€šè¿‡æ¦‚ç‡è¶Šå¤§")
        
        # ç¼ºå‹¤æƒé‡ï¼ˆè´Ÿå‘ç‰¹å¾ï¼Œæ‰©å¤§è´Ÿå‘èŒƒå›´ï¼‰
        absence_weight = st.slider(
            "ç¼ºå‹¤æƒé‡ (w2)", 
            -5.0,  # æœ€å¤§è´Ÿå‘å€¼ï¼ˆæ‰©å¤§è´Ÿå‘èŒƒå›´ï¼‰
            1.0,   # æœ€å°æ­£å‘å€¼ï¼ˆç¼©å°æ­£å‘èŒƒå›´ï¼‰
            -3.0,  # é»˜è®¤å€¼
            0.05   # æ­¥é•¿
        )
        # ç¼ºå‹¤æƒé‡è§£é‡Šï¼ˆæ»‘å—ä¸‹æ–¹å³æ—¶è¯´æ˜ï¼‰
        st.write(f"ç¼ºå‹¤åº”ä¸ºè´Ÿå‘æƒé‡ï¼Œå³ç¼ºå‹¤è¶Šå¤šï¼Œé€šè¿‡æ¦‚ç‡è¶Šä½")
        
        # åç½®é¡¹
        bias = st.slider("åç½® (b)", -10.0, 10.0, -5.0, 0.5)
        # åç½®è§£é‡Šï¼ˆæ»‘å—ä¸‹æ–¹å³æ—¶è¯´æ˜ï¼‰
        st.write(f"è®¾ç½®åç½®å¯ä»¥æ•´ä½“æé«˜æˆ–é™ä½é€šè¿‡æ¦‚ç‡åŸºå‡†çº¿")
        
        # åˆ†ç±»é˜ˆå€¼
        threshold = st.slider("é€šè¿‡æ¦‚ç‡é˜ˆå€¼", 0.1, 0.9, 0.5, 0.05)
        # é˜ˆå€¼è§£é‡Šï¼ˆæ»‘å—ä¸‹æ–¹å³æ—¶è¯´æ˜ï¼‰
        if threshold > 0.5:
            st.write(f"å½“å‰é˜ˆå€¼ï¼š{threshold:.2f} â†’ åˆ¤å®šé€šè¿‡çš„æ ‡å‡†æ›´ä¸¥æ ¼ï¼ˆå‡å°‘è¯¯åˆ¤é€šè¿‡ï¼‰")
        elif threshold < 0.5:
            st.write(f"å½“å‰é˜ˆå€¼ï¼š{threshold:.2f} â†’ åˆ¤å®šé€šè¿‡çš„æ ‡å‡†æ›´å®½æ¾ï¼ˆå‡å°‘è¯¯åˆ¤ä¸é€šè¿‡ï¼‰")
        else:
            st.write(f"å½“å‰é˜ˆå€¼ï¼š0.5 â†’ ä¸­ç«‹åˆ¤å®šæ ‡å‡†")
            
        # è®¡ç®—é¢„æµ‹ç»“æœ
        z = score_weight * scores + absence_weight * absences + bias
        y_prob = sigmoid(z)
        y_pred = (y_prob >= threshold).astype(int)
        
        # æ¨¡å‹è¯„ä¼°
        accuracy = accuracy_score(y, y_pred)
        st.metric("é¢„æµ‹å‡†ç¡®ç‡", f"{accuracy:.4f}")
        
    with col2:
        # ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))
        
        # æˆç»©å¯¹é€šè¿‡æ¦‚ç‡çš„å½±å“
        fixed_absence = np.mean(absences)
        score_range = np.linspace(0, 100, 200)
        z_scores = score_weight * score_range + absence_weight * fixed_absence + bias
        prob_scores = sigmoid(z_scores)
        
        ax1.plot(score_range, prob_scores, 'b-', label=f'å›ºå®šç¼ºå‹¤={fixed_absence:.1f}æ¬¡')
        ax1.axhline(threshold, color='r', linestyle='--', label=f'é€šè¿‡é˜ˆå€¼={threshold}')
        ax1.scatter(scores[y==1], np.ones_like(scores[y==1]), c='green', alpha=0.5, label='å®é™…é€šè¿‡')
        ax1.scatter(scores[y==0], np.zeros_like(scores[y==0]), c='red', alpha=0.5, label='å®é™…æŒ‚ç§‘')
        ax1.set_xlabel('æ¨¡æ‹Ÿè€ƒè¯•æˆç»©')
        ax1.set_ylabel('é€šè¿‡æ¦‚ç‡')
        ax1.set_title('æˆç»©å¯¹é€šè¿‡æ¦‚ç‡çš„å½±å“ï¼ˆå›ºå®šç¼ºå‹¤æ¬¡æ•°ï¼‰')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åŒç‰¹å¾å†³ç­–è¾¹ç•Œ
        x_min, x_max = scores.min() - 10, scores.max() + 10  # å¢å¤§èŒƒå›´
        y_min, y_max = absences.min() - 3, absences.max() + 3  # å¢å¤§èŒƒå›´
        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.5),
                             np.arange(y_min, y_max, 0.2))
        
        Z = sigmoid(score_weight * xx + absence_weight * yy + bias)
        Z_class = (Z >= threshold).astype(int)
        
        ax2.contourf(xx, yy, Z_class, alpha=0.3, cmap=plt.cm.coolwarm)
        ax2.scatter(scores[y==1], absences[y==1], c='green', label='å®é™…é€šè¿‡', alpha=0.7)
        ax2.scatter(scores[y==0], absences[y==0], c='red', label='å®é™…æŒ‚ç§‘', alpha=0.7)
        
        if score_weight != 0:
            absence_line = np.linspace(y_min, y_max, 100)
            score_line = (np.log(threshold/(1-threshold)) - absence_weight * absence_line - bias) / score_weight
            valid = (score_line >= x_min) & (score_line <= x_max)
            ax2.plot(score_line[valid], absence_line[valid], 'k-', linewidth=2, label=f'å†³ç­–è¾¹ç•Œï¼ˆæ¦‚ç‡={threshold}ï¼‰')
        
        ax2.set_xlabel('æ¨¡æ‹Ÿè€ƒè¯•æˆç»©')
        ax2.set_ylabel('ç¼ºå‹¤æ¬¡æ•°')
        ax2.set_title('åŒç‰¹å¾å†³ç­–è¾¹ç•Œï¼ˆç»¿è‰²åŒºåŸŸ=é¢„æµ‹é€šè¿‡ï¼‰')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)

    col1, col2 = st.columns([2,3])    
    with col1:        
        # æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
        st.subheader("æ··æ·†çŸ©é˜µ")
        cm = confusion_matrix(y, y_pred)
        cm_df = pd.DataFrame(cm, index=['å®é™…æŒ‚ç§‘', 'å®é™…é€šè¿‡'], columns=['é¢„æµ‹æŒ‚ç§‘', 'é¢„æµ‹é€šè¿‡'])
        st.dataframe(cm_df)
    with col2:
        st.subheader('æ··æ·†çŸ©é˜µç†è§£')
        st.write("""
            - **è¯¯åˆ¤ï¼ˆå³ä¸Šè§’ï¼‰**ï¼šå®é™…æŒ‚ç§‘å´è¢«é¢„æµ‹ä¸ºé€šè¿‡ï¼ˆå‡é˜³æ€§ï¼‰
            - **æ¼åˆ¤ï¼ˆå·¦ä¸‹è§’ï¼‰**ï¼šå®é™…é€šè¿‡å´è¢«é¢„æµ‹ä¸ºæŒ‚ç§‘ï¼ˆå‡é˜´æ€§ï¼‰
            - å·¦ä¸Šè§’ï¼šå®é™…æŒ‚ç§‘ä¸”é¢„æµ‹æŒ‚ç§‘ï¼ˆçœŸé˜´æ€§ï¼‰
            - å³ä¸‹è§’ï¼šå®é™…é€šè¿‡ä¸”é¢„æµ‹é€šè¿‡ï¼ˆçœŸé˜³æ€§ï¼‰
            """)      
        
    st.info("""
    **å‚æ•°è°ƒæ•´æŒ‡å—:**
    - å°è¯•å°†æˆç»©æƒé‡ä¿æŒä¸ºæ­£å€¼ï¼Œç¼ºå‹¤æƒé‡ä¿æŒä¸ºè´Ÿå€¼ï¼ˆç¬¦åˆå®é™…é€»è¾‘ï¼‰
    - è°ƒæ•´æƒé‡å¤§å°å¯ä»¥æ”¹å˜å¯¹åº”ç‰¹å¾å¯¹ç»“æœçš„å½±å“å¼ºåº¦
    - åç½®é¡¹å¯ä»¥æ•´ä½“æŠ¬é«˜æˆ–é™ä½é€šè¿‡æ¦‚ç‡çš„åŸºå‡†çº¿
    """)


    # è®°å½•æ“ä½œ
    st.session_state.logistic_records["para_tuning"].append({
        "score_weight": score_weight,
        "absence_weight": absence_weight,
        "bias": bias,
        "threshold": threshold,
        "accuracy": accuracy,
        "timestamp": datetime.now().timestamp()
    })     
    return f"æ‰‹åŠ¨è°ƒæ•´æ¨¡å—: æˆç»©æƒé‡={score_weight:.1f}, ç¼ºå‹¤æƒé‡={absence_weight:.1f}, åç½®={bias:.1f}, é˜ˆå€¼={threshold:.2f}, å‡†ç¡®ç‡={accuracy:.4f}"


# æ¢¯åº¦ä¸‹é™å¯è§†åŒ–æ¨¡å—
def gradient_descent_section():
    st.header("ğŸ“‰ é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™å¯è§†åŒ–")
    X,y = generate_classification_data("çº¿æ€§å¯åˆ†", 300, 0.6) 

    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    col1, col2 = st.columns([2,3])
    
    with col1:
        learning_rate = st.slider("å­¦ä¹ ç‡", 0.1, 50.0, 1.0)
        n_iterations = st.slider("è¿­ä»£æ¬¡æ•°", 0, 15, 8)
        st.markdown("""
        **å­¦ä¹ ç‡é€‰æ‹©å»ºè®®:**
        - å¤ªå°: æ”¶æ•›é€Ÿåº¦æ…¢ï¼Œéœ€è¦æ›´å¤šè¿­ä»£
        - å¤ªå¤§: å¯èƒ½å¯¼è‡´ä¸æ”¶æ•›ï¼ŒæŸå¤±æ³¢åŠ¨ç”šè‡³å¢å¤§
        """)
    with col2:
        st.markdown("""
        **é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™åŸç†:**
        
        1. **åˆå§‹åŒ–**æƒé‡å’Œåç½®ä¸º0
        2. è®¡ç®—**çº¿æ€§è¾“å‡º** $z = wx + b$
        3. åº”ç”¨**sigmoidå‡½æ•°**å¾—åˆ°æ¦‚ç‡é¢„æµ‹ $\\hat{y} = \\sigma(z)$
        4. è®¡ç®—**äº¤å‰ç†µæŸå¤±**:
           $$L = -\\frac{1}{n}\\sum(y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}))$$
        5. è®¡ç®—æŸå¤±å¯¹æƒé‡å’Œåç½®çš„**æ¢¯åº¦**
        6. æ²¿æ¢¯åº¦åæ–¹å‘**æ›´æ–°å‚æ•°**:
           $$w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$
           $$b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$
        7. é‡å¤æ­¥éª¤2-6ç›´åˆ°æ”¶æ•›
        """)        
    if st.button("å¼€å§‹æ¢¯åº¦ä¸‹é™æ¼”ç¤º"):
        # è¿è¡Œæ¢¯åº¦ä¸‹é™
        weights, bias, costs = logistic_regression_gradient_descent(
            X_scaled, y, learning_rate, n_iterations
        )
            
        # æ˜¾ç¤ºè¿‡ç¨‹
        placeholder = st.empty()
        # åªæ˜¾ç¤ºéƒ¨åˆ†è¿­ä»£æ­¥éª¤ï¼Œé¿å…å¤ªæ…¢
        step = max(1, n_iterations // 20)
        for i in range(0, n_iterations + 1, step):
            with placeholder.container():
                # è®¡ç®—å½“å‰è¿­ä»£çš„å‚æ•°ï¼ˆå¦‚æœè¶…å‡ºèŒƒå›´åˆ™ç”¨æœ€åä¸€ç»„ï¼‰
                current_weights = weights if i == n_iterations else \
                                    logistic_regression_gradient_descent(
                                        X_scaled, y, learning_rate, i)[0]
                current_bias = bias if i == n_iterations else \
                                logistic_regression_gradient_descent(
                                    X_scaled, y, learning_rate, i)[1]
                    
                # ç»˜åˆ¶å†³ç­–è¾¹ç•Œå’ŒæŸå¤±æ›²çº¿
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                    
                # å†³ç­–è¾¹ç•Œ
                x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
                y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
                xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                                        np.arange(y_min, y_max, 0.01))
                    
                # æ ‡å‡†åŒ–ç½‘æ ¼ç‚¹
                grid_points = np.c_[xx.ravel(), yy.ravel()]
                grid_points_scaled = scaler.transform(grid_points)
                    
                Z = sigmoid(np.dot(grid_points_scaled, current_weights) + current_bias)
                Z = (Z >= 0.5).astype(int)
                Z = Z.reshape(xx.shape)
                    
                ax1.contourf(xx, yy, Z, alpha=0.2, cmap=plt.cm.Paired)
                ax1.scatter(X[y==0, 0], X[y==0, 1], alpha=0.7, label='ç±»åˆ« 0')
                ax1.scatter(X[y==1, 0], X[y==1, 1], alpha=0.7, label='ç±»åˆ« 1')
                ax1.set_title(f'è¿­ä»£ {i}/{n_iterations}')
                ax1.legend()
                    
                # æŸå¤±æ›²çº¿
                ax2.plot(range(min(i+1, len(costs))), costs[:min(i+1, len(costs))])
                ax2.set_xlabel('è¿­ä»£æ¬¡æ•°')
                ax2.set_ylabel('äº¤å‰ç†µæŸå¤±')
                ax2.set_title(f'æŸå¤±: {costs[min(i, len(costs)-1)]:.4f}')
                ax2.grid(True)
                    
                plt.tight_layout()
                st.pyplot(fig)
                time.sleep(0.05)
            
        st.success(f"æ¢¯åº¦ä¸‹é™å®Œæˆ! æœ€ç»ˆæŸå¤±: {costs[-1]:.4f}")
        # è®°å½•æ“ä½œï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
        st.session_state.logistic_records["gradient_descent"].append({
            "learning_rate": learning_rate,
            "n_iterations": n_iterations,
            "final_cost": costs[-1],
            "timestamp": datetime.now().timestamp()
        })
    
   
    
    return f"æ¢¯åº¦ä¸‹é™æ¨¡å—: å­¦ä¹ ç‡={learning_rate}, è¿­ä»£æ¬¡æ•°={n_iterations}"

# æ¨¡å‹è¯„ä¼°æ¨¡å—ï¼ˆä¸“æ³¨äºæ··æ·†çŸ©é˜µå’Œè¯„ä¼°æŒ‡æ ‡è§£é‡Šï¼‰
def model_evaluation_section():
    st.header("ğŸ“Š æ¨¡å‹è¯„ä¼°ä¸æŒ‡æ ‡è§£é‡Š")
    
    # é€‰æ‹©è§£é‡Šåœºæ™¯
    st.subheader("é€‰æ‹©ä¸€ä¸ªåœºæ™¯å¸®åŠ©ç†è§£æ··æ·†çŸ©é˜µï¼š")
    scenario = st.selectbox(
        "åœºæ™¯ç¤ºä¾‹ï¼š",
        ["ç–¾ç—…æ£€æµ‹", "åƒåœ¾é‚®ä»¶è¿‡æ»¤"]
    )
    
    # æ ¹æ®åœºæ™¯ç”Ÿæˆæ¨¡æ‹Ÿçš„æ··æ·†çŸ©é˜µæ•°æ®åŠæœ¯è¯­
    if scenario == "ç–¾ç—…æ£€æµ‹":
        # ç–¾ç—…æ£€æµ‹åœºæ™¯çš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆTN, FP, FN, TPï¼‰
        tn, fp, fn, tp = 85, 5, 3, 7
        classes = ['å¥åº·', 'æ‚£ç—…']
        terms = {
            "tn": "å¥åº·äººè¢«æ­£ç¡®åˆ¤æ–­ä¸ºå¥åº·ï¼ˆTNï¼‰",
            "fp": "å¥åº·äººè¢«é”™è¯¯åˆ¤æ–­ä¸ºæ‚£ç—…ï¼ˆFPï¼‰",
            "fn": "æ‚£ç—…è€…è¢«é”™è¯¯åˆ¤æ–­ä¸ºå¥åº·ï¼ˆFNï¼‰",
            "tp": "æ‚£ç—…è€…è¢«æ­£ç¡®åˆ¤æ–­ä¸ºæ‚£ç—…ï¼ˆTPï¼‰",
            "title": "ç–¾ç—…æ£€æµ‹åœºæ™¯ä¸‹çš„æ··æ·†çŸ©é˜µ"
        }
        # é”™è¯¯åæœ
        fp_consequence = "å¥åº·äººæ¥å—ä¸å¿…è¦çš„æ²»ç–—ï¼Œé€ æˆç»æµæŸå¤±å’Œå¿ƒç†è´Ÿæ‹…"
        fn_consequence = "çœŸæ­£çš„æ‚£è€…é”™è¿‡æ²»ç–—æ—¶æœºï¼Œå¯¼è‡´ç—…æƒ…æ¶åŒ–ç”šè‡³å±åŠç”Ÿå‘½"
        # æŒ‡æ ‡ç¤ºä¾‹
        precision_example = "é¢„æµ‹ä¸ºæ‚£ç—…çš„äººé‡Œï¼ŒçœŸæ­£æ‚£ç—…çš„æ¯”ä¾‹"
        recall_example = "æ‰€æœ‰çœŸæ­£æ‚£ç—…çš„äººé‡Œï¼Œè¢«æ£€æµ‹å‡ºæ¥çš„æ¯”ä¾‹"
    else:  # åƒåœ¾é‚®ä»¶è¿‡æ»¤åœºæ™¯
        # åƒåœ¾é‚®ä»¶è¿‡æ»¤åœºæ™¯çš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆTN, FP, FN, TPï¼‰
        tn, fp, fn, tp = 90, 2, 5, 3
        classes = ['æ­£å¸¸é‚®ä»¶', 'åƒåœ¾é‚®ä»¶']
        terms = {
            "tn": "æ­£å¸¸é‚®ä»¶è¢«æ­£ç¡®åˆ¤æ–­ä¸ºæ­£å¸¸ï¼ˆTNï¼‰",
            "fp": "æ­£å¸¸é‚®ä»¶è¢«é”™è¯¯åˆ¤æ–­ä¸ºåƒåœ¾é‚®ä»¶ï¼ˆFPï¼‰",
            "fn": "åƒåœ¾é‚®ä»¶è¢«é”™è¯¯åˆ¤æ–­ä¸ºæ­£å¸¸é‚®ä»¶ï¼ˆFNï¼‰",
            "tp": "åƒåœ¾é‚®ä»¶è¢«æ­£ç¡®åˆ¤æ–­ä¸ºåƒåœ¾é‚®ä»¶ï¼ˆTPï¼‰",
            "title": "åƒåœ¾é‚®ä»¶è¿‡æ»¤åœºæ™¯ä¸‹çš„æ··æ·†çŸ©é˜µ"
        }
        # é”™è¯¯åæœ
        fp_consequence = "é‡è¦é‚®ä»¶è¢«è¯¯åˆ ï¼Œå¯èƒ½é”™è¿‡å…³é”®ä¿¡æ¯ï¼ˆå¦‚å·¥ä½œé‚®ä»¶ã€é€šçŸ¥ï¼‰"
        fn_consequence = "åƒåœ¾é‚®ä»¶å……æ–¥é‚®ç®±ï¼Œå¹²æ‰°ç”¨æˆ·æ­£å¸¸ä½¿ç”¨ï¼Œç”šè‡³åŒ…å«è¯ˆéª—ä¿¡æ¯"
        # æŒ‡æ ‡ç¤ºä¾‹
        precision_example = "è¢«æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶çš„é‚®ä»¶ä¸­ï¼ŒçœŸæ­£æ˜¯åƒåœ¾é‚®ä»¶çš„æ¯”ä¾‹"
        recall_example = "æ‰€æœ‰å®é™…æ˜¯åƒåœ¾é‚®ä»¶çš„é‚®ä»¶ä¸­ï¼Œè¢«æ­£ç¡®è¯†åˆ«çš„æ¯”ä¾‹"
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    total = tn + fp + fn + tp
    accuracy = (tp + tn) / total if total > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    # æ˜¾ç¤ºæ··æ·†çŸ©é˜µè¡¨æ ¼ï¼ˆå¸¦TP/TN/FP/FNæ ‡æ³¨ï¼‰
    st.subheader(terms["title"])
    cm_data = {
        f"é¢„æµ‹ä¸º{classes[0]}": [f"TN: {tn}", f"FN: {fn}"],
        f"é¢„æµ‹ä¸º{classes[1]}": [f"FP: {fp}", f"TP: {tp}"]
    }
    cm_df = pd.DataFrame(cm_data, index=[f"å®é™…ä¸º{classes[0]}", f"å®é™…ä¸º{classes[1]}"])
    st.dataframe(cm_df, use_container_width=True)
    
    # æ˜¾ç¤ºæ•°å€¼è§£é‡Šï¼ˆå¼ºåŒ–æœ¯è¯­å¯¹åº”å…³ç³»ï¼‰
    st.markdown(f"""
    **æ··æ·†çŸ©é˜µæ ¸å¿ƒæœ¯è¯­è§£é‡Šï¼š**
    - **TNï¼ˆçœŸé˜´æ€§ï¼‰**ï¼š{terms['tn'].split('ï¼ˆ')[0]}ï¼Œå…±{tn}ä¾‹
    - **FPï¼ˆå‡é˜³æ€§ï¼‰**ï¼š{terms['fp'].split('ï¼ˆ')[0]}ï¼Œå…±{fp}ä¾‹
    - **FNï¼ˆå‡é˜´æ€§ï¼‰**ï¼š{terms['fn'].split('ï¼ˆ')[0]}ï¼Œå…±{fn}ä¾‹
    - **TPï¼ˆçœŸé˜³æ€§ï¼‰**ï¼š{terms['tp'].split('ï¼ˆ')[0]}ï¼Œå…±{tp}ä¾‹
    """)
    
    # æ··æ·†çŸ©é˜µåœºæ™¯åŒ–è§£è¯»
    st.subheader("æ··æ·†çŸ©é˜µå®æˆ˜è§£è¯»")
    st.markdown(f"""
    åœ¨**{scenario}** åœºæ™¯ä¸­ï¼Œå››ä¸ªæŒ‡æ ‡çš„ä¸šåŠ¡å«ä¹‰ï¼š
    
    | çœŸå®æƒ…å†µ \\ é¢„æµ‹ç»“æœ | é¢„æµ‹ä¸º{classes[0]} | é¢„æµ‹ä¸º{classes[1]} |
    |-------------------|----------------|----------------|
    | **å®é™…ä¸º{classes[0]}** | TNï¼ˆæ­£ç¡®ï¼‰ | FPï¼ˆé”™è¯¯ï¼‰ |
    | **å®é™…ä¸º{classes[1]}** | FNï¼ˆé”™è¯¯ï¼‰ | TPï¼ˆæ­£ç¡®ï¼‰ |
    
    **å…³é”®é”™è¯¯å½±å“åˆ†æï¼š**
    - FPï¼ˆ{terms['fp'].split('ï¼ˆ')[1][:-1]}ï¼‰ï¼š{fp_consequence}
    - FNï¼ˆ{terms['fn'].split('ï¼ˆ')[1][:-1]}ï¼‰ï¼š{fn_consequence}
    
    **åœºæ™¯åŒ–æŒ‡æ ‡é€‰æ‹©ç­–ç•¥ï¼š**
    - å½“FNä»£ä»·æ›´é«˜ï¼ˆå¦‚ç–¾ç—…æ£€æµ‹ï¼‰ï¼šä¼˜å…ˆä¿è¯**å¬å›ç‡**ï¼ˆå‡å°‘æ¼è¯Šï¼‰
    - å½“FPä»£ä»·æ›´é«˜ï¼ˆå¦‚åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼‰ï¼šä¼˜å…ˆä¿è¯**ç²¾ç¡®ç‡**ï¼ˆå‡å°‘è¯¯åˆ ï¼‰
    """)
        
    # è¯„ä¼°æŒ‡æ ‡è®¡ç®—ä¸è§£é‡Š
    st.subheader("æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—ä¸ä¸šåŠ¡æ„ä¹‰")
    st.markdown(f"""
    - **å‡†ç¡®ç‡ (Accuracy)**ï¼š{accuracy:.4f}  
      â†’ è®¡ç®—å…¬å¼ï¼š(TP + TN) / æ€»æ ·æœ¬æ•° = ({tp} + {tn}) / {total}  
      â†’ å«ä¹‰ï¼šæ‰€æœ‰åˆ¤æ–­ä¸­æ­£ç¡®çš„æ¯”ä¾‹
    
    - **ç²¾ç¡®ç‡ (Precision)**ï¼š{precision:.4f}  
      â†’ è®¡ç®—å…¬å¼ï¼šTP / (TP + FP) = {tp} / ({tp} + {fp})  
      â†’ å«ä¹‰ï¼š{precision_example}
    
    - **å¬å›ç‡ (Recall)**ï¼š{recall:.4f}  
      â†’ è®¡ç®—å…¬å¼ï¼šTP / (TP + FN) = {tp} / ({tp} + {fn})  
      â†’ å«ä¹‰ï¼š{recall_example}
    
    - **F1åˆ†æ•°**ï¼š{f1:.4f}  
      â†’ è®¡ç®—å…¬å¼ï¼š2 Ã— (ç²¾ç¡®ç‡ Ã— å¬å›ç‡) / (ç²¾ç¡®ç‡ + å¬å›ç‡)  
      â†’ å«ä¹‰ï¼šå¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„ç»¼åˆæŒ‡æ ‡
    """)

    # è®°å½•æ“ä½œï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
    st.session_state.logistic_records["model_evaluation"].append({
        "scenario": scenario,
        "timestamp": datetime.now().timestamp()
    })
    
    return f"æ¨¡å‹è¯„ä¼°æ¨¡å—: å‡†ç¡®ç‡={accuracy:.4f}, ç²¾ç¡®ç‡={precision:.4f}, å¬å›ç‡={recall:.4f}, F1={f1:.4f}"

# æ¦‚å¿µæµ‹éªŒæ¨¡å—
def quiz_section():
    st.header("ğŸ¯ æ¦‚å¿µæµ‹éªŒ")
    st.write("è¯·å®Œæˆä»¥ä¸‹5é“å•é€‰é¢˜ï¼Œå…¨éƒ¨ç­”å®Œåå¯æäº¤æŸ¥çœ‹ç»“æœ")
    
    # å®šä¹‰æµ‹éªŒé¢˜ç›®ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆåŠè§£æ
    quiz_data = [
        {
            "question": "1. é€»è¾‘å›å½’çš„è¾“å‡ºæ˜¯ä»€ä¹ˆ?",
            "options": [
                "A. è¿ç»­çš„é¢„æµ‹å€¼",
                "B. 0æˆ–1çš„åˆ†ç±»ç»“æœ",
                "C. å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡"
            ],
            "correct": "C",
            "explanation": "é€»è¾‘å›å½’è¾“å‡ºçš„æ˜¯æ ·æœ¬å±äºæ­£ç±»çš„æ¦‚ç‡ï¼ŒèŒƒå›´åœ¨0åˆ°1ä¹‹é—´ã€‚"
        },
        {
            "question": "2. sigmoidå‡½æ•°çš„ä½œç”¨æ˜¯ä»€ä¹ˆ?",
            "options": [
                "A. å¢åŠ æ¨¡å‹å¤æ‚åº¦",
                "B. å°†çº¿æ€§è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡",
                "C. åŠ é€Ÿæ¨¡å‹è®­ç»ƒ"
            ],
            "correct": "B",
            "explanation": "Sigmoidå‡½æ•°èƒ½å°†ä»»æ„å®æ•°æ˜ å°„åˆ°(0,1)åŒºé—´ï¼Œé€‚åˆè¡¨ç¤ºæ¦‚ç‡ã€‚"
        },
        {
            "question": "3. é€»è¾‘å›å½’ä¸ºä»€ä¹ˆä½¿ç”¨äº¤å‰ç†µæŸå¤±?",
            "options": [
                "A. äº¤å‰ç†µæŸå¤±è®¡ç®—æ›´ç®€å•",
                "B. äº¤å‰ç†µæŸå¤±æ˜¯å‡¸å‡½æ•°ï¼Œæ›´å®¹æ˜“ä¼˜åŒ–",
                "C. æ²¡æœ‰ç‰¹åˆ«åŸå› ï¼Œåªæ˜¯ä¼ ç»Ÿä¹ æƒ¯"
            ],
            "correct": "B",
            "explanation": "å¯¹äºé€»è¾‘å›å½’ï¼Œäº¤å‰ç†µæŸå¤±æ˜¯å‡¸å‡½æ•°ï¼Œå­˜åœ¨å”¯ä¸€æœ€å°å€¼ï¼Œè€Œå‡æ–¹è¯¯å·®æ˜¯non-convexçš„ã€‚"
        },
        {
            "question": "4. åˆ†ç±»é˜ˆå€¼å¦‚ä½•å½±å“æ¨¡å‹æ€§èƒ½?",
            "options": [
                "A. é˜ˆå€¼ä¸å½±å“æ¨¡å‹æ€§èƒ½",
                "B. é«˜é˜ˆå€¼ä¼šæé«˜ç²¾ç¡®ç‡ä½†é™ä½å¬å›ç‡",
                "C. é«˜é˜ˆå€¼ä¼šåŒæ—¶æé«˜ç²¾ç¡®ç‡å’Œå¬å›ç‡"
            ],
            "correct": "B",
            "explanation": "é«˜é˜ˆå€¼æ„å‘³ç€æ›´ä¸¥æ ¼çš„æ­£ç±»åˆ¤æ–­æ ‡å‡†ï¼Œå‡å°‘è¯¯æŠ¥ä½†å¯èƒ½å¢åŠ æ¼æŠ¥ã€‚"
        },
        {
            "question": "5. é€»è¾‘å›å½’å¯ä»¥å¤„ç†éçº¿æ€§é—®é¢˜å—?",
            "options": [
                "A. ä¸èƒ½ï¼Œé€»è¾‘å›å½’åªèƒ½å¤„ç†çº¿æ€§å¯åˆ†é—®é¢˜",
                "B. å¯ä»¥ï¼Œé€šè¿‡ç‰¹å¾å·¥ç¨‹å¼•å…¥éçº¿æ€§ç‰¹å¾",
                "C. å¯ä»¥ï¼Œé€»è¾‘å›å½’æœ¬èº«æ˜¯éçº¿æ€§æ¨¡å‹"
            ],
            "correct": "B",
            "explanation": "é€»è¾‘å›å½’çš„å†³ç­–è¾¹ç•Œæœ¬èº«æ˜¯çº¿æ€§çš„ï¼Œä½†é€šè¿‡æ·»åŠ å¤šé¡¹å¼ç‰¹å¾ç­‰æ–¹å¼ï¼Œå¯ä»¥å¤„ç†éçº¿æ€§é—®é¢˜ã€‚"
        }
    ]
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å­˜å‚¨ç”¨æˆ·ç­”æ¡ˆ
    st.session_state.user_answers = [None] * len(quiz_data)
    
    # æ˜¾ç¤ºæ‰€æœ‰é¢˜ç›®å’Œé€‰é¡¹ï¼ˆåˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼‰
    for i, item in enumerate(quiz_data):
        st.markdown(f"**{item['question']}**")
        # è®¾ç½®é»˜è®¤å€¼ä¸ºNoneå®ç°åˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼Œé€šè¿‡ä¼šè¯çŠ¶æ€ä¿å­˜ç­”æ¡ˆ
        answer = st.radio(
            "é€‰æ‹©ç­”æ¡ˆ:",
            item["options"],
            key=f"quiz_{i}",
            index=None,  # å…³é”®ï¼šåˆå§‹æ— é€‰ä¸­é¡¹
            label_visibility="collapsed"
        )
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„ç­”æ¡ˆï¼ˆæå–é€‰é¡¹å­—æ¯A/B/Cï¼‰
        if answer is not None:
            st.session_state.user_answers[i] = answer[0]
        
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢˜ç›®éƒ½å·²ä½œç­”
    all_answered = all(ans is not None for ans in st.session_state.user_answers)
    
    # æäº¤æŒ‰é’®ï¼šåªæœ‰å…¨éƒ¨ç­”å®Œæ‰å¯ç”¨
    submit_btn = st.button(
        "æäº¤ç­”æ¡ˆ", 
        key="submit_quiz",
        disabled=not all_answered  # æœªç­”å®Œæ—¶ç¦ç”¨
    )
    
    # æœªç­”å®Œæ—¶æ˜¾ç¤ºæç¤º
    if not all_answered:
        st.info("è¯·å®Œæˆæ‰€æœ‰5é“é¢˜ç›®åå†æäº¤")
    
    # å¤„ç†æäº¤
    if submit_btn and all_answered:
        # è®¡ç®—å¾—åˆ†å’Œé”™è¯¯é¢˜ç›®
        score = 0
        results = []
        incorrect_questions = []
        for i, item in enumerate(quiz_data):
            is_correct = st.session_state.user_answers[i] == item["correct"]
            if is_correct:
                score += 20  # æ¯é¢˜20åˆ†
            else:
                incorrect_questions.append({"topic": item["question"], "user_answer": st.session_state.user_answers[i]})
            results.append({
                "question": item["question"],
                "user_answer": st.session_state.user_answers[i],
                "correct_answer": item["correct"],
                "is_correct": is_correct,
                "explanation": item["explanation"]
            })


        # è®°å½•æµ‹éªŒç»“æœï¼ˆæ–°å¢ï¼šç”¨äºè¯„ä»·åˆ†æï¼‰
        st.session_state.logistic_records["logistic_quiz"] = {
            "score": score,
            "incorrect_questions": incorrect_questions,
            "timestamp": datetime.now().timestamp()
        }
        
        # æ˜¾ç¤ºå¾—åˆ†
        st.success(f"ğŸ“Š æµ‹éªŒå®Œæˆï¼ä½ çš„å¾—åˆ†æ˜¯ï¼š{score}åˆ†")
        st.write("### ç­”æ¡ˆè§£æï¼š")
        
        # æ˜¾ç¤ºæ¯é¢˜ç»“æœï¼ˆä¿®æ­£åï¼‰
        for res in results:
            # ä½¿ç”¨emojiå’Œæ–‡å­—æ ‡è®°æ­£ç¡®/é”™è¯¯çŠ¶æ€
            if res["is_correct"]:
                status_text = "âœ… æ­£ç¡®"
            else:
                status_text = "âŒ é”™è¯¯"
            
            with st.expander(f"{res['question']} {status_text}"):
                if res["is_correct"]:
                    st.success(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆæ­£ç¡®ï¼‰")
                else:
                    st.error(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆé”™è¯¯ï¼‰")
                    st.info(f"æ­£ç¡®ç­”æ¡ˆï¼š{res['correct_answer']}")
                st.write(f"è§£æï¼š{res['explanation']}")
        
        # å‡†å¤‡AIåˆ†æçš„è¾“å…¥
        incorrect_topics = [
            res["question"] for res in results if not res["is_correct"]
        ]
        
        analysis_prompt = f"""
        ä»¥ä¸‹æ˜¯å­¦ç”Ÿåœ¨çº¿æ€§å›å½’æµ‹éªŒä¸­çš„ç­”é¢˜æƒ…å†µï¼š
        - æ€»å¾—åˆ†ï¼š{score}åˆ†
        - é”™è¯¯é¢˜ç›®ï¼š{len(incorrect_topics)}é“
        - é”™è¯¯çŸ¥è¯†ç‚¹ï¼š{'; '.join(incorrect_topics) if incorrect_topics else 'æ— '}
        
        è¯·åˆ†æè¯¥å­¦ç”Ÿçš„çŸ¥è¯†æŒæ¡æƒ…å†µï¼ŒæŒ‡å‡ºæœªæŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶ç»™å‡ºå…·ä½“çš„å­¦ä¹ å»ºè®®å’ŒæŒ‡å¯¼æ–¹å‘ï¼Œå¸®åŠ©å­¦ç”Ÿé’ˆå¯¹æ€§æå‡ã€‚
        ç­”æ¡ˆå¿…é¡»æ§åˆ¶åœ¨450å­—ä»¥å†…
        """
        
        # è°ƒç”¨AIåˆ†æ
        with st.spinner("AIæ­£åœ¨åˆ†æä½ çš„ç­”é¢˜æƒ…å†µ..."):
            ai_analysis = ask_ai_assistant(analysis_prompt, "çº¿æ€§å›å½’æµ‹éªŒåˆ†æ")
        
        # æ˜¾ç¤ºAIåˆ†æç»“æœ
        st.write("### ğŸ¤– AIå­¦ä¹ è¯Šæ–­ï¼š")
        st.info(ai_analysis)
    
    return "æ¦‚å¿µæµ‹éªŒæ¨¡å—ï¼šå®Œæˆ5é¢˜å•é€‰é¢˜æµ‹è¯•"

# å®é™…åº”ç”¨æ¡ˆä¾‹æ¨¡å—
def real_world_example_section():
    st.header("ğŸŒ é€»è¾‘å›å½’å®é™…åº”ç”¨æ¡ˆä¾‹")
    
    example = st.selectbox(
        "é€‰æ‹©å®é™…åº”ç”¨æ¡ˆä¾‹:",
        ["ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹", "å®¢æˆ·æµå¤±é¢„æµ‹", "ç–¾ç—…é£é™©é¢„æµ‹", "ä¸Šä¼ è‡ªå·±çš„æ•°æ®"]
    )
    
    if example == "ä¸Šä¼ è‡ªå·±çš„æ•°æ®":
        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file:
            data = pd.read_csv(uploaded_file)
            st.write("æ•°æ®é¢„è§ˆ:", data.head())
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ç±»å˜é‡
            categorical_cols = data.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                st.warning("æ£€æµ‹åˆ°åˆ†ç±»å˜é‡ï¼Œæœ¬æ¼”ç¤ºå°†è‡ªåŠ¨å¿½ç•¥è¿™äº›åˆ—ã€‚")
                data = data.select_dtypes(exclude=['object'])
            
            # é€‰æ‹©ç›®æ ‡åˆ—
            if len(data.columns) < 2:
                st.error("æ•°æ®è‡³å°‘éœ€è¦åŒ…å«ä¸€ä¸ªç‰¹å¾åˆ—å’Œä¸€ä¸ªç›®æ ‡åˆ—!")
                return
            
            target_col = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—(åº”åŒ…å«0å’Œ1)", data.columns)
            
            # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦ä¸ºäºŒåˆ†ç±»
            unique_vals = data[target_col].unique()
            if len(unique_vals) != 2 or not set(unique_vals).issubset({0, 1}):
                st.error("ç›®æ ‡åˆ—å¿…é¡»æ˜¯äºŒåˆ†ç±»(åªåŒ…å«0å’Œ1)!")
                return
            
            # é€‰æ‹©ç‰¹å¾åˆ—
            feature_cols = [col for col in data.columns if col != target_col]
            if not feature_cols:
                st.error("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—!")
                return
            
            X = data[feature_cols].values
            y = data[target_col].values
            
            analyze_custom_data(X, y, feature_cols, target_col)
            return f"å®é™…åº”ç”¨æ¨¡å—: ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®, ç›®æ ‡åˆ—={target_col}"
    else:
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        X, y, description = load_example_dataset(example)
        st.write(description)
        
        analyze_custom_data(X, y, ["ç‰¹å¾1", "ç‰¹å¾2", "ç‰¹å¾3"], "ç›®æ ‡å˜é‡")
        return f"å®é™…åº”ç”¨æ¨¡å—: ä½¿ç”¨{example}æ•°æ®é›†"

# åŠ è½½ç¤ºä¾‹æ•°æ®é›†
def load_example_dataset(example_name):
    np.random.seed(42)
    
    if example_name == "ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹":
        # ç”Ÿæˆæ¬ºè¯ˆæ£€æµ‹æ•°æ®ï¼šå¤§å¤šæ•°æ˜¯æ­£å¸¸äº¤æ˜“ï¼Œå°‘æ•°æ˜¯æ¬ºè¯ˆ
        n_samples = 500
        n_fraud = int(n_samples * 0.1)  # 10%æ¬ºè¯ˆç‡
        
        # æ­£å¸¸äº¤æ˜“ç‰¹å¾
        normal_amount = np.random.normal(500, 300, n_samples - n_fraud)
        normal_time = np.random.normal(12, 6, n_samples - n_fraud)
        normal_freq = np.random.normal(2, 1, n_samples - n_fraud)
        
        # æ¬ºè¯ˆäº¤æ˜“ç‰¹å¾ï¼ˆé‡‘é¢æ›´å¤§ï¼Œæ—¶é—´æ›´æ™šï¼Œé¢‘ç‡æ›´ä½ï¼‰
        fraud_amount = np.random.normal(2000, 800, n_fraud)
        fraud_time = np.random.normal(20, 4, n_fraud)
        fraud_freq = np.random.normal(0.5, 0.3, n_fraud)
        
        # åˆå¹¶æ•°æ®
        X = np.vstack([
            np.column_stack((normal_amount, normal_time, normal_freq)),
            np.column_stack((fraud_amount, fraud_time, fraud_freq))
        ])
        y = np.hstack([np.zeros(n_samples - n_fraud), np.ones(n_fraud)])
        
        # æ‰“ä¹±é¡ºåº
        indices = np.random.permutation(n_samples)
        X = X[indices]
        y = y[indices]
        
        description = "ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹æ•°æ®: åŒ…å«äº¤æ˜“é‡‘é¢ã€æ—¶é—´å’Œé¢‘ç‡ç‰¹å¾ï¼Œé¢„æµ‹äº¤æ˜“æ˜¯å¦ä¸ºæ¬ºè¯ˆ(1=æ¬ºè¯ˆ)"
        return X, y, description
    
    elif example_name == "å®¢æˆ·æµå¤±é¢„æµ‹":
        # ç”Ÿæˆå®¢æˆ·æµå¤±æ•°æ®
        n_samples = 500
        
        # ç‰¹å¾ï¼šä½¿ç”¨æ—¶é•¿(æœˆ)ã€æœˆæ¶ˆè´¹ã€å®¢æœè”ç³»æ¬¡æ•°
        tenure = np.random.normal(30, 20, n_samples)
        monthly_charge = np.random.normal(50, 30, n_samples)
        support_calls = np.random.randint(0, 10, n_samples)
        
        X = np.column_stack((tenure, monthly_charge, support_calls))
        
        # æµå¤±æ¦‚ç‡ï¼šä½¿ç”¨æ—¶é•¿è¶ŠçŸ­ã€æœˆæ¶ˆè´¹è¶Šé«˜ã€å®¢æœè”ç³»è¶Šå¤šï¼Œæµå¤±æ¦‚ç‡è¶Šå¤§
        z = -0.05*tenure + 0.03*monthly_charge + 0.3*support_calls - 2
        prob = sigmoid(z)
        y = np.random.binomial(1, prob)
        
        description = "å®¢æˆ·æµå¤±é¢„æµ‹æ•°æ®: åŒ…å«ä½¿ç”¨æ—¶é•¿ã€æœˆæ¶ˆè´¹å’Œå®¢æœè”ç³»æ¬¡æ•°ï¼Œé¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šæµå¤±(1=æµå¤±)"
        return X, y, description
    
    elif example_name == "ç–¾ç—…é£é™©é¢„æµ‹":
        # ç”Ÿæˆç–¾ç—…é£é™©é¢„æµ‹æ•°æ®
        n_samples = 500
        
        # ç‰¹å¾ï¼šå¹´é¾„ã€BMIã€è¡€å‹
        age = np.random.normal(50, 15, n_samples)
        bmi = np.random.normal(25, 5, n_samples)
        blood_pressure = np.random.normal(120, 15, n_samples)
        
        X = np.column_stack((age, bmi, blood_pressure))
        
        # æ‚£ç—…æ¦‚ç‡ï¼šå¹´é¾„è¶Šå¤§ã€BMIè¶Šé«˜ã€è¡€å‹è¶Šé«˜ï¼Œæ‚£ç—…æ¦‚ç‡è¶Šå¤§
        z = 0.04*age + 0.1*bmi + 0.03*blood_pressure - 10
        prob = sigmoid(z)
        y = np.random.binomial(1, prob)
        
        description = "ç–¾ç—…é£é™©é¢„æµ‹æ•°æ®: åŒ…å«å¹´é¾„ã€BMIå’Œè¡€å‹ï¼Œé¢„æµ‹æ‚£ç—…é£é™©(1=æ‚£ç—…)"
        return X, y, description
    
    return None, None, ""

# åˆ†æè‡ªå®šä¹‰æ•°æ®ï¼ˆä¸ä½¿ç”¨æ ‡å‡†åŒ–ï¼‰
def analyze_custom_data(X, y, feature_names, target_name):
    if len(X) != len(y):
        st.error("ç‰¹å¾å’Œç›®æ ‡çš„é•¿åº¦ä¸åŒ¹é…!")
        return
    
    if len(X) < 10:
        st.error("æ•°æ®ç‚¹å¤ªå°‘ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬!")
        return
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆä¸ä½¿ç”¨æ ‡å‡†åŒ–ï¼‰
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X, y)
    
    # é¢„æµ‹æ¦‚ç‡
    y_prob = model.predict_proba(X)[:, 1]
    
    # è¯„ä¼°æ¨¡å‹
    threshold = 0.5
    y_pred = (y_prob >= threshold).astype(int)
    accuracy = accuracy_score(y, y_pred)
    report = classification_report(y, y_pred)
    
    st.subheader("æ¨¡å‹æ€§èƒ½")
    st.text(report)
    
    # æ˜¾ç¤ºç³»æ•°
    st.subheader("ç‰¹å¾é‡è¦æ€§ï¼ˆç³»æ•°ï¼‰")
    coef_df = pd.DataFrame({
        'ç‰¹å¾': feature_names,
        'ç³»æ•°': model.coef_[0]
    }).sort_values('ç³»æ•°', ascending=False)
    st.dataframe(coef_df)
    
    st.info("""
    **ç³»æ•°è§£é‡Š:**
    - æ­£ç³»æ•°: è¯¥ç‰¹å¾å€¼è¶Šå¤§ï¼Œå±äºæ­£ç±»çš„æ¦‚ç‡è¶Šé«˜
    - è´Ÿç³»æ•°: è¯¥ç‰¹å¾å€¼è¶Šå¤§ï¼Œå±äºæ­£ç±»çš„æ¦‚ç‡è¶Šä½
    - ç³»æ•°ç»å¯¹å€¼è¶Šå¤§ï¼Œç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“è¶Šå¤§
    
    æ³¨æ„ï¼šç³»æ•°å¤§å°å—ç‰¹å¾å°ºåº¦å½±å“ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯åŸå§‹æ•°æ®ï¼Œæœªè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚
    """)
    
    # å¦‚æœæ˜¯äºŒç»´æ•°æ®ï¼Œç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    if X.shape[1] == 2:
        fig = plot_decision_boundary(X, y, model.coef_[0], model.intercept_[0])
        st.pyplot(fig)

        
# ä¸»ç¨‹åº
def main():

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'section' not in st.session_state:
        st.session_state.section = "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢"

    # åˆå§‹åŒ–é€»è¾‘å›å½’ä¸“å±çš„å­¦ä¹ è®°å½•ï¼ˆä¸çº¿æ€§å›å½’åŒºåˆ†å¼€ï¼‰
    if "logistic_records" not in st.session_state:
        st.session_state.logistic_records = {
            "data_generation": [],  # æ•°æ®ç”Ÿæˆæ¨¡å—è®°å½•
            "sig_function":[],  #sigmoidå‡½æ•°äº¤äº’
            "module_sequence": [],
            "module_timestamps": {},
            "para_tuning": [],  # å‚æ•°æ‰‹åŠ¨è°ƒæ•´
            "gradient_descent": [],  # æ¢¯åº¦ä¸‹é™æ¨¡å—è®°å½•
            "model_evaluation": [],  # æ¨¡å‹è¯„ä¼°æ¨¡å—è®°å½•
            "logistic_quiz": {},  # é€»è¾‘å›å½’ä¸“å±æµ‹éªŒ
            "ai_interactions": []
        }
    # è®°å½•æ¨¡å—è®¿é—®é¡ºåºï¼ˆè¿›å…¥æ¨¡å—æ—¶è§¦å‘ï¼‰AI
    current_section = st.session_state.section
    st.session_state.logistic_records["module_sequence"].append(current_section)
    if current_section not in st.session_state.logistic_records["module_timestamps"]:
        st.session_state.logistic_records["module_timestamps"][current_section] = {
            "enter_time": time.time()
        }       

    
    st.sidebar.title("å¯¼èˆªèœå•")
    section = st.sidebar.radio("é€‰æ‹©å­¦ä¹ æ¨¡å—", [
        "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢",
        "Sigmoidå‡½æ•°äº¤äº’æ¼”ç¤º",
        "å‚æ•°æ‰‹åŠ¨è°ƒæ•´",
        "æ¢¯åº¦ä¸‹é™å¯è§†åŒ–",
        "æ¨¡å‹è¯„ä¼°",
        "æ¦‚å¿µæµ‹éªŒ",
        "å®é™…åº”ç”¨æ¡ˆä¾‹",
        "ç¼–ç¨‹å®ä¾‹ï¼ˆä¹³è…ºç™Œæ•°æ®é›†ï¼‰" 
    ])
  
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.section = section
    
    context = ""
    if section == "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢":
        context = data_generation_section()
    elif section == "Sigmoidå‡½æ•°äº¤äº’æ¼”ç¤º":
        context = sigmoid_interactive_section()
    elif section == "å‚æ•°æ‰‹åŠ¨è°ƒæ•´":
        context = manual_tuning_section()
    elif section == "æ¢¯åº¦ä¸‹é™å¯è§†åŒ–":
        context = gradient_descent_section()
    elif section == "æ¨¡å‹è¯„ä¼°":
        context = model_evaluation_section()
    elif section == "æ¦‚å¿µæµ‹éªŒ":
        context = quiz_section()
    elif section == "å®é™…åº”ç”¨æ¡ˆä¾‹":
        context = real_world_example_section()
    elif section == "ç¼–ç¨‹å®ä¾‹ï¼ˆä¹³è…ºç™Œæ•°æ®é›†ï¼‰":
        # åˆå§‹åŒ–stepå˜é‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'step' not in st.session_state:
            st.session_state.step = 0
        logistic_regression_step_by_step.main()
        context = "ç¼–ç¨‹å®ä¾‹æ¨¡å—: ä¹³è…ºç™Œæ•°æ®é›†é€»è¾‘å›å½’åˆ†æ­¥ç»ƒä¹ "
    
    display_chat_interface(context)

    # è®°å½•æ¨¡å—é€€å‡ºæ—¶é—´ï¼ˆæ–°å¢ï¼šç”¨äºè®¡ç®—åœç•™æ—¶é—´ï¼‰
    if current_section in st.session_state.logistic_records["module_timestamps"]:
        st.session_state.logistic_records["module_timestamps"][current_section]["exit_time"] = datetime.now().timestamp()

    if section != "ç¼–ç¨‹å®ä¾‹ï¼ˆä¹³è…ºç™Œæ•°æ®é›†ï¼‰":
        # ä¾§è¾¹æ æ·»åŠ å­¦ä¹ æŠ¥å‘ŠæŒ‰é’®ï¼ˆè°ƒç”¨ç‹¬ç«‹æ¨¡å—ï¼‰
        st.sidebar.markdown("---")
        if st.sidebar.button("é€»è¾‘å›å½’æ¨¡å—å­¦ä¹ æŠ¥å‘Š"):
            # ä¼ å…¥æ¨¡å—ç±»å‹ã€åŸå§‹è®°å½•ã€AIè°ƒç”¨å‡½æ•°
            report = generate_evaluation(
                module_type="logistic_regression",
                raw_records=st.session_state.logistic_records
            )
            st.write("### é€»è¾‘å›å½’å­¦ä¹ æƒ…å†µæŠ¥å‘Š")
            st.info(report)
    
    # ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **é€»è¾‘å›å½’äº¤äº’å¼å­¦ä¹ å¹³å°**
    
    è®¾è®¡ç”¨äºæœºå™¨å­¦ä¹ æ•™å­¦ï¼Œå¸®åŠ©å­¦ç”Ÿç†è§£:
    - é€»è¾‘å›å½’åŸºæœ¬åŸç†
    - Sigmoidå‡½æ•°çš„ä½œç”¨ä¸ç‰¹æ€§
    - åˆ†ç±»é˜ˆå€¼çš„é€‰æ‹©ç­–ç•¥
    - æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ä¸è§£é‡Š
    """)


if __name__ == "__main__":
    main()
