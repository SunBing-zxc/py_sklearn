# streamlit run neural_network_demo.py

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.datasets import make_classification, make_regression, load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, mean_squared_error
import time
from api_deepseek import client, ask_ai_assistant
from matplotlib.colors import ListedColormap
import neural_network_step_by_step
from datetime import datetime
from learning_report import generate_evaluation
# è®¾ç½®é¡µé¢
st.set_page_config(page_title="ç¥ç»ç½‘ç»œäº¤äº’å¼å­¦ä¹ å¹³å°", layout="wide")
st.title("ğŸ§  ç¥ç»ç½‘ç»œäº¤äº’å¼å­¦ä¹ å¹³å°")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆåœ¨ä¸»ç¨‹åºå…¥å£å¤„ï¼‰
def init_session_state():
    if 'nn_records' not in st.session_state:
        st.session_state.nn_records = {
            "nn_basics_section": [],  # ç¥ç»ç½‘ç»œåŸºæœ¬æ¦‚å¿µ
            "multi_layer_nn_section": [],  # å¤šå±‚ç¥ç»ç½‘ç»œä¸åå‘ä¼ æ’­
            "activation_functions_section": [],  # æ¿€æ´»å‡½æ•°ä½œä¸šä¸é€‰æ‹©
            "nn_parameter_tuning_section": [],  # ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜
            "nn_applications_section": [], #å®é™…æ¡ˆä¾‹
            "module_sequence": [],  # æ¨¡å—è®¿é—®é¡ºåº
            "module_timestamps": {},  # æ¨¡å—åœç•™æ—¶é—´
            "ANN_quiz": {},  # æµ‹éªŒè®°å½•
            "ai_interactions": []  # AIäº¤äº’è®°å½•
        }
        
def display_chat_interface(context=""):
    """æ˜¾ç¤ºèŠå¤©ç•Œé¢"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¬ AIåŠ©æ•™å·²å°±ç»ª")
    
    # é¢„è®¾é—®é¢˜å¿«æ·æŒ‰é’®
    st.sidebar.markdown("**å¿«æ·é—®é¢˜:**")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        btn1 = st.button("ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ?")
        btn2 = st.button("æ¿€æ´»å‡½æ•°çš„ä½œç”¨?")
    
    with col2:
        btn3 = st.button("åå‘ä¼ æ’­ç®—æ³•?")
        btn4 = st.button("è¿‡æ‹Ÿåˆå¦‚ä½•è§£å†³?")
    
    # å¤„ç†å¿«æ·é—®é¢˜
    question = ""
    if btn1:
        question = "ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ?"
    elif btn2:
        question = "æ¿€æ´»å‡½æ•°çš„ä½œç”¨æ˜¯ä»€ä¹ˆ?"
    elif btn3:
        question = "ä»€ä¹ˆæ˜¯åå‘ä¼ æ’­ç®—æ³•?"
    elif btn4:
        question = "å¦‚ä½•è§£å†³ç¥ç»ç½‘ç»œçš„è¿‡æ‹Ÿåˆé—®é¢˜?"
    
    # æé—®è¾“å…¥æ¡†
    user_input = st.sidebar.text_input("è¾“å…¥ä½ çš„é—®é¢˜:", key="question_input")
    if user_input:
        question = user_input
    
    # å¤„ç†æé—®
    if question:
        # è®°å½•AIäº¤äº’
        if "ai_interactions" not in st.session_state.nn_records:
            st.session_state.nn_records["ai_interactions"] = []

        st.session_state.nn_records["ai_interactions"].append({
            "question": question,
            "timestamp": datetime.now().timestamp()
        })
        
        # æ˜¾ç¤ºå½“å‰é—®é¢˜
        st.sidebar.markdown(f"**ä½ :** {question}")
        
        # è·å–å›ç­”
        with st.spinner("åŠ©æ•™æ€è€ƒä¸­..."):
            time.sleep(1)  # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
            answer = ask_ai_assistant(question, context)
        
        # æ˜¾ç¤ºå½“å‰å›ç­”
        st.sidebar.markdown(f"**åŠ©æ•™:** {answer}")
        st.sidebar.markdown("---")

# æ•°æ®ç”Ÿæˆå‡½æ•°
def generate_data(data_type, n_samples=300, noise=0.1):
    """ç”Ÿæˆä¸åŒç±»å‹çš„æ•°æ®ç”¨äºç¥ç»ç½‘ç»œæ¼”ç¤º"""
    np.random.seed(42)
    
    if data_type == "äºŒåˆ†ç±»é—®é¢˜":
        X, y = make_classification(
            n_samples=n_samples, n_features=2, n_informative=2,
            n_redundant=0, n_clusters_per_class=1, random_state=42
        )
        problem_type = "classification"
    
    elif data_type == "å¤šåˆ†ç±»é—®é¢˜":
        X, y = make_classification(
            n_samples=n_samples, n_features=2, n_informative=2,
            n_redundant=0, n_classes=3, n_clusters_per_class=1, random_state=42
        )
        problem_type = "classification"
    
    elif data_type == "éçº¿æ€§åˆ†ç±»":
        # ç”Ÿæˆç¯å½¢æ•°æ®
        X = np.random.randn(n_samples, 2)
        y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)
        y = y.astype(int)
        problem_type = "classification"
    
    elif data_type == "å›å½’é—®é¢˜":
        X, y = make_regression(
            n_samples=n_samples, n_features=1, noise=noise*10, random_state=42
        )
        # ä½¿å…³ç³»éçº¿æ€§åŒ–
        y = y + 30 * np.sin(X).ravel()
        problem_type = "regression"
    
    return X, y, problem_type

# ç»˜åˆ¶æ•°æ®åˆ†å¸ƒ
def plot_data(X, y=None, title="æ•°æ®åˆ†å¸ƒ", problem_type="classification"):
    """ç»˜åˆ¶æ•°æ®é›†çš„æ•£ç‚¹å›¾æˆ–çº¿å›¾"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    if problem_type == "classification":
        if y is not None:
            scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.7, s=50)
            ax.legend(*scatter.legend_elements(), title="ç±»åˆ«")
        else:
            ax.scatter(X[:, 0], X[:, 1], c='gray', alpha=0.7, s=50)
        ax.set_xlabel('ç‰¹å¾ 1')
        ax.set_ylabel('ç‰¹å¾ 2')
    
    elif problem_type == "regression":
        ax.scatter(X, y, alpha=0.7, s=50)
        ax.set_xlabel('ç‰¹å¾')
        ax.set_ylabel('ç›®æ ‡å€¼')
    
    ax.set_title(title)
    ax.grid(True, linestyle='--', alpha=0.7)
    return fig

# å¯è§†åŒ–ç¥ç»ç½‘ç»œå†³ç­–è¾¹ç•Œ
def plot_decision_boundary(X, y, model, title="ç¥ç»ç½‘ç»œå†³ç­–è¾¹ç•Œ", problem_type="classification"):
    """ç»˜åˆ¶ç¥ç»ç½‘ç»œçš„å†³ç­–è¾¹ç•Œ"""
    if problem_type != "classification" or X.shape[1] != 2:
        return None
    
    h = 0.02  # ç½‘æ ¼æ­¥é•¿
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    
    # é¢„æµ‹ç½‘æ ¼ç‚¹çš„ç±»åˆ«
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    fig, ax = plt.subplots(figsize=(10, 6))
    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])
    
    ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.3)
    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, alpha=0.7, s=50, edgecolor="k")
    
    ax.set_xlabel('ç‰¹å¾ 1')
    ax.set_ylabel('ç‰¹å¾ 2')
    ax.set_title(title)
    ax.grid(True, linestyle='--', alpha=0.7)
    return fig

# å¯è§†åŒ–ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹
def plot_training_curve(history, title="ç¥ç»ç½‘ç»œè®­ç»ƒæ›²çº¿"):
    """ç»˜åˆ¶ç¥ç»ç½‘ç»œçš„è®­ç»ƒæ›²çº¿ï¼ˆæŸå¤±å’Œå‡†ç¡®ç‡ï¼‰"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    ax1.plot(history['loss'], label='è®­ç»ƒæŸå¤±')
    if 'val_loss' in history:
        ax1.plot(history['val_loss'], label='éªŒè¯æŸå¤±')
    ax1.set_title('æŸå¤±æ›²çº¿')
    ax1.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax1.set_ylabel('æŸå¤±å€¼')
    ax1.legend()
    ax1.grid(True, linestyle='--', alpha=0.7)
    
    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿ï¼ˆå¦‚æœæ˜¯åˆ†ç±»é—®é¢˜ï¼‰
    if 'accuracy' in history:
        ax2.plot(history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')
        if 'val_accuracy' in history:
            ax2.plot(history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')
        ax2.set_title('å‡†ç¡®ç‡æ›²çº¿')
        ax2.set_xlabel('è¿­ä»£æ¬¡æ•°')
        ax2.set_ylabel('å‡†ç¡®ç‡')
        ax2.legend()
        ax2.grid(True, linestyle='--', alpha=0.7)
    else:
        ax2.set_visible(False)
    
    plt.tight_layout()
    return fig

# æ¿€æ´»å‡½æ•°å¯è§†åŒ–
def plot_activation_functions():
    """ç»˜åˆ¶å¸¸ç”¨æ¿€æ´»å‡½æ•°"""
    x = np.linspace(-5, 5, 100)
    
    # å®šä¹‰æ¿€æ´»å‡½æ•°
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))
    
    def tanh(x):
        return np.tanh(x)
    
    def relu(x):
        return np.maximum(0, x)
    
    def leaky_relu(x, alpha=0.1):
        return np.where(x >= 0, x, alpha * x)
    
    # ç»˜åˆ¶æ¿€æ´»å‡½æ•°
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('å¸¸ç”¨æ¿€æ´»å‡½æ•°', fontsize=16)
    
    axes[0, 0].plot(x, sigmoid(x))
    axes[0, 0].set_title('Sigmoid')
    axes[0, 0].grid(True, linestyle='--', alpha=0.7)
    
    axes[0, 1].plot(x, tanh(x))
    axes[0, 1].set_title('Tanh')
    axes[0, 1].grid(True, linestyle='--', alpha=0.7)
    
    axes[1, 0].plot(x, relu(x))
    axes[1, 0].set_title('ReLU')
    axes[1, 0].grid(True, linestyle='--', alpha=0.7)
    
    axes[1, 1].plot(x, leaky_relu(x))
    axes[1, 1].set_title('Leaky ReLU')
    axes[1, 1].grid(True, linestyle='--', alpha=0.7)
    
    # ç»˜åˆ¶å®Œæ‰€æœ‰æ¿€æ´»å‡½æ•°æ›²çº¿åï¼Œéå†æ‰€æœ‰å­å›¾æ·»åŠ å‚è€ƒçº¿
    for ax in axes.flatten():
        ax.axvline(x=0, color='red', linestyle='--', alpha=0.7)  # x=0å‚ç›´çº¿
        ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)  # y=0æ°´å¹³çº¿
        
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    return fig

# ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µæ¨¡å—
def nn_basics_section():
    st.header("ğŸ” ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µ")
    
    # ä½¿ç”¨åˆ—å¸ƒå±€å°†æ–‡æœ¬å’Œç¤ºæ„å›¾å¹¶æ’æ˜¾ç¤º
    col_text, col_image = st.columns([3, 2])  # æ–‡æœ¬å 3ä»½ï¼Œå›¾ç‰‡å 2ä»½
    
    with col_text:
        st.markdown("""
        **ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»„æˆ:**
        ç¥ç»ç½‘ç»œç”±ç›¸äº’è¿æ¥çš„äººå·¥ç¥ç»å…ƒç»„æˆï¼Œä¸»è¦åŒ…æ‹¬ï¼š
        
        - **è¾“å…¥å±‚**: æ¥æ”¶åŸå§‹æ•°æ®
        - **éšè—å±‚**: è¿›è¡Œç‰¹å¾å­¦ä¹ å’Œè½¬æ¢
        - **è¾“å‡ºå±‚**: äº§ç”Ÿæœ€ç»ˆé¢„æµ‹ç»“æœ
        - **æƒé‡å’Œåç½®**: ç½‘ç»œçš„å‚æ•°ï¼Œé€šè¿‡è®­ç»ƒå­¦ä¹ å¾—åˆ°
        - **æ¿€æ´»å‡½æ•°**: å¼•å…¥éçº¿æ€§ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚æ¨¡å¼
        
        **ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†:**
        1. å‰å‘ä¼ æ’­: è¾“å…¥æ•°æ®é€šè¿‡ç½‘ç»œå±‚å±‚ä¼ é€’ï¼Œè®¡ç®—è¾“å‡º
        2. è®¡ç®—æŸå¤±: æ¯”è¾ƒé¢„æµ‹è¾“å‡ºä¸çœŸå®å€¼çš„å·®å¼‚
        3. åå‘ä¼ æ’­: è®¡ç®—æŸå¤±å¯¹å„å‚æ•°çš„æ¢¯åº¦
        4. å‚æ•°æ›´æ–°: ä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æ›´æ–°æƒé‡å’Œåç½®
        """)
    
    with col_image:
        # æ˜¾ç¤ºç¥ç»ç½‘ç»œç»“æ„ç¤ºæ„å›¾ï¼Œè®¾ç½®è¾ƒå°çš„å®½åº¦
        st.markdown("**ç¥ç»ç½‘ç»œç»“æ„ç¤ºæ„å›¾**")
        st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/800px-Colored_neural_network.svg.png",
                 caption="ä¸‰å±‚ç¥ç»ç½‘ç»œç»“æ„ï¼ˆè¾“å…¥å±‚ã€éšè—å±‚ã€è¾“å‡ºå±‚ï¼‰",
                 width=250)  # è°ƒæ•´å®½åº¦ä½¿å›¾ç‰‡å˜å°
    
    # æ„ŸçŸ¥å™¨æ¼”ç¤º
    st.subheader("æ„ŸçŸ¥å™¨æ¼”ç¤ºï¼ˆæœ€ç®€å•çš„ç¥ç»ç½‘ç»œï¼‰")

    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        æ„ŸçŸ¥å™¨æ˜¯æœ€ç®€å•çš„ç¥ç»ç½‘ç»œï¼ŒåŒ…å«ä¸€ä¸ªç¥ç»å…ƒï¼š
        1. æ¥æ”¶å¤šä¸ªè¾“å…¥å¹¶åŠ æƒæ±‚å’Œ
        2. åº”ç”¨æ¿€æ´»å‡½æ•°äº§ç”Ÿè¾“å‡º
        3. é€šè¿‡å­¦ä¹ è°ƒæ•´æƒé‡ä»¥æ­£ç¡®åˆ†ç±»æ•°æ®

        æ„ŸçŸ¥å™¨åªèƒ½è§£å†³çº¿æ€§å¯åˆ†é—®é¢˜ï¼Œæ— æ³•è§£å†³å¼‚æˆ–ï¼ˆXORï¼‰ç­‰éçº¿æ€§é—®é¢˜ã€‚
        """)

      
    with col2:
        # æ˜¾ç¤ºæ„ŸçŸ¥å™¨å…¬å¼
        st.markdown("""**æ„ŸçŸ¥å™¨å­¦ä¹ è§„åˆ™:**""")       
        st.latex(r"y = \text{sign}(w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n)")
        st.markdown("""**å½“é¢„æµ‹é”™è¯¯æ—¶ï¼Œæ›´æ–°æƒé‡ï¼š**""") 
        st.latex(r"w_i = w_i + \eta \cdot (y_{true} - y_{pred}) \cdot x_i")

    # è®°å½•æ•°æ®ç”Ÿæˆæ“ä½œ
    st.session_state.nn_records["nn_basics_section"].append({
        "timestamp": datetime.now().timestamp()
    })

    return "ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µæ¨¡å—: ä»‹ç»äº†ç¥ç»ç½‘ç»œç»„æˆå’Œæ„ŸçŸ¥å™¨åŸç†"

# å¤šå±‚ç¥ç»ç½‘ç»œæ¨¡å—
def multi_layer_nn_section():
    st.header("ğŸ—ï¸ å¤šå±‚ç¥ç»ç½‘ç»œä¸åå‘ä¼ æ’­")
   

    st.markdown("""
    **å¤šå±‚ç¥ç»ç½‘ç»œçš„ä¼˜åŠ¿:**
    å¤šå±‚ç¥ç»ç½‘ç»œï¼ˆæ·±åº¦å­¦ä¹ ï¼‰é€šè¿‡å åŠ å¤šä¸ªéšè—å±‚ï¼Œå¯ä»¥å­¦ä¹ æ›´å¤æ‚çš„éçº¿æ€§å…³ç³»ï¼Œèƒ½å¤Ÿè§£å†³æ„ŸçŸ¥å™¨æ— æ³•è§£å†³çš„éçº¿æ€§é—®é¢˜ï¼ˆå¦‚å¼‚æˆ–é—®é¢˜ï¼‰
    """)
    
    import os
    # æ˜¾ç¤ºå›¾ç‰‡
    st.subheader("å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„")
    image_path = f"{os.path.dirname(os.path.abspath(__file__))}/ANN.jpg"
    st.image(image_path,
                caption="å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„",
                width=500)
    
    # åå‘ä¼ æ’­ç®—æ³•éƒ¨åˆ†ï¼Œä½¿ç”¨ä¸Šä¸‹æ’ç‰ˆè€Œéåˆ†æ 
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        **åå‘ä¼ æ’­ç®—æ³•:**
        åå‘ä¼ æ’­æ˜¯è®­ç»ƒå¤šå±‚ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒç®—æ³•ï¼š
        1. å‰å‘ä¼ æ’­è®¡ç®—é¢„æµ‹å€¼å’ŒæŸå¤±
        2. åå‘è®¡ç®—æŸå¤±å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦
        3. ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±
        """)
    with col2:
        st.markdown("""
        **åå‘ä¼ æ’­çš„æ ¸å¿ƒæ€æƒ³:**
        - åˆ©ç”¨é“¾å¼æ³•åˆ™è®¡ç®—æŸå¤±å¯¹æ¯ä¸ªæƒé‡çš„æ¢¯åº¦
        - ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚åå‘ä¼ æ’­è¯¯å·®
        - é€šè¿‡æ¢¯åº¦ä¸‹é™æ›´æ–°æƒé‡ï¼Œä½¿æŸå¤±æœ€å°åŒ–
        
        å¯¹äºä¸€ä¸ªç®€å•çš„ä¸¤å±‚ç½‘ç»œï¼Œè¾“å‡ºå±‚æƒé‡æ›´æ–°å…¬å¼ï¼š""")
        st.latex(r"\Delta w_{jk} = \eta \cdot \delta_k \cdot a_j")
        st.markdown("å…¶ä¸­ $\delta_k$ æ˜¯è¾“å‡ºå±‚è¯¯å·®é¡¹ï¼Œ$a_j$ æ˜¯éšè—å±‚æ¿€æ´»å€¼ã€‚")
            
    # å¼‚æˆ–é—®é¢˜æ¼”ç¤º
    st.subheader("å¼‚æˆ–é—®é¢˜çš„è§£å†³")
    st.markdown("""
    å¼‚æˆ–ï¼ˆXORï¼‰æ˜¯ä¸€ä¸ªç»å…¸çš„éçº¿æ€§é—®é¢˜ï¼Œå•å±‚æ„ŸçŸ¥å™¨æ— æ³•è§£å†³ï¼Œä½†å¤šå±‚ç¥ç»ç½‘ç»œå¯ä»¥è§£å†³ï¼š
    """)
    
    # ç”Ÿæˆå¼‚æˆ–æ•°æ®
    X, y, problem_type = generate_data("éçº¿æ€§åˆ†ç±»", n_samples=100)
    col1, col2 = st.columns([2,3])
    with col1: 
    # ç¥ç»ç½‘ç»œå‚æ•°è®¾ç½®
        hidden_units = st.slider("éšè—å±‚ç¥ç»å…ƒæ•°", 2, 20, 4)
        activation = st.selectbox("æ¿€æ´»å‡½æ•°", ["relu", "tanh", "logistic"])
        max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 800, 200)
        learning_rate = st.slider("å­¦ä¹ ç‡", 0.001, 0.3, 0.01)    
    with col2:    
        # æ˜¾ç¤ºå¼‚æˆ–æ•°æ®
        fig_xor = plot_data(X, y, "å¼‚æˆ–é—®é¢˜æ•°æ®åˆ†å¸ƒ")
        st.pyplot(fig_xor)

    # è®°å½•æ•°æ®ç”Ÿæˆæ“ä½œ
    st.session_state.nn_records["multi_layer_nn_section"].append({
        "hidden_units":hidden_units,
        "activation":activation,
        "max_iter":max_iter,
        "learning_rate":learning_rate,
        "timestamp": datetime.now().timestamp()
    })
        
    if st.button("è®­ç»ƒç¥ç»ç½‘ç»œè§£å†³å¼‚æˆ–é—®é¢˜"):
        # è®­ç»ƒç¥ç»ç½‘ç»œ
        model = MLPClassifier(
            hidden_layer_sizes=(hidden_units,),
            activation=activation,
            learning_rate_init=learning_rate,
            max_iter=max_iter,
            random_state=42,
            solver='sgd',
            verbose=False)
            
        model.fit(X, y)
            
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        y_pred = model.predict(X)
        accuracy = accuracy_score(y, y_pred)
        st.success(f"è®­ç»ƒå®Œæˆï¼å‡†ç¡®ç‡: {accuracy:.4f}")
        col1, col2, col3 = st.columns([1,4,1])
        with col2:             
            # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
            fig_db = plot_decision_boundary(X, y, model, f"ç¥ç»ç½‘ç»œå†³ç­–è¾¹ç•Œ (å‡†ç¡®ç‡: {accuracy:.4f})")
            if fig_db: st.pyplot(fig_db)
                
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        history = {
            'loss': model.loss_curve_,
            'accuracy': [accuracy_score(y, model.predict(X))] * len(model.loss_curve_)
            }
        fig_train = plot_training_curve(history, "ç¥ç»ç½‘ç»œè®­ç»ƒæ›²çº¿")
        st.pyplot(fig_train)
        
    
    return "å¤šå±‚ç¥ç»ç½‘ç»œæ¨¡å—: æ¼”ç¤ºäº†å¤šå±‚ç½‘ç»œè§£å†³å¼‚æˆ–é—®é¢˜"

# æ¿€æ´»å‡½æ•°æ¨¡å—
def activation_functions_section():
    st.header("âš¡ æ¿€æ´»å‡½æ•°çš„ä½œç”¨ä¸é€‰æ‹©")
    
    st.info("""
    **æ¿€æ´»å‡½æ•°çš„é‡è¦æ€§:**
    æ¿€æ´»å‡½æ•°ä¸ºç¥ç»ç½‘ç»œå¼•å…¥éçº¿æ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„æ¨¡å¼å’Œå…³ç³»ï¼š
    - æ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œæ— è®ºå¤šå°‘å±‚çš„ç¥ç»ç½‘ç»œéƒ½åªèƒ½è¡¨ç¤ºçº¿æ€§å…³ç³»
    - æ¿€æ´»å‡½æ•°å†³å®šç¥ç»å…ƒæ˜¯å¦è¢«"æ¿€æ´»"ï¼ˆè¾“å‡ºä¿¡å·å¼ºåº¦ï¼‰
    - ä¸åŒçš„æ¿€æ´»å‡½æ•°é€‚ç”¨äºä¸åŒçš„åœºæ™¯å’Œç½‘ç»œç»“æ„
    """)
    
    # æ˜¾ç¤ºæ¿€æ´»å‡½æ•°å›¾åƒ
    fig_activation = plot_activation_functions()
    st.pyplot(fig_activation)
    
    # æ¿€æ´»å‡½æ•°å¯¹æ¯”è¡¨æ ¼
    st.subheader("å¸¸ç”¨æ¿€æ´»å‡½æ•°å¯¹æ¯”")
    activation_data = {
        "æ¿€æ´»å‡½æ•°": ["Sigmoid", "Tanh", "ReLU", "Leaky ReLU"],
        "å€¼åŸŸ": ["(0, 1)", "(-1, 1)", "[0, âˆ)", "(-âˆ, âˆ)"],
        "ä¼˜ç‚¹": [
            "è¾“å‡ºåœ¨0-1ä¹‹é—´ï¼Œå¯è¡¨ç¤ºæ¦‚ç‡",
            "å‡å€¼ä¸º0ï¼Œè®­ç»ƒæ›´ç¨³å®š",
            "è®¡ç®—ç®€å•ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±",
            "è§£å†³ReLUçš„æ­»äº¡ç¥ç»å…ƒé—®é¢˜"
        ],
        "ç¼ºç‚¹": [
            "æ¢¯åº¦æ¶ˆå¤±ï¼Œè®¡ç®—æˆæœ¬é«˜",
            "ä»å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜",
            "å­˜åœ¨æ­»äº¡ç¥ç»å…ƒé—®é¢˜",
            "å¢åŠ äº†ä¸€ä¸ªè¶…å‚æ•°"
        ],
        "é€‚ç”¨åœºæ™¯": [
            "äºŒåˆ†ç±»è¾“å‡ºå±‚",
            "éšè—å±‚",
            "éšè—å±‚ï¼ˆæœ€å¸¸ç”¨ï¼‰",
            "éšè—å±‚ï¼ˆæ›¿ä»£ReLUï¼‰"
        ]
    }
    activation_df = pd.DataFrame(activation_data)
    st.dataframe(activation_df)
    
    # æ¿€æ´»å‡½æ•°å¯¹è®­ç»ƒçš„å½±å“æ¼”ç¤º
    st.subheader("æ¿€æ´»å‡½æ•°å¯¹ç¥ç»ç½‘ç»œè®­ç»ƒçš„å½±å“")
    
    # ç”Ÿæˆéçº¿æ€§åˆ†ç±»æ•°æ®
    X, y, problem_type = generate_data("éçº¿æ€§åˆ†ç±»", n_samples=150)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # é€‰æ‹©æ¿€æ´»å‡½æ•°è¿›è¡Œæ¯”è¾ƒ
    activation1 = st.selectbox("æ¿€æ´»å‡½æ•° 1", ["relu", "tanh", "logistic"], key="a1")
    activation2 = st.selectbox("æ¿€æ´»å‡½æ•° 2", ["tanh", "relu", "logistic"], key="a2")

    # è®°å½•æ•°æ®ç”Ÿæˆæ“ä½œ
    st.session_state.nn_records["activation_functions_section"].append({
        "activation1":activation1,
        "activation2":activation2,
        "timestamp": datetime.now().timestamp()
    })
    
    if st.button("æ¯”è¾ƒæ¿€æ´»å‡½æ•°æ•ˆæœ"):
        # è®­ç»ƒä¸¤ä¸ªä¸åŒæ¿€æ´»å‡½æ•°çš„ç½‘ç»œ
        models = []
        histories = []
        
        for activation in [activation1, activation2]:
            model = MLPClassifier(
                hidden_layer_sizes=(10,),
                activation=activation,
                max_iter=1000,
                random_state=42,
                solver='adam'
            )
            model.fit(X_train, y_train)
            models.append(model)
            
            # è®¡ç®—è®­ç»ƒå’Œæµ‹è¯•å‡†ç¡®ç‡
            train_acc = accuracy_score(y_train, model.predict(X_train))
            test_acc = accuracy_score(y_test, model.predict(X_test))
            
            histories.append({
                'loss': model.loss_curve_,
                'accuracy': [train_acc] * len(model.loss_curve_),
                'val_accuracy': [test_acc] * len(model.loss_curve_)
            })
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¯¹æ¯”
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(histories[0]['loss'], label=f'{activation1} æŸå¤±')
        ax1.plot(histories[1]['loss'], label=f'{activation2} æŸå¤±')
        ax1.set_title('æŸå¤±æ›²çº¿å¯¹æ¯”',fontsize=18)
        ax1.set_xlabel('è¿­ä»£æ¬¡æ•°')
        ax1.set_ylabel('æŸå¤±å€¼')
        ax1.legend()
        ax1.grid(True)
        
        # å‡†ç¡®ç‡æ›²çº¿
        ax2.plot(histories[0]['accuracy'], label=f'{activation1} è®­ç»ƒå‡†ç¡®ç‡')
        ax2.plot(histories[0]['val_accuracy'], label=f'{activation1} æµ‹è¯•å‡†ç¡®ç‡')
        ax2.plot(histories[1]['accuracy'], label=f'{activation2} è®­ç»ƒå‡†ç¡®ç‡')
        ax2.plot(histories[1]['val_accuracy'], label=f'{activation2} æµ‹è¯•å‡†ç¡®ç‡')
        ax2.set_title('å‡†ç¡®ç‡æ›²çº¿å¯¹æ¯”',fontsize=18)
        ax2.set_xlabel('è¿­ä»£æ¬¡æ•°')
        ax2.set_ylabel('å‡†ç¡®ç‡')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # æ˜¾ç¤ºå†³ç­–è¾¹ç•Œå¯¹æ¯”
        fig_db, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # ç»˜åˆ¶å†³ç­–è¾¹ç•Œçš„è¾…åŠ©å‡½æ•°
        def plot_db(model, ax, title):
            h = 0.02
            x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
            y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                                np.arange(y_min, y_max, h))
            
            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
            Z = Z.reshape(xx.shape)
            
            cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])
            cmap_bold = ListedColormap(['#FF0000', '#00FF00'])
            
            ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.3)
            ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, alpha=0.7, edgecolor="k")
            ax.set_title(title,fontsize=18)
            ax.grid(True, linestyle='--', alpha=0.7)
        
        plot_db(models[0], ax1, f'{activation1} å†³ç­–è¾¹ç•Œ (å‡†ç¡®ç‡: {histories[0]["val_accuracy"][0]:.4f})')
        plot_db(models[1], ax2, f'{activation2} å†³ç­–è¾¹ç•Œ (å‡†ç¡®ç‡: {histories[1]["val_accuracy"][0]:.4f})')
        
        plt.tight_layout()
        st.pyplot(fig_db)
        
   
    return "æ¿€æ´»å‡½æ•°æ¨¡å—: æ¯”è¾ƒäº†ä¸åŒæ¿€æ´»å‡½æ•°çš„æ•ˆæœ"

# ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜æ¨¡å—
def nn_parameter_tuning_section():
    st.header("ğŸ›ï¸ ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜")
    
    st.markdown("""
    **ç¥ç»ç½‘ç»œçš„å…³é”®å‚æ•°:**
    ç¥ç»ç½‘ç»œçš„æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºå‚æ•°è®¾ç½®ï¼Œä¸»è¦åŒ…æ‹¬ï¼šğŸ¯ """)
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
    1. âš¡ **ç½‘ç»œç»“æ„**:
       - éšè—å±‚æ•°é‡
       - æ¯å±‚ç¥ç»å…ƒæ•°é‡""")
        st.info("""
    2. âš¡ **è®­ç»ƒå‚æ•°**:
       - å­¦ä¹ ç‡
       - è¿­ä»£æ¬¡æ•°
       - æ‰¹å¤§å°
       - æ­£åˆ™åŒ–å‚æ•°""")
    with col2:
        st.info("""
    3. âš¡ **ä¼˜åŒ–å™¨é€‰æ‹©**:
       - SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰
       - Adam
       - RMSprop
       - Adagrad
    """)
    
    # åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†
    digits = load_digits()
    X, y = digits.data, digits.target
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    st.subheader("ğŸƒ å‚æ•°è°ƒä¼˜å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“")
    st.markdown("ä½¿ç”¨æ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡æ¼”ç¤ºå‚æ•°è°ƒä¼˜çš„å½±å“ï¼š")
    
    # æ˜¾ç¤ºç¤ºä¾‹æ•°å­—
    st.subheader("ç¤ºä¾‹æ•°æ®")
    fig, axes = plt.subplots(1, 5, figsize=(10, 2))
    for i, ax in enumerate(axes):
        ax.imshow(digits.images[i], cmap=plt.cm.gray_r)
        ax.set_title(f'æ ‡ç­¾: {digits.target[i]}')
        ax.axis('off')
    st.pyplot(fig)
    
    # å‚æ•°è®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        hidden_layers = st.slider("éšè—å±‚æ•°é‡", 1, 3, 1)
        neurons_per_layer = st.slider("æ¯å±‚ç¥ç»å…ƒæ•°é‡", 10, 100, 30, step=10)
        
        # æ ¹æ®éšè—å±‚æ•°é‡æ„å»ºç½‘ç»œç»“æ„
        hidden_layer_sizes = tuple([neurons_per_layer] * hidden_layers)
        
        learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.1, 0.01)
        regularization = st.slider("L2æ­£åˆ™åŒ–ç³»æ•°", 0.01, 0.1, 0.01)
        solver = st.selectbox("ä¼˜åŒ–å™¨", ["sgd", "adam", "lbfgs", "rmsprop"])
        
         
    with col2:
        st.subheader("å‚æ•°è°ƒä¼˜å»ºè®®")
        st.markdown("""
        **ç½‘ç»œç»“æ„:**
        - éšè—å±‚æ•°é‡: ç®€å•é—®é¢˜1-2å±‚ï¼Œå¤æ‚é—®é¢˜3-5å±‚
        - ç¥ç»å…ƒæ•°é‡: è¾“å…¥ç‰¹å¾å¤šåˆ™é€‚å½“å¢åŠ ï¼Œé¿å…è¿‡å¤šå¯¼è‡´è¿‡æ‹Ÿåˆ
        
        **å­¦ä¹ ç‡:**
        - è¿‡å°: æ”¶æ•›æ…¢ï¼Œéœ€è¦æ›´å¤šè¿­ä»£
        - è¿‡å¤§: å¯èƒ½è·³è¿‡æœ€ä¼˜è§£ï¼Œè®­ç»ƒä¸ç¨³å®š
        - é€šå¸¸åœ¨0.001-0.1ä¹‹é—´
        
        **æ­£åˆ™åŒ–:**
        - ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
        - ç³»æ•°è¿‡å¤§ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆ
        - é€šå¸¸åœ¨0.0001-0.1ä¹‹é—´
        
        **ä¼˜åŒ–å™¨é€‰æ‹©:**
        - SGD: åŸºç¡€ä¼˜åŒ–å™¨ï¼Œå¯é…åˆåŠ¨é‡
        - Adam: è‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹è¡¨ç°è‰¯å¥½
        - RMSprop: åœ¨é€’å½’ç¥ç»ç½‘ç»œä¸­è¡¨ç°è¾ƒå¥½
        """)

    # è®°å½•æ•°æ®ç”Ÿæˆæ“ä½œ
    st.session_state.nn_records["nn_parameter_tuning_section"].append({
        "hidden_layer_sizes":hidden_layer_sizes,
        "neurons_per_layer":neurons_per_layer,
        "regularization":regularization,
        "learning_rate":learning_rate,
        "solver":solver,
        "timestamp": datetime.now().timestamp()
    })
        
    if st.button("è®­ç»ƒç¥ç»ç½‘ç»œ"):
        # è®­ç»ƒç¥ç»ç½‘ç»œ
        model = MLPClassifier(
            hidden_layer_sizes=hidden_layer_sizes,
            activation='relu',
            solver=solver,
            learning_rate_init=learning_rate,
            alpha=regularization,
            max_iter=500,
            random_state=42,
            early_stopping=True,
            validation_fraction=0.2
        )
            
        with st.spinner("æ¨¡å‹è®­ç»ƒä¸­..."):
            model.fit(X_train_scaled, y_train)
            
        # è¯„ä¼°æ¨¡å‹
        train_acc = accuracy_score(y_train, model.predict(X_train_scaled))
        test_acc = accuracy_score(y_test, model.predict(X_test_scaled))
            
        st.success(f"è®­ç»ƒå®Œæˆï¼è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
            
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        history = {
            'loss': model.loss_curve_,
            'val_loss': model.validation_scores_,
            'accuracy': [train_acc] * len(model.loss_curve_),
            'val_accuracy': [test_acc] * len(model.loss_curve_)
        }
        fig_train = plot_training_curve(history, "ç¥ç»ç½‘ç»œè®­ç»ƒæ›²çº¿")
        st.pyplot(fig_train)
            
        # æ˜¾ç¤ºé”™è¯¯åˆ†ç±»çš„ä¾‹å­
        y_pred = model.predict(X_test_scaled)
        misclassified = X_test[y_pred != y_test]
        true_labels = y_test[y_pred != y_test]
        pred_labels = y_pred[y_pred != y_test]
            
        if len(misclassified) > 0:
            st.subheader("é”™è¯¯åˆ†ç±»çš„ç¤ºä¾‹")
            fig_mis, axes = plt.subplots(1, min(5, len(misclassified)), figsize=(10, 2))
            for i, ax in enumerate(axes):
                ax.imshow(misclassified[i].reshape(8, 8), cmap=plt.cm.gray_r)
                ax.set_title(f'çœŸå®: {true_labels[i]}, é¢„æµ‹: {pred_labels[i]}')
                ax.axis('off')
            st.pyplot(fig_mis)    
    return "ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜æ¨¡å—: æ¼”ç¤ºäº†å‚æ•°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“"

# æ¦‚å¿µæµ‹éªŒæ¨¡å—
def quiz_section():
    st.header("ğŸ¯ ç¥ç»ç½‘ç»œæ¦‚å¿µæµ‹éªŒ")
    st.write("è¯·å®Œæˆä»¥ä¸‹5é“å•é€‰é¢˜ï¼Œå…¨éƒ¨ç­”å®Œåå¯æäº¤æŸ¥çœ‹ç»“æœ")
    
    # å®šä¹‰ç¥ç»ç½‘ç»œæµ‹éªŒé¢˜ç›®ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆåŠè§£æ
    quiz_data = [
        {
            "question": "1. ç¥ç»ç½‘ç»œä¸­æ¿€æ´»å‡½æ•°çš„æ ¸å¿ƒä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
            "options": [
                "A. åŠ é€Ÿæ•°æ®å½’ä¸€åŒ–è¿‡ç¨‹",
                "B. å¼•å…¥éçº¿æ€§ï¼Œè®©ç½‘ç»œèƒ½æ‹Ÿåˆå¤æ‚æ¨¡å¼",
                "C. å‡å°‘æ¨¡å‹çš„å‚æ•°æ•°é‡",
                "D. æå‡æ•°æ®çš„ç»´åº¦"
            ],
            "correct": "B",
            "explanation": "æ¿€æ´»å‡½æ•°çš„æ ¸å¿ƒæ˜¯å¼•å…¥éçº¿æ€§å˜æ¢ï¼Œè‹¥æ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œå¤šå±‚ç¥ç»ç½‘ç»œé€€åŒ–ä¸ºçº¿æ€§æ¨¡å‹ï¼Œæ— æ³•æ‹Ÿåˆå¤æ‚çš„éçº¿æ€§å…³ç³»ã€‚"
        },
        {
            "question": "2. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰çš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "options": [
                "A. åˆå§‹åŒ–ç¥ç»ç½‘ç»œçš„æƒé‡å‚æ•°",
                "B. è®¡ç®—æŸå¤±å‡½æ•°å¯¹å„å‚æ•°çš„æ¢¯åº¦ï¼Œç”¨äºæ›´æ–°æƒé‡",
                "C. å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç‰¹å¾æå–",
                "D. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"
            ],
            "correct": "B",
            "explanation": "åå‘ä¼ æ’­é€šè¿‡é“¾å¼æ³•åˆ™ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚åå‘è®¡ç®—æŸå¤±å‡½æ•°å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œæ˜¯æ¢¯åº¦ä¸‹é™ä¼˜åŒ–æ¨¡å‹çš„æ ¸å¿ƒæ­¥éª¤ã€‚"
        },
        {
            "question": "3. ä»¥ä¸‹å“ªç§æ–¹æ³•ä¸èƒ½ç¼“è§£ç¥ç»ç½‘ç»œçš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Ÿ",
            "options": [
                "A. æ—©åœæ³•ï¼ˆEarly Stoppingï¼‰",
                "B. å¢åŠ è®­ç»ƒæ•°æ®é‡",
                "C. å‡å°‘ç½‘ç»œçš„éšè—å±‚ç¥ç»å…ƒæ•°é‡",
                "D. å¢å¤§å­¦ä¹ ç‡"
            ],
            "correct": "D",
            "explanation": "å¢å¤§å­¦ä¹ ç‡å¯èƒ½å¯¼è‡´æ¨¡å‹ä¸æ”¶æ•›æˆ–éœ‡è¡ï¼Œæ— æ³•ç¼“è§£è¿‡æ‹Ÿåˆï¼›æ—©åœæ³•ã€å¢åŠ æ•°æ®ã€ç®€åŒ–ç½‘ç»œç»“æ„éƒ½æ˜¯å¸¸è§çš„è¿‡æ‹Ÿåˆç¼“è§£ç­–ç•¥ã€‚"
        },
        {
            "question": "4. å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ˆFCNï¼‰ä¸­ï¼Œç›¸é‚»ä¸¤å±‚ç¥ç»å…ƒçš„è¿æ¥æ–¹å¼æ˜¯ï¼Ÿ",
            "options": [
                "A. æ¯ä¸ªç¥ç»å…ƒåªè¿æ¥ä¸‹ä¸€å±‚çš„ä¸€ä¸ªç¥ç»å…ƒ",
                "B. æ¯ä¸ªç¥ç»å…ƒè¿æ¥ä¸‹ä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒ",
                "C. ç¥ç»å…ƒéšæœºè¿æ¥ä¸‹ä¸€å±‚çš„éƒ¨åˆ†ç¥ç»å…ƒ",
                "D. åŒå±‚ç¥ç»å…ƒäº’ç›¸è¿æ¥"
            ],
            "correct": "B",
            "explanation": "å…¨è¿æ¥å±‚çš„æ ¸å¿ƒç‰¹å¾æ˜¯ï¼šä¸Šä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒä¸ä¸‹ä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½æœ‰æƒé‡è¿æ¥ï¼Œå› æ­¤å‚æ•°æ•°é‡é€šå¸¸è¾ƒå¤šã€‚"
        },
        {
            "question": "5. æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­ï¼Œå­¦ä¹ ç‡ï¼ˆLearning Rateï¼‰è¿‡å¤§ä¼šå¯¼è‡´ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
            "options": [
                "A. æ¨¡å‹è®­ç»ƒé€Ÿåº¦è¿‡æ…¢",
                "B. æ¨¡å‹å¯èƒ½è¶Šè¿‡æœ€ä¼˜è§£ï¼Œæ— æ³•æ”¶æ•›",
                "C. æ¨¡å‹æ³›åŒ–èƒ½åŠ›å¢å¼º",
                "D. æ¢¯åº¦è®¡ç®—é”™è¯¯"
            ],
            "correct": "B",
            "explanation": "å­¦ä¹ ç‡è¿‡å¤§æ—¶ï¼Œå‚æ•°æ›´æ–°æ­¥é•¿å¤ªå¤§ï¼Œå¯èƒ½åœ¨æœ€ä¼˜è§£é™„è¿‘éœ‡è¡ç”šè‡³è¶Šè¿‡æœ€ä¼˜è§£ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æ”¶æ•›ï¼›å­¦ä¹ ç‡è¿‡å°åˆ™è®­ç»ƒé€Ÿåº¦æ…¢ã€‚"
        }
    ]
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å­˜å‚¨ç”¨æˆ·ç­”æ¡ˆ
    if "nn_user_answers" not in st.session_state:
        st.session_state.nn_user_answers = [None] * len(quiz_data)
    
    # åˆå§‹åŒ–æµ‹éªŒè®°å½•ï¼ˆè‹¥æœªå­˜åœ¨ï¼‰
    if "nn_records" not in st.session_state:
        st.session_state.nn_records = {}
    
    # æ˜¾ç¤ºæ‰€æœ‰é¢˜ç›®å’Œé€‰é¡¹ï¼ˆåˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼‰
    for i, item in enumerate(quiz_data):
        st.markdown(f"**{item['question']}**")
        # è®¾ç½®é»˜è®¤å€¼ä¸ºNoneå®ç°åˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼Œé€šè¿‡ä¼šè¯çŠ¶æ€ä¿å­˜ç­”æ¡ˆ
        answer = st.radio(
            "é€‰æ‹©ç­”æ¡ˆ:",
            item["options"],
            key=f"nn_quiz_{i}",
            index=None,  # å…³é”®ï¼šåˆå§‹æ— é€‰ä¸­é¡¹
            label_visibility="collapsed"
        )
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„ç­”æ¡ˆï¼ˆæå–é€‰é¡¹å­—æ¯A/B/C/Dï¼‰
        if answer is not None:
            st.session_state.nn_user_answers[i] = answer[0]
        
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢˜ç›®éƒ½å·²ä½œç­”
    all_answered = all(ans is not None for ans in st.session_state.nn_user_answers)
    
    # æäº¤æŒ‰é’®ï¼šåªæœ‰å…¨éƒ¨ç­”å®Œæ‰å¯ç”¨
    submit_btn = st.button(
        "æäº¤ç­”æ¡ˆ", 
        key="submit_nn_quiz",
        disabled=not all_answered  # æœªç­”å®Œæ—¶ç¦ç”¨
    )
    
    # æœªç­”å®Œæ—¶æ˜¾ç¤ºæç¤º
    if not all_answered:
        st.info("è¯·å®Œæˆæ‰€æœ‰5é“é¢˜ç›®åå†æäº¤")
    
    # å¤„ç†æäº¤
    if submit_btn and all_answered:
        # è®¡ç®—å¾—åˆ†å’Œé”™è¯¯é¢˜ç›®ï¼ˆæ¯é¢˜20åˆ†ï¼‰
        score = 0
        results = []
        incorrect_questions = []
        for i, item in enumerate(quiz_data):
            is_correct = st.session_state.nn_user_answers[i] == item["correct"]
            if is_correct:
                score += 20  # æ¯é¢˜20åˆ†ï¼Œæ€»åˆ†100
            else:
                incorrect_questions.append({
                    "topic": item["question"], 
                    "user_answer": st.session_state.nn_user_answers[i]
                })

            results.append({
                "question": item["question"],
                "user_answer": st.session_state.nn_user_answers[i],
                "correct_answer": item["correct"],
                "is_correct": is_correct,
                "explanation": item["explanation"]
            })
            
        # è®°å½•æµ‹éªŒç»“æœåˆ°ä¼šè¯çŠ¶æ€
        st.session_state.nn_records["ANN_quiz"] = {
            "score": score,
            "incorrect_questions": incorrect_questions,
            "timestamp": datetime.now().timestamp()
        }
       
        # æ˜¾ç¤ºå¾—åˆ†
        st.success(f"ğŸ“Š æµ‹éªŒå®Œæˆï¼ä½ çš„å¾—åˆ†æ˜¯ï¼š{score}åˆ†")
        st.write("### ç­”æ¡ˆè§£æï¼š")
        
        # å±•å¼€å¼æ˜¾ç¤ºæ¯é¢˜ç»“æœ
        for res in results:
            # ä½¿ç”¨emojiæ ‡è®°æ­£ç¡®/é”™è¯¯çŠ¶æ€
            status_text = "âœ… æ­£ç¡®" if res["is_correct"] else "âŒ é”™è¯¯"
            
            with st.expander(f"{res['question']} {status_text}"):
                if res["is_correct"]:
                    st.success(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆæ­£ç¡®ï¼‰")
                else:
                    st.error(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆé”™è¯¯ï¼‰")
                    st.info(f"æ­£ç¡®ç­”æ¡ˆï¼š{res['correct_answer']}")
                st.write(f"è§£æï¼š{res['explanation']}")

        # å‡†å¤‡AIåˆ†æçš„è¾“å…¥
        incorrect_topics = [
            res["question"] for res in results if not res["is_correct"]
        ]
        
        analysis_prompt = f"""
        ä»¥ä¸‹æ˜¯å­¦ç”Ÿåœ¨ç¥ç»ç½‘ç»œæµ‹éªŒä¸­çš„ç­”é¢˜æƒ…å†µï¼š
        - æ€»å¾—åˆ†ï¼š{score}åˆ†
        - é”™è¯¯é¢˜ç›®ï¼š{len(incorrect_topics)}é“
        - é”™è¯¯çŸ¥è¯†ç‚¹ï¼š{'; '.join(incorrect_topics) if incorrect_topics else 'æ— '}
        
        è¯·åˆ†æè¯¥å­¦ç”Ÿçš„çŸ¥è¯†æŒæ¡æƒ…å†µï¼ŒæŒ‡å‡ºæœªæŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶ç»™å‡ºå…·ä½“çš„å­¦ä¹ å»ºè®®å’ŒæŒ‡å¯¼æ–¹å‘ï¼Œå¸®åŠ©å­¦ç”Ÿé’ˆå¯¹æ€§æå‡ã€‚
        ç­”æ¡ˆå¿…é¡»æ§åˆ¶åœ¨450å­—ä»¥å†…
        """
        
        # è°ƒç”¨AIåˆ†æï¼ˆå¸¦åŠ è½½çŠ¶æ€ï¼‰
        with st.spinner("AIæ­£åœ¨åˆ†æä½ çš„ç­”é¢˜æƒ…å†µ..."):
            ai_analysis = ask_ai_assistant(analysis_prompt, "ç¥ç»ç½‘ç»œæµ‹éªŒåˆ†æ")
        
        # æ˜¾ç¤ºAIåˆ†æç»“æœ
        st.write("### ğŸ¤– AIå­¦ä¹ è¯Šæ–­ï¼š")
        st.info(ai_analysis)       
  
    return "ç¥ç»ç½‘ç»œæ¦‚å¿µæµ‹éªŒæ¨¡å—ï¼šå®Œæˆ5é¢˜å•é€‰é¢˜æµ‹è¯•"

# ç¥ç»ç½‘ç»œåº”ç”¨æ¡ˆä¾‹æ¨¡å—
def nn_applications_section():
    st.header("ğŸŒ ç¥ç»ç½‘ç»œå®é™…åº”ç”¨æ¡ˆä¾‹")
    
    example = st.selectbox(
        "é€‰æ‹©åº”ç”¨æ¡ˆä¾‹:",
        ["å›¾åƒè¯†åˆ«", "å›å½’é¢„æµ‹", "ä¸Šä¼ è‡ªå·±çš„æ•°æ®"]
    )
    
    if example == "ä¸Šä¼ è‡ªå·±çš„æ•°æ®":
        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file:
            data = pd.read_csv(uploaded_file)
            st.write("æ•°æ®é¢„è§ˆ:", data.head())
            
            # æ£€æŸ¥ç›®æ ‡åˆ—
            target_col = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—", data.columns)
            if target_col:
                X = data.drop(target_col, axis=1)
                y = data[target_col]
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†ç±»é—®é¢˜
                is_classification = len(y.unique()) < 10 or str(y.dtype) == 'object'
                
                # å¤„ç†åˆ†ç±»ç‰¹å¾
                X = pd.get_dummies(X)
                
                # æ ‡å‡†åŒ–æ•°æ®
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # è®­ç»ƒç¥ç»ç½‘ç»œ
                st.subheader("ç¥ç»ç½‘ç»œå‚æ•°")
                layers = st.slider("éšè—å±‚æ•°é‡", 1, 3, 1)
                neurons = st.slider("æ¯å±‚ç¥ç»å…ƒæ•°é‡", 10, 100, 50)
                
                if st.button("è®­ç»ƒæ¨¡å‹"):
                    if is_classification:
                        model = MLPClassifier(
                            hidden_layer_sizes=tuple([neurons]*layers),
                            max_iter=500,
                            random_state=42
                        )
                    else:
                        model = MLPRegressor(
                            hidden_layer_sizes=tuple([neurons]*layers),
                            max_iter=500,
                            random_state=42
                        )
                    
                    model.fit(X_scaled, y)
                    
                    # è¯„ä¼°æ¨¡å‹
                    if is_classification:
                        y_pred = model.predict(X_scaled)
                        accuracy = accuracy_score(y, y_pred)
                        st.success(f"åˆ†ç±»å‡†ç¡®ç‡: {accuracy:.4f}")
                    else:
                        y_pred = model.predict(X_scaled)
                        mse = mean_squared_error(y, y_pred)
                        st.success(f"å‡æ–¹è¯¯å·®: {mse:.4f}")
                    
                    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
                    history = {'loss': model.loss_curve_}
                    if is_classification:
                        history['accuracy'] = [accuracy_score(y, model.predict(X_scaled))] * len(model.loss_curve_)
                    fig = plot_training_curve(history)
                    st.pyplot(fig)
    
    elif example == "å›¾åƒè¯†åˆ«":
        st.markdown("""
        **å›¾åƒè¯†åˆ«åº”ç”¨:**
        ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä»ç®€å•çš„æ•°å­—è¯†åˆ«åˆ°å¤æ‚çš„ç‰©ä½“æ£€æµ‹ï¼š
        - å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ˜¯å›¾åƒè¯†åˆ«çš„é¦–é€‰æ¨¡å‹
        - èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å›¾åƒçš„è¾¹ç¼˜ã€çº¹ç†ç­‰ç‰¹å¾
        - åº”ç”¨åŒ…æ‹¬äººè„¸è¯†åˆ«ã€åŒ»å­¦å½±åƒåˆ†æã€è‡ªåŠ¨é©¾é©¶ç­‰
        """)
        
        # ä½¿ç”¨æ‰‹å†™æ•°å­—æ•°æ®é›†æ¼”ç¤º
        digits = load_digits()
        X, y = digits.data, digits.target
        
        # è®­ç»ƒä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ
        model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
        model.fit(X, y)
        
        # å±•ç¤ºä¸€äº›é¢„æµ‹ç»“æœ
        st.subheader("æ•°å­—è¯†åˆ«ç¤ºä¾‹")
        fig, axes = plt.subplots(2, 5, figsize=(12, 6))
        for i, ax in enumerate(axes.ravel()):
            ax.imshow(digits.images[i], cmap=plt.cm.gray_r)
            pred = model.predict([digits.data[i]])[0]
            ax.set_title(f'é¢„æµ‹: {pred}, çœŸå®: {digits.target[i]}')
            ax.axis('off')
        plt.tight_layout()
        st.pyplot(fig)
        
        st.info("""
        å®é™…åº”ç”¨ä¸­çš„å›¾åƒè¯†åˆ«ç³»ç»Ÿé€šå¸¸ä½¿ç”¨æ›´æ·±çš„å·ç§¯ç¥ç»ç½‘ç»œï¼š
        - LeNet-5: æ—©æœŸçš„æ•°å­—è¯†åˆ«ç½‘ç»œ
        - AlexNet: æ·±åº¦å­¦ä¹ é©å‘½çš„é‡Œç¨‹ç¢‘
        - ResNet: ä½¿ç”¨æ®‹å·®è¿æ¥è§£å†³æ·±å±‚ç½‘ç»œè®­ç»ƒé—®é¢˜
        - YOLO: å®æ—¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ
        """)
    
    elif example == "å›å½’é¢„æµ‹":
        st.markdown("""
        **å›å½’é¢„æµ‹åº”ç”¨:**
        ç¥ç»ç½‘ç»œå¯ä»¥ç”¨äºé¢„æµ‹è¿ç»­å€¼è¾“å‡ºï¼š
        - æˆ¿ä»·é¢„æµ‹
        - è‚¡ç¥¨ä»·æ ¼é¢„æµ‹
        - é”€å”®é¢é¢„æµ‹
        - æ¸©åº¦é¢„æµ‹ç­‰
        """)
        
        # ç”Ÿæˆéçº¿æ€§å›å½’æ•°æ®
        X, y, problem_type = generate_data("å›å½’é—®é¢˜", n_samples=200, noise=0.2)
        X = X.reshape(-1, 1)
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        # è®­ç»ƒç¥ç»ç½‘ç»œ
        model = MLPRegressor(
            hidden_layer_sizes=(50, 30),
            activation='relu',
            max_iter=1000,
            random_state=42
        )
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        X_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
        y_pred = model.predict(X_range)
        
        # ç»˜åˆ¶ç»“æœ
        cols=st.columns([1,4,1])
        with cols[1]:
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(X_train, y_train, alpha=0.5, label='è®­ç»ƒæ•°æ®')
            ax.scatter(X_test, y_test, alpha=0.5, c='red', label='æµ‹è¯•æ•°æ®')
            ax.plot(X_range, y_pred, 'g-', linewidth=2, label='ç¥ç»ç½‘ç»œé¢„æµ‹')
            ax.set_title('ç¥ç»ç½‘ç»œå›å½’é¢„æµ‹')
            ax.set_xlabel('ç‰¹å¾')
            ax.set_ylabel('ç›®æ ‡å€¼')
            ax.legend()
            ax.grid(True)
            st.pyplot(fig)
        
        # è¯„ä¼°æ¨¡å‹
        train_mse = mean_squared_error(y_train, model.predict(X_train))
        test_mse = mean_squared_error(y_test, model.predict(X_test))
        st.write(f"è®­ç»ƒé›†å‡æ–¹è¯¯å·®: {train_mse:.4f}")
        st.write(f"æµ‹è¯•é›†å‡æ–¹è¯¯å·®: {test_mse:.4f}")
        
        st.session_state.nn_records["nn_applications_section"] = {
            "timestamp": datetime.now().timestamp()
        }    
    return f"ç¥ç»ç½‘ç»œåº”ç”¨æ¨¡å—: å±•ç¤ºäº†{example}åº”ç”¨æ¡ˆä¾‹"

# ä¸»ç¨‹åº
def main():

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'section' not in st.session_state:
        st.session_state.section = "ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µ"
        
    # è®°å½•æ¨¡å—è®¿é—®é¡ºåº
    current_section = st.session_state.section
    st.session_state.nn_records["module_sequence"].append(current_section)
    if current_section not in st.session_state.nn_records["module_timestamps"]:
        st.session_state.nn_records["module_timestamps"][current_section] = {
            "enter_time": time.time()
        }
        
    st.sidebar.title("å¯¼èˆªèœå•")
    section = st.sidebar.radio("é€‰æ‹©å­¦ä¹ æ¨¡å—", [
        "ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µ",
        "å¤šå±‚ç¥ç»ç½‘ç»œä¸åå‘ä¼ æ’­",
        "æ¿€æ´»å‡½æ•°çš„ä½œç”¨ä¸é€‰æ‹©",
        "ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜",
        "æ¦‚å¿µæµ‹éªŒ",  
        "ç¥ç»ç½‘ç»œå®é™…åº”ç”¨æ¡ˆä¾‹",
        "ç¼–ç¨‹å®ä¾‹ï¼ˆåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼‰"
    ])
  
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.section = section
    
    
    context = ""
    if section == "ç¥ç»ç½‘ç»œåŸºç¡€æ¦‚å¿µ":
        context = nn_basics_section()
    elif section == "å¤šå±‚ç¥ç»ç½‘ç»œä¸åå‘ä¼ æ’­":
        context = multi_layer_nn_section()
    elif section == "æ¿€æ´»å‡½æ•°çš„ä½œç”¨ä¸é€‰æ‹©":
        context = activation_functions_section()
    elif section == "ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜":
        context = nn_parameter_tuning_section()
    elif section == "æ¦‚å¿µæµ‹éªŒ":  
        context = quiz_section()
    elif section == "ç¥ç»ç½‘ç»œå®é™…åº”ç”¨æ¡ˆä¾‹":
        context = nn_applications_section()
    elif section == "ç¼–ç¨‹å®ä¾‹ï¼ˆåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼‰":
        # åˆå§‹åŒ–stepå˜é‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'step' not in st.session_state:
            st.session_state.step = 0
        neural_network_step_by_step.main()
        context = "ç¼–ç¨‹å®ä¾‹æ¨¡å—: åŠ å·æˆ¿ä»·æ•°æ®é›†ç¥ç»ç½‘ç»œåˆ†æ­¥ç»ƒä¹ "
    
    # æ˜¾ç¤ºèŠå¤©ç•Œé¢
    display_chat_interface(context)
    
    # è®°å½•æ¨¡å—é€€å‡ºæ—¶é—´
    if current_section in st.session_state.nn_records["module_timestamps"]:
        st.session_state.nn_records["module_timestamps"][current_section]["exit_time"] = datetime.now().timestamp()
    
    if section != "ç¼–ç¨‹å®ä¾‹ï¼ˆåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼‰":
        # ä¾§è¾¹æ æ·»åŠ å­¦ä¹ æŠ¥å‘ŠæŒ‰é’®ï¼ˆè°ƒç”¨ç‹¬ç«‹æ¨¡å—ï¼‰
        st.sidebar.markdown("---")
        if st.sidebar.button("ç¥ç»ç½‘ç»œæ¨¡å—å­¦ä¹ æŠ¥å‘Š"):
            report = generate_evaluation(
                module_type="ANN",
                raw_records=st.session_state.nn_records
            )
            st.write("### ç¥ç»ç½‘ç»œæ¨¡å—å­¦ä¹ æƒ…å†µæŠ¥å‘Š")
            st.info(report)
            
    # ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **ç¥ç»ç½‘ç»œäº¤äº’å¼å­¦ä¹ å¹³å°**
    
    è®¾è®¡ç”¨äºæœºå™¨å­¦ä¹ æ•™å­¦ï¼Œå¸®åŠ©å­¦ç”Ÿç†è§£:
    - ç¥ç»ç½‘ç»œçš„åŸºæœ¬åŸç†ä¸ç»“æ„
    - å¤šå±‚ç¥ç»ç½‘ç»œä¸åå‘ä¼ æ’­ç®—æ³•
    - æ¿€æ´»å‡½æ•°çš„ä½œç”¨ä¸é€‰æ‹©
    - ç¥ç»ç½‘ç»œå‚æ•°è°ƒä¼˜æ–¹æ³•
    - ç¥ç»ç½‘ç»œçš„å®é™…åº”ç”¨åœºæ™¯
    """)


if __name__ == "__main__":
    main()
