# C:\Users\å­™å†°\Desktop\AIåŠ©æ•™
# streamlit run C:\Users\å­™å†°\Desktop\AIåŠ©æ•™25-12-07\KMeans_demo.py

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs, make_moons, make_circles
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler
import time
import io
import KMeans_step_by_step
from api_deepseek import ask_ai_assistant
from datetime import datetime
from learning_report import generate_evaluation

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="KMeansèšç±»äº¤äº’å¼å­¦ä¹ å¹³å°", layout="wide")
st.title("ğŸ“Š KMeansèšç±»äº¤äº’å¼å­¦ä¹ å¹³å°")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆåœ¨ä¸»ç¨‹åºå…¥å£å¤„ï¼‰
def init_session_state():
    if "kmeans_records" not in st.session_state:
        st.session_state.kmeans_records = {
            "data_generation": [],  # æ•°æ®ç”Ÿæˆæ¨¡å—è®°å½•
            "kmeans_basics_section": [],  # KMeansåŸºæœ¬åŸç†
            "k_selection_section": [],  # Kå€¼é€‰æ‹©
            "kmeans_limitations_section": [],  # KMeanså±€é™æ€§
            "evaluation_metrics_section": [],  # èšç±»è¯„ä¼°æŒ‡æ ‡
            "real_world_example_section": [], #å®é™…æ¡ˆä¾‹
            "module_sequence": [],  # æ¨¡å—è®¿é—®é¡ºåº
            "module_timestamps": {},  # æ¨¡å—åœç•™æ—¶é—´
            "kmeans_quiz": {},  # æµ‹éªŒè®°å½•
            "ai_interactions": []  # AIäº¤äº’è®°å½•
        }

def display_chat_interface(context=""):
    """æ˜¾ç¤ºèŠå¤©ç•Œé¢"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¬ AIåŠ©æ•™å·²å°±ç»ª")
    
    # é¢„è®¾é—®é¢˜å¿«æ·æŒ‰é’®
    st.sidebar.markdown("**å¿«æ·é—®é¢˜:**")
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        btn1 = st.button("ä»€ä¹ˆæ˜¯KMeansèšç±»?")
        btn2 = st.button("Kå€¼å¦‚ä½•é€‰æ‹©?")
    
    with col2:
        btn3 = st.button("KMeansçš„ä¼˜ç¼ºç‚¹")
        btn4 = st.button("èšç±»ä¸åˆ†ç±»çš„åŒºåˆ«")
    
    # å¤„ç†å¿«æ·é—®é¢˜
    question = ""
    if btn1:
        question = "ä»€ä¹ˆæ˜¯KMeansèšç±»?å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆ?"
    elif btn2:
        question = "KMeansä¸­çš„Kå€¼åº”è¯¥å¦‚ä½•é€‰æ‹©?æœ‰ä»€ä¹ˆæ–¹æ³•?"
    elif btn3:
        question = "KMeansç®—æ³•æœ‰å“ªäº›ä¼˜ç‚¹å’Œç¼ºç‚¹?é€‚ç”¨äºä»€ä¹ˆåœºæ™¯?"
    elif btn4:
        question = "èšç±»å’Œåˆ†ç±»æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«?åˆ†åˆ«é€‚ç”¨äºä»€ä¹ˆæƒ…å†µ?"
    
    # æé—®è¾“å…¥æ¡†
    user_input = st.sidebar.text_input("è¾“å…¥ä½ çš„é—®é¢˜:", key="question_input")
    if user_input:
        question = user_input
    
    # å¤„ç†æé—®
    if question:
        # è®°å½•AIäº¤äº’
        if "ai_interactions" not in st.session_state.kmeans_records:
            st.session_state.kmeans_records["ai_interactions"] = []

        st.session_state.kmeans_records["ai_interactions"].append({
            "question": question,
            "timestamp": datetime.now().timestamp()
        })
        # æ˜¾ç¤ºå½“å‰é—®é¢˜
        st.sidebar.markdown(f"**ä½ :** {question}")
        
        # è·å–å›ç­”
        with st.spinner("åŠ©æ•™æ€è€ƒä¸­..."):
            answer = ask_ai_assistant(question, context)
        
        # æ˜¾ç¤ºå½“å‰å›ç­”
        st.sidebar.markdown(f"**åŠ©æ•™:** {answer}")
        st.sidebar.markdown("---")

# æ•°æ®ç”Ÿæˆå‡½æ•°
def generate_cluster_data(data_type, n_samples, n_centers, cluster_std, noise=0.05):
    """ç”Ÿæˆä¸åŒç±»å‹çš„èšç±»æ•°æ®"""
    np.random.seed(42)
    
    if data_type == "çƒå½¢èšç±»":
        X, y_true = make_blobs(
            n_samples=n_samples,
            centers=n_centers,
            cluster_std=cluster_std,
            random_state=42
        )
    
    elif data_type == "åŠæœˆå½¢èšç±»":
        X = make_moons(n_samples=n_samples, noise=noise, random_state=42)[0]
        y_true = None  # åŠæœˆå½¢æ•°æ®æ²¡æœ‰çœŸå®çš„çƒå½¢èšç±»æ ‡ç­¾
    
    elif data_type == "ç¯å½¢èšç±»":
        X = make_circles(n_samples=n_samples, noise=noise, factor=0.5, random_state=42)[0]
        y_true = None  # ç¯å½¢æ•°æ®æ²¡æœ‰çœŸå®çš„çƒå½¢èšç±»æ ‡ç­¾
    
    elif data_type == "ä¸å‡åŒ€å¯†åº¦èšç±»":
        # ç”Ÿæˆå¯†åº¦ä¸åŒçš„èšç±»
        centers = [(-3, -3), (0, 0), (3, 3)]
        X = []
        y_true = []
        
        # ä¸ºæ¯ä¸ªä¸­å¿ƒç”Ÿæˆä¸åŒæ•°é‡çš„ç‚¹ï¼ˆä¸åŒå¯†åº¦ï¼‰
        sizes = [int(n_samples*0.6), int(n_samples*0.3), int(n_samples*0.1)]
        stds = [0.5, 1.0, 0.8]
        
        for i, (center, size, std) in enumerate(zip(centers, sizes, stds)):
            cluster = np.random.normal(loc=center, scale=std, size=(size, 2))
            X.append(cluster)
            y_true.extend([i]*size)
        
        X = np.vstack(X)
        y_true = np.array(y_true)
        
        # æ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        X = X[indices]
        y_true = y_true[indices]
    
    return X, y_true

# ç»˜åˆ¶èšç±»æ•°æ®
def plot_cluster_data(X, y=None, centers=None, title="èšç±»æ•°æ®åˆ†å¸ƒ"):
    """ç»˜åˆ¶èšç±»æ•°æ®æ•£ç‚¹å›¾"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    if y is not None:
        # å¦‚æœæœ‰æ ‡ç­¾ï¼Œä½¿ç”¨ä¸åŒé¢œè‰²è¡¨ç¤ºä¸åŒç±»åˆ«
        scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.7, s=50)
        ax.legend(*scatter.legend_elements(), title="èšç±»")
    else:
        # æ²¡æœ‰æ ‡ç­¾ï¼Œä½¿ç”¨å•ä¸€é¢œè‰²
        ax.scatter(X[:, 0], X[:, 1], c='blue', alpha=0.7, s=50)
    
    # ç»˜åˆ¶ä¸­å¿ƒç‚¹
    if centers is not None:
        ax.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, label='ä¸­å¿ƒç‚¹')
        ax.legend()
    
    ax.set_xlabel('ç‰¹å¾ 1')
    ax.set_ylabel('ç‰¹å¾ 2')
    ax.set_title(title)
    ax.grid(True, linestyle='--', alpha=0.7)
    return fig

# KMeansç®—æ³•æ­¥éª¤å¯è§†åŒ–
def kmeans_step_visualization(X, n_clusters, max_iter=10):
    """å¯è§†åŒ–KMeansç®—æ³•çš„æ¯ä¸€æ­¥"""
    # åˆå§‹åŒ–ä¸­å¿ƒç‚¹ï¼ˆéšæœºé€‰æ‹©æ ·æœ¬ä½œä¸ºåˆå§‹ä¸­å¿ƒï¼‰
    np.random.seed(42)
    indices = np.random.choice(len(X), n_clusters, replace=False)
    centers = X[indices]
    
    steps = []
    steps.append((centers.copy(), np.zeros(len(X))))  # è®°å½•åˆå§‹çŠ¶æ€
    
    for i in range(max_iter):
        # æ­¥éª¤1: åˆ†é…æ¯ä¸ªç‚¹åˆ°æœ€è¿‘çš„ä¸­å¿ƒ
        distances = np.sqrt(((X - centers[:, np.newaxis])**2).sum(axis=2))
        labels = np.argmin(distances, axis=0)
        
        # è®°å½•å½“å‰æ­¥éª¤
        steps.append((centers.copy(), labels.copy()))
        
        # æ­¥éª¤2: è®¡ç®—æ–°çš„ä¸­å¿ƒç‚¹
        new_centers = np.array([X[labels == k].mean(axis=0) for k in range(n_clusters)])
        
        # å¦‚æœä¸­å¿ƒç‚¹ä¸å†å˜åŒ–ï¼Œæå‰ç»“æŸ
        if np.allclose(centers, new_centers):
            break
            
        centers = new_centers
    
    # è®°å½•æœ€ç»ˆçŠ¶æ€
    distances = np.sqrt(((X - centers[:, np.newaxis])** 2).sum(axis=2))
    labels = np.argmin(distances, axis=0)
    steps.append((centers.copy(), labels.copy()))
    
    return steps

# ç»˜åˆ¶KMeansæ­¥éª¤
def plot_kmeans_steps(X, steps):
    """ç»˜åˆ¶KMeansç®—æ³•çš„æ¯ä¸€æ­¥"""
    figs = []
    
    for i, (centers, labels) in enumerate(steps):
        if i == 0:
            title = f"æ­¥éª¤ {i}: åˆå§‹åŒ–ä¸­å¿ƒç‚¹"
        elif i == len(steps) - 1:
            title = f"æ­¥éª¤ {i}: æ”¶æ•›å®Œæˆ"
        else:
            title = f"æ­¥éª¤ {i}: è¿­ä»£æ›´æ–°"
            
        fig = plot_cluster_data(X, labels, centers, title)
        figs.append(fig)
        
    return figs

# ç»˜åˆ¶ä¸åŒKå€¼çš„èšç±»ç»“æœå¯¹æ¯”
def plot_k_comparison(X, k_values):
    """å¯¹æ¯”ä¸åŒKå€¼çš„èšç±»ç»“æœï¼Œé‡ç‚¹å±•ç¤ºKå€¼ä¸æƒ¯æ€§å€¼çš„å…³ç³»åŠæƒ¯æ€§çš„æ„ä¹‰"""
    n_k = len(k_values)
    fig, axes = plt.subplots(1, n_k, figsize=(5*n_k, 5))
    # å­˜å‚¨æ¯ä¸ªKå€¼å¯¹åº”çš„æƒ¯æ€§å€¼ï¼Œç”¨äºåç»­è§„å¾‹å±•ç¤º
    inertias = []
    
    if n_k == 1:
        axes = [axes]
    
    for i, k in enumerate(k_values):
        kmeans = KMeans(n_clusters=k, random_state=42)
        labels = kmeans.fit_predict(X)
        centers = kmeans.cluster_centers_
        inertia = kmeans.inertia_
        inertias.append(inertia)
        
        # ç»˜åˆ¶æ ·æœ¬ç‚¹å’Œèšç±»ä¸­å¿ƒ
        axes[i].scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.7, s=50)
        axes[i].scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200)
        # æ ‡é¢˜çªå‡ºKå€¼å’Œæƒ¯æ€§å€¼ï¼Œå­—ä½“åŠ ç²—æ›´é†’ç›®
        axes[i].set_title(f'K={k}, æƒ¯æ€§={inertia:.2f}', fontsize=22, fontweight='bold')
        axes[i].grid(True, linestyle='--', alpha=0.7)
    
    plt.tight_layout()
    # è°ƒæ•´å¸ƒå±€ï¼Œé¿å…åº•éƒ¨æ–‡å­—è¢«é®æŒ¡
    plt.subplots_adjust(bottom=0.15)
    return fig

# ç»˜åˆ¶è‚˜éƒ¨æ³•åˆ™å›¾è¡¨
def plot_elbow_method(X, max_k=10):
    """ç»˜åˆ¶è‚˜éƒ¨æ³•åˆ™å›¾è¡¨å¸®åŠ©é€‰æ‹©Kå€¼"""
    inertias = []
    k_range = range(1, max_k+1)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(X)
        inertias.append(kmeans.inertia_)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(k_range, inertias, 'bo-')
    ax.set_xlabel('Kå€¼ (èšç±»æ•°é‡)')
    ax.set_ylabel('æƒ¯æ€§ (Inertia)')
    ax.set_title('è‚˜éƒ¨æ³•åˆ™ (Elbow Method)')
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # æ ‡è®°å¯èƒ½çš„æœ€ä½³Kå€¼ç‚¹
    if max_k >= 3:
        ax.annotate('å¯èƒ½çš„æœ€ä½³Kå€¼', xy=(3, inertias[2]+200), 
                    xytext=(4, inertias[2]+1600),
                    fontsize=16,
                    arrowprops=dict(facecolor='red', shrink=0.05))
    return fig

# ç»˜åˆ¶è½®å»“ç³»æ•°å›¾è¡¨
def plot_silhouette_method(X, max_k=10):
    """ç»˜åˆ¶è½®å»“ç³»æ•°å›¾è¡¨å¸®åŠ©é€‰æ‹©Kå€¼"""
    silhouette_scores = []
    k_range = range(2, max_k+1)  # è½®å»“ç³»æ•°ä¸é€‚ç”¨äºk=1
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        labels = kmeans.fit_predict(X)
        silhouette_avg = silhouette_score(X, labels)
        silhouette_scores.append(silhouette_avg)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(k_range, silhouette_scores, 'go-')
    ax.set_xlabel('Kå€¼ (èšç±»æ•°é‡)')
    ax.set_ylabel('å¹³å‡è½®å»“ç³»æ•°')
    ax.set_title('è½®å»“ç³»æ•°æ³• (Silhouette Method)')
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # æ ‡è®°æœ€ä½³Kå€¼ç‚¹
    best_k = k_range[np.argmax(silhouette_scores)]
    ax.annotate(f'æœ€ä½³Kå€¼={best_k}', fontsize=16,
               xy=(best_k, max(silhouette_scores)), 
               xytext=(best_k+1, max(silhouette_scores)-0.08),
               arrowprops=dict(facecolor='red', shrink=0.05))
    
    return fig

# æ•°æ®ç”Ÿæˆä¸æ¢ç´¢æ¨¡å—
def data_generation_section():
    st.header("ğŸ“Š èšç±»æ•°æ®ç”Ÿæˆä¸æ¢ç´¢")
    
    col1, col2 = st.columns(2)
    
    with col1:
        data_type = st.selectbox("é€‰æ‹©æ•°æ®ç±»å‹", 
                               ["çƒå½¢èšç±»", "åŠæœˆå½¢èšç±»", "ç¯å½¢èšç±»", "ä¸å‡åŒ€å¯†åº¦èšç±»"])
        n_samples = st.slider("æ ·æœ¬æ•°é‡", 100, 1000, 300)
        
        # æ ¹æ®æ•°æ®ç±»å‹æ˜¾ç¤ºä¸åŒçš„å‚æ•°
        if data_type == "çƒå½¢èšç±»":
            n_centers = st.slider("èšç±»ä¸­å¿ƒæ•°é‡", 2, 6, 3)
            cluster_std = st.slider("èšç±»æ ‡å‡†å·®ï¼ˆç¦»æ•£ç¨‹åº¦ï¼‰", 0.3, 2.0, 0.8, 0.1)
            noise = 0.05
        elif data_type in ["åŠæœˆå½¢èšç±»", "ç¯å½¢èšç±»"]:
            n_centers = 2  # è¿™äº›ç±»å‹æ•°æ®å›ºå®šä¸º2ä¸ªèšç±»
            cluster_std = 0.8
            noise = st.slider("å™ªå£°æ°´å¹³", 0.01, 0.3, 0.05, 0.01)
        else:  # ä¸å‡åŒ€å¯†åº¦èšç±»
            n_centers = 3  # å›ºå®šä¸º3ä¸ªèšç±»
            cluster_std = 0.8
            noise = 0.05
        
        X, y_true = generate_cluster_data(data_type, n_samples, n_centers, cluster_std, noise)
        
        st.write(f"æ•°æ®ç»Ÿè®¡:")
        st.write(f"- æ ·æœ¬æ•°é‡: {X.shape[0]}")
        st.write(f"- ç‰¹å¾æ•°é‡: {X.shape[1]}")
        st.write(f"- ç‰¹å¾1å‡å€¼: {np.mean(X[:, 0]):.2f}, æ ‡å‡†å·®: {np.std(X[:, 0]):.2f}")
        st.write(f"- ç‰¹å¾2å‡å€¼: {np.mean(X[:, 1]):.2f}, æ ‡å‡†å·®: {np.std(X[:, 1]):.2f}")
    
    with col2:
        # æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼ˆä¸å¸¦èšç±»æ ‡ç­¾ï¼‰
        fig_raw = plot_cluster_data(X, title=f'{data_type}åŸå§‹æ•°æ®åˆ†å¸ƒ')
        st.pyplot(fig_raw)
        
        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œæ˜¾ç¤ºå¸¦æœ‰æ ‡ç­¾çš„æ•°æ®
        if y_true is not None and data_type != "åŠæœˆå½¢èšç±»" and data_type != "ç¯å½¢èšç±»":
            fig_labeled = plot_cluster_data(X, y_true, title=f'{data_type}çœŸå®èšç±»åˆ†å¸ƒ')
            st.pyplot(fig_labeled)

    # è®°å½•æ•°æ®ç”Ÿæˆæ“ä½œ
    st.session_state.kmeans_records["data_generation"].append({
        "data_type": data_type,
        "timestamp": datetime.now().timestamp()
    })
    
    st.info("""
    **èšç±»æ•°æ®ç‰¹ç‚¹:**
    - çƒå½¢èšç±»: æ•°æ®è‡ªç„¶å½¢æˆçƒå½¢ç°‡ï¼Œé€‚åˆKMeansç®—æ³•
    - åŠæœˆå½¢/ç¯å½¢èšç±»: éå‡¸å½¢çŠ¶çš„èšç±»ï¼ŒKMeansæ•ˆæœè¾ƒå·®
    - ä¸å‡åŒ€å¯†åº¦èšç±»: ä¸åŒç°‡çš„å¯†åº¦å·®å¼‚å¤§ï¼Œå¯¹KMeansæ˜¯æŒ‘æˆ˜
    
    KMeansç®—æ³•å¯¹çƒå½¢ã€å¯†åº¦ç›¸è¿‘çš„èšç±»æ•ˆæœæœ€å¥½ã€‚
    """)
    
    # å­˜å‚¨æ•°æ®ä¾›åç»­æ¨¡å—ä½¿ç”¨
    st.session_state.X = X
    st.session_state.data_type = data_type
    
    return f"æ•°æ®ç”Ÿæˆæ¨¡å—: åˆ›å»ºäº†{data_type}æ•°æ®ï¼Œæ ·æœ¬æ•°={n_samples}"

# KMeansåŸºæœ¬åŸç†æ¨¡å—
def kmeans_basics_section():
    st.header("ğŸ” KMeansèšç±»åŸºæœ¬åŸç†")
    
    # ç§»é™¤å·¦å³åˆ†æ ï¼Œæ”¹ä¸ºä¸Šä¸‹æ’ç‰ˆ
    st.markdown("""
    **KMeansèšç±»æ ¸å¿ƒæ€æƒ³:**
    KMeansæ˜¯ä¸€ç§**æ— ç›‘ç£**å­¦ä¹ ç®—æ³•ï¼Œç”¨äºå°†æ•°æ®è‡ªåŠ¨åˆ†ç»„ä¸ºKä¸ªä¸åŒçš„ç°‡ã€‚
    
    **ç®—æ³•æ­¥éª¤:**
    1. **åˆå§‹åŒ–**: é€‰æ‹©Kä¸ªåˆå§‹ä¸­å¿ƒç‚¹
    2. **åˆ†é…**: å°†æ¯ä¸ªæ•°æ®ç‚¹åˆ†é…åˆ°æœ€è¿‘çš„ä¸­å¿ƒç‚¹æ‰€åœ¨çš„ç°‡
    3. **æ›´æ–°**: è®¡ç®—æ¯ä¸ªç°‡çš„å¹³å‡å€¼ï¼Œä½œä¸ºæ–°çš„ä¸­å¿ƒç‚¹
    4. **é‡å¤**: é‡å¤æ­¥éª¤2å’Œ3ï¼Œç›´åˆ°ä¸­å¿ƒç‚¹ä¸å†æ˜¾è‘—å˜åŒ–
    
    **æ•°å­¦è¡¨è¾¾:**
    ç›®æ ‡æ˜¯æœ€å°åŒ–æ‰€æœ‰æ•°æ®ç‚¹åˆ°å…¶æ‰€å±ç°‡ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œï¼ˆæƒ¯æ€§ï¼‰:
    $$\\min \\sum_{k=1}^{K} \\sum_{x_i \\in C_k} ||x_i - \\mu_k||^2$$
    
    å…¶ä¸­$C_k$æ˜¯ç¬¬kä¸ªç°‡ï¼Œ$\\mu_k$æ˜¯ç¬¬kä¸ªç°‡çš„ä¸­å¿ƒã€‚
    """)
    
    if 'X' not in st.session_state:
        st.session_state.X, _ = generate_cluster_data("çƒå½¢èšç±»", 300, 3, 0.8)
    
    X = st.session_state.X
    
    # å±•ç¤ºKMeansçš„ä¸¤ä¸ªæ ¸å¿ƒæ­¥éª¤
    st.subheader("èšç±»æ ¸å¿ƒæ­¥éª¤æ¼”ç¤º")
    k = st.slider("é€‰æ‹©èšç±»æ•°é‡K", 2, 5, 3)
    
    if st.button("æ¼”ç¤ºKMeansæ ¸å¿ƒæ­¥éª¤"):
        steps = kmeans_step_visualization(X, k, max_iter=5)
        figs = plot_kmeans_steps(X, steps)
        col1,col2 = st.columns(2)
        with col1:
            st.write("**1. åˆå§‹åŒ–**: é€‰æ‹©Kä¸ªåˆå§‹ä¸­å¿ƒç‚¹")
            st.pyplot(figs[0])
            time.sleep(1)
        with col2:
            st.write("**2. åˆ†é…**: å°†æ¯ä¸ªæ•°æ®ç‚¹åˆ†é…åˆ°æœ€è¿‘çš„ä¸­å¿ƒç‚¹æ‰€åœ¨çš„ç°‡")
            st.pyplot(figs[1])
            time.sleep(1)
            
        col1,col2 = st.columns(2)
        with col1:
            st.write("**3. æ›´æ–°**: è®¡ç®—æ¯ä¸ªç°‡çš„å¹³å‡å€¼ï¼Œä½œä¸ºæ–°çš„ä¸­å¿ƒç‚¹")
            st.pyplot(figs[2])
            time.sleep(1)
        with col2:
            st.write("**4. é‡å¤**: é‡å¤æ­¥éª¤2å’Œ3ï¼Œç›´åˆ°ä¸­å¿ƒç‚¹ä¸å†æ˜¾è‘—å˜åŒ–")
            st.pyplot(figs[3])
            time.sleep(1)
            
        # è®°å½•å‚æ•°è°ƒæ•´æ“ä½œ
        st.session_state.kmeans_records["kmeans_basics_section"].append({
            "k_value": k,
            "timestamp": datetime.now().timestamp()
        })

   
    with st.expander("æŸ¥çœ‹KMeansèšç±»çš„åŠ¨ç”»æ¼”ç¤º"):
        cols= st.columns([1,4,1])
        with cols[1]:
            st.subheader("KMeansèšç±»çš„åŠ¨ç”»æ¼”ç¤º")
            st.image("https://upload.wikimedia.org/wikipedia/commons/e/ea/K-means_convergence.gif", 
                     caption="KMeansèšç±»æ”¶æ•›è¿‡ç¨‹åŠ¨ç”»")
    with st.expander("æŸ¥çœ‹KMeansèšç±»çš„å‡ ä½•è§£é‡Š"):
        cols= st.columns([1,4,1])
        with cols[1]:
            st.subheader("KMeansçš„å‡ ä½•è§£é‡Š")
            st.markdown("""        
            ![Voronoiå›¾](https://upload.wikimedia.org/wikipedia/commons/5/54/Euclidean_Voronoi_diagram.svg)
            - æ¯ä¸ªç°‡ç”±å…¶ä¸­å¿ƒç‚¹ï¼ˆè´¨å¿ƒï¼‰ä»£è¡¨
            - æ•°æ®ç‚¹æ ¹æ®è·ç¦»æœ€è¿‘çš„è´¨å¿ƒè¿›è¡Œåˆ†ç»„
            - èšç±»è¾¹ç•Œæ˜¯ Voronoi å›¾ï¼ˆå‚ç›´å¹³åˆ†çº¿ï¼‰
            - ç®—æ³•æœ€ç»ˆæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£
            """)
    
    return f"KMeansåŸºæœ¬åŸç†æ¨¡å—: æ¼”ç¤ºäº†K={k}æ—¶çš„èšç±»æ­¥éª¤"

# Kå€¼é€‰æ‹©æ¨¡å—
def k_selection_section():
    st.header("ğŸ¯ Kå€¼é€‰æ‹©æ–¹æ³•")
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®ï¼Œæ²¡æœ‰åˆ™ç”Ÿæˆé»˜è®¤æ•°æ®
    if 'X' not in st.session_state:
        st.session_state.X, _ = generate_cluster_data("çƒå½¢èšç±»", 300, 3, 0.8)
    X = st.session_state.X
    
    st.subheader("è‚˜éƒ¨æ³•åˆ™ (Elbow Method)")
    col1,col2 = st.columns([2,3])
    with col1:
        st.markdown("""
        è‚˜éƒ¨æ³•åˆ™é€šè¿‡ç»˜åˆ¶ä¸åŒKå€¼å¯¹åº”çš„æƒ¯æ€§ï¼ˆInertiaï¼‰æ¥é€‰æ‹©æœ€ä½³Kå€¼ï¼š
        - æƒ¯æ€§ï¼šæ‰€æœ‰æ ·æœ¬åˆ°å…¶æœ€è¿‘ç°‡ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œ
        - éšç€Kå¢å¤§ï¼Œæƒ¯æ€§ä¼šå‡å°
        - æœ€ä½³Kå€¼å‡ºç°åœ¨"è‚˜éƒ¨"ä½ç½®ï¼Œå³æƒ¯æ€§å¼€å§‹ç¼“æ…¢ä¸‹é™çš„ç‚¹
        
        ä¼˜ç‚¹ï¼šè®¡ç®—ç®€å•å¿«é€Ÿ
        
        ç¼ºç‚¹ï¼šä¸»è§‚æ€§å¼ºï¼Œæœ‰æ—¶æ²¡æœ‰æ˜æ˜¾çš„è‚˜éƒ¨
        """)
        max_k_elbow = st.slider("æœ€å¤§Kå€¼ï¼ˆè‚˜éƒ¨æ³•åˆ™ï¼‰", 5, 10, 8)
    with col2:    
        fig_elbow = plot_elbow_method(X, max_k_elbow)
        st.pyplot(fig_elbow)
    
    # è½®å»“ç³»æ•°æ³•éƒ¨åˆ†ç§»è‡³ä¸‹æ–¹
    st.subheader("è½®å»“ç³»æ•°æ³• (Silhouette Method)")
    col1,col2 = st.columns([2,3])
    with col1:
        st.markdown("""
        è½®å»“ç³»æ•°è¡¡é‡æ¯ä¸ªæ ·æœ¬ä¸å…¶è‡ªèº«ç°‡å†…æ ·æœ¬çš„ç›¸ä¼¼åº¦ï¼Œä»¥åŠä¸å…¶ä»–ç°‡æ ·æœ¬çš„ä¸ç›¸ä¼¼åº¦ï¼š
        - å–å€¼èŒƒå›´ï¼š[-1, 1]
        - æ¥è¿‘1ï¼šæ ·æœ¬èšç±»åˆç†
        - æ¥è¿‘0ï¼šæ ·æœ¬ä½äºä¸¤ä¸ªç°‡çš„è¾¹ç•Œ
        - æ¥è¿‘-1ï¼šæ ·æœ¬å¯èƒ½è¢«åˆ†åˆ°é”™è¯¯çš„ç°‡
        
        ä¼˜ç‚¹ï¼šä¸éœ€è¦çŸ¥é“çœŸå®æ ‡ç­¾ï¼Œæä¾›äº†èšç±»è´¨é‡çš„é‡åŒ–è¯„ä¼°
        
        ç¼ºç‚¹ï¼šè®¡ç®—æˆæœ¬é«˜ï¼Œå¯¹çƒå½¢ç°‡æ•ˆæœå¥½ä½†å¯¹éå‡¸å½¢çŠ¶æ•ˆæœå·®
        """)    
        max_k_silhouette = st.slider("æœ€å¤§Kå€¼ï¼ˆè½®å»“ç³»æ•°ï¼‰", 5, 10, 8)
    with col2:
        fig_silhouette = plot_silhouette_method(X, max_k_silhouette)
        st.pyplot(fig_silhouette)
    
    # ä¸åŒKå€¼å¯¹æ¯”éƒ¨åˆ†ä¿æŒä¸å˜
    st.subheader("é€‰æ‹©ä¸åŒKå€¼å¯¹èšç±»ç»“æœçš„å½±å“")
    st.success("KMeansèšç±»ï¼š**Kå€¼ä¸æƒ¯æ€§å€¼çš„å…³ç³»**ï¼ˆæƒ¯æ€§ï¼šæ ·æœ¬åˆ°èšç±»ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œï¼‰")
    X = np.random.randn(200, 2) * 5
    # é€‰æ‹©K=2ã€3ã€4ã€5ï¼Œè¦†ç›–ä¸åŒæ•°é‡çº§ï¼Œæ¸…æ™°ä½“ç°æƒ¯æ€§å˜åŒ–è§„å¾‹
    k_values = [2, 3, 4, 5]
    # è°ƒç”¨å‡½æ•°
    fig_compare = plot_k_comparison(X, k_values)
    st.pyplot(fig_compare)
    # æ·»åŠ æ–‡å­—æ³¨é‡Šï¼Œè§£é‡Šä¸¤ä¸ªå…³é”®ç»“è®º
    st.success("""
                    ğŸ‘‰**è§„å¾‹1**ï¼šKå€¼è¶Šå¤§ï¼Œæƒ¯æ€§å€¼è¶Šå°
                    ğŸ‘‰**è§„å¾‹2**ï¼šæƒ¯æ€§å€¼å¹¶éè¶Šå°è¶Šå¥½ï¼ˆKç­‰äºæ ·æœ¬æ•°æ—¶æƒ¯æ€§ä¸º0ï¼Œä½†èšç±»æ— æ„ä¹‰ï¼Œéœ€é€‰è‚˜éƒ¨ç‚¹ï¼‰
                """)

    # è®°å½•å‚æ•°è°ƒæ•´æ“ä½œ
    st.session_state.kmeans_records["k_selection_section"].append({
        "max_k_elbow": max_k_elbow,
        "max_k_silhouette": max_k_silhouette,
        "timestamp": datetime.now().timestamp()
    })  
    st.info("""
    **Kå€¼é€‰æ‹©å»ºè®®:**
    - ç»“åˆè‚˜éƒ¨æ³•åˆ™å’Œè½®å»“ç³»æ•°æ³•è¿›è¡Œåˆ¤æ–­
    - è€ƒè™‘å®é™…ä¸šåŠ¡éœ€æ±‚å’Œè§£é‡Šæ€§
    - å¯¹äºæ–°æ•°æ®ï¼Œå¯ä»¥å°è¯•å¤šç§Kå€¼å¹¶è¯„ä¼°ç»“æœ
    - æ²¡æœ‰æ”¾ä¹‹å››æµ·è€Œçš†å‡†çš„æœ€ä½³Kå€¼ï¼Œéœ€è¦æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©
    """)
    
    return f"Kå€¼é€‰æ‹©æ¨¡å—: æ¯”è¾ƒäº†K=2ã€3ã€4ã€5çš„èšç±»ç»“æœ"

# KMeanså±€é™æ€§æ¨¡å—
def kmeans_limitations_section():
    st.header("âš ï¸ KMeansèšç±»çš„å±€é™æ€§")
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®ï¼Œæ²¡æœ‰åˆ™ç”Ÿæˆé»˜è®¤æ•°æ®
    if 'X' not in st.session_state:
        st.session_state.X, _ = generate_cluster_data("çƒå½¢èšç±»", 300, 3, 0.8)
    
    data_type = st.session_state.data_type if 'data_type' in st.session_state else "çƒå½¢èšç±»"
    
    st.subheader("ğŸ”´ å¯¹éçƒå½¢ç°‡çš„å¤„ç†")
    col1,col2 = st.columns([2,3])
    with col1:
        st.markdown("""
        KMeanså‡è®¾èšç±»æ˜¯å‡¸å½¢å’Œçƒå½¢çš„ï¼Œå¯¹éçƒå½¢ç°‡æ•ˆæœè¾ƒå·®ï¼š
        - æ— æ³•æ­£ç¡®è¯†åˆ«åŠæœˆå½¢ã€ç¯å½¢ç­‰å¤æ‚å½¢çŠ¶
        - å€¾å‘äºå°†æ•°æ®åˆ†æˆå¤§å°ç›¸è¿‘çš„ç°‡
        """)
    with col2:
    # å±•ç¤ºKMeansåœ¨åŠæœˆå½¢æ•°æ®ä¸Šçš„è¡¨ç°
        X_moons, _ = make_moons(n_samples=300, noise=0.05, random_state=42)
        kmeans_moons = KMeans(n_clusters=2, random_state=42)
        labels_moons = kmeans_moons.fit_predict(X_moons)
        
        fig_moons = plt.figure(figsize=(10, 6))
        plt.scatter(X_moons[:, 0], X_moons[:, 1], c=labels_moons, cmap='viridis', alpha=0.7)
        plt.scatter(kmeans_moons.cluster_centers_[:, 0], kmeans_moons.cluster_centers_[:, 1], 
                   c='red', marker='X', s=200)
        plt.title('KMeansåœ¨åŠæœˆå½¢æ•°æ®ä¸Šçš„è¡¨ç°',fontsize=16)
        plt.grid(True, linestyle='--', alpha=0.7)
        st.pyplot(fig_moons)
    
    # ç¬¬äºŒä¸ªå±€é™æ€§ï¼šå¯¹ä¸åŒå¯†åº¦ç°‡çš„å¤„ç†
    st.subheader("ğŸ”´ å¯¹ä¸åŒå¯†åº¦ç°‡çš„å¤„ç†")
    col1,col2 = st.columns([2,3])
    with col1:
        st.markdown("""
        KMeanså¯¹å¯†åº¦å·®å¼‚å¤§çš„ç°‡å¤„ç†ä¸ä½³ï¼š
        - å€¾å‘äºå°†é«˜å¯†åº¦åŒºåŸŸåˆ†å‰²æˆå¤šä¸ªç°‡
        - ä½å¯†åº¦åŒºåŸŸå¯èƒ½è¢«åˆå¹¶æˆä¸€ä¸ªç°‡
        - å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ
        """)
    with col2:
    # ç”Ÿæˆå¯†åº¦ä¸åŒçš„èšç±»æ•°æ®
        X_density = np.vstack([
            np.random.normal(loc=(-3, -3), scale=0.5, size=(300, 2)),  # é«˜å¯†åº¦ç°‡
            np.random.normal(loc=(0, 0), scale=1.2, size=(150, 2)),    # ä¸­ç­‰å¯†åº¦ç°‡
            np.random.normal(loc=(3, 3), scale=0.8, size=(50, 2))      # ä½å¯†åº¦ç°‡
        ])
        
        kmeans_density = KMeans(n_clusters=3, random_state=42)
        labels_density = kmeans_density.fit_predict(X_density)
        
        fig_density = plt.figure(figsize=(10, 6))
        plt.scatter(X_density[:, 0], X_density[:, 1], c=labels_density, cmap='viridis', alpha=0.7)
        plt.scatter(kmeans_density.cluster_centers_[:, 0], kmeans_density.cluster_centers_[:, 1], 
                   c='red', marker='X', s=200)
        plt.title('KMeansåœ¨ä¸åŒå¯†åº¦ç°‡ä¸Šçš„è¡¨ç°',fontsize=16)
        plt.grid(True, linestyle='--', alpha=0.7)
        st.pyplot(fig_density)
    
    # ç¬¬ä¸‰ä¸ªå±€é™æ€§ï¼šåˆå§‹ä¸­å¿ƒç‚¹æ•æ„Ÿæ€§
    st.subheader("ğŸ”´ åˆå§‹ä¸­å¿ƒç‚¹æ•æ„Ÿæ€§")
    col1,col2 = st.columns([2,3])
    with col1:
        st.markdown("""
        KMeansçš„ç»“æœå—åˆå§‹ä¸­å¿ƒç‚¹é€‰æ‹©å½±å“ï¼š
        - ä¸åŒçš„åˆå§‹ç‚¹å¯èƒ½å¯¼è‡´ä¸åŒçš„èšç±»ç»“æœ
        - å¯èƒ½æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è€Œéå…¨å±€æœ€ä¼˜
        """)
    with col2:
        # å±•ç¤ºä¸åŒåˆå§‹ç‚¹çš„å½±å“
        X = st.session_state.X
        st.success("ğŸ‘‰ğŸ‘‰ğŸ‘‰ä»¥5ä¸ªåˆå§‹ç‚¹ä¸ºä¾‹ï¼Œä¸åŒçš„åˆå§‹ç‚¹å¯èƒ½å¯¼è‡´ä¸åŒçš„èšç±»ç»“æœ")
    

    fig_initial, axes = plt.subplots(1, 3, figsize=(15, 5))
        
    for i, seed in enumerate([42, 100, 200]):
        kmeans = KMeans(n_clusters=5, random_state=seed, n_init=1)  # n_init=1ç¡®ä¿åªè¿è¡Œä¸€æ¬¡
        labels = kmeans.fit_predict(X)
            
        axes[i].scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.7)
        axes[i].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
                        c='red', marker='X', s=200)
        axes[i].set_title(f'éšæœºç§å­={seed}, æƒ¯æ€§={kmeans.inertia_:.2f}',fontsize=16)
        axes[i].grid(True, linestyle='--', alpha=0.7)
        
    plt.tight_layout()
    st.pyplot(fig_initial)
    
    # è®°å½•å‚æ•°è°ƒæ•´æ“ä½œ
    st.session_state.kmeans_records["kmeans_limitations_section"].append({
        "timestamp": datetime.now().timestamp()
    })   
    st.info("""
    **KMeanså±€é™æ€§æ€»ç»“:**
    1. éœ€è¦é¢„å…ˆæŒ‡å®šKå€¼
    2. å¯¹åˆå§‹ä¸­å¿ƒç‚¹æ•æ„Ÿ
    3. åªèƒ½å‘ç°å‡¸å½¢ã€çƒå½¢ç°‡
    4. å¯¹å™ªå£°å’Œå¼‚å¸¸å€¼æ•æ„Ÿ
    5. å¯¹ä¸åŒå¤§å°å’Œå¯†åº¦çš„ç°‡å¤„ç†ä¸ä½³
    6. ä¸é€‚åˆé«˜ç»´æ•°æ®ï¼ˆç»´åº¦ç¾éš¾ï¼‰
    
    **æ”¹è¿›æ–¹æ³•:**
    - ä½¿ç”¨KMeans++åˆå§‹åŒ–ä¸­å¿ƒç‚¹
    - å¤šæ¬¡è¿è¡Œå–æœ€ä¼˜ç»“æœ
    - å¯¹é«˜ç»´æ•°æ®å…ˆè¿›è¡Œé™ç»´
    - è€ƒè™‘ä½¿ç”¨DBSCANç­‰å…¶ä»–èšç±»ç®—æ³•å¤„ç†éçƒå½¢æ•°æ®
    """)
    
    return f"KMeanså±€é™æ€§æ¨¡å—: å±•ç¤ºäº†K=5æ—¶çš„åˆå§‹ç‚¹å½±å“"

# èšç±»è¯„ä¼°æŒ‡æ ‡æ¨¡å—
def evaluation_metrics_section():
    st.header("ğŸ“ˆ èšç±»è¯„ä¼°æŒ‡æ ‡")
    
    # ç”Ÿæˆæœ‰æ˜ç¡®èšç±»çš„æ•°æ®
    X, y_true = generate_cluster_data("çƒå½¢èšç±»", 300, 3, 0.8)
    
    # å†…éƒ¨è¯„ä¼°æŒ‡æ ‡éƒ¨åˆ†ï¼ˆä¸ŠåŠéƒ¨åˆ†ï¼‰
    st.subheader("å½“æ²¡æœ‰çœŸå®æ ‡ç­¾æ—¶ï¼Œä½¿ç”¨å†…éƒ¨æŒ‡æ ‡è¯„ä¼°èšç±»è´¨é‡")
    col1,col2 = st.columns(2)
    with col1:
        st.info("""
    1. **æƒ¯æ€§ (Inertia)**    
       - æ‰€æœ‰æ ·æœ¬åˆ°å…¶æœ€è¿‘ç°‡ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œ
       - å€¼è¶Šå°è¡¨ç¤ºèšç±»è¶Šç´§å‡‘
       - ç¼ºç‚¹ï¼šéšç€Kå¢å¤§å•è°ƒå‡å°ï¼Œæ— æ³•ç¡®å®šæœ€ä½³Kå€¼"""
    )
    with col2:
        st.info("""    
    2. **è½®å»“ç³»æ•° (Silhouette Score)**
       - è¡¡é‡æ ·æœ¬ä¸è‡ªèº«ç°‡çš„ç›¸ä¼¼åº¦å’Œä¸å…¶ä»–ç°‡çš„å·®å¼‚æ€§
       - èŒƒå›´ï¼š[-1, 1]ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½""")
        
    col1,col2 = st.columns(2)
    with col1:
        st.info("""    
    3. **Calinski-HarabaszæŒ‡æ•°**
       - ç°‡é—´ç¦»æ•£åº¦ä¸ç°‡å†…ç¦»æ•£åº¦çš„æ¯”å€¼
       - å€¼è¶Šå¤§è¡¨ç¤ºèšç±»è´¨é‡è¶Šå¥½""")
    with col2:
        st.info("""      
    4. **Davies-BouldinæŒ‡æ•°**
       - è¡¡é‡ç°‡ä¹‹é—´çš„ç›¸ä¼¼åº¦
       - å€¼è¶Šå°è¡¨ç¤ºèšç±»è´¨é‡è¶Šå¥½""")
        
    st.markdown("---")
    st.subheader("å½“æœ‰çœŸå®æ ‡ç­¾æ—¶ï¼Œä½¿ç”¨å¤–éƒ¨æŒ‡æ ‡è¯„ä¼°èšç±»è´¨é‡")
    col1,col2 = st.columns(2)
    with col1:
        st.info("""
    1. **è°ƒæ•´å…°å¾·æŒ‡æ•° (ARI)**
       - è¡¡é‡èšç±»ç»“æœä¸çœŸå®æ ‡ç­¾çš„ä¸€è‡´æ€§
       - èŒƒå›´ï¼š[-1, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨ä¸€è‡´"""
    )
    with col2:
        st.info("""    
    2. **è°ƒæ•´äº’ä¿¡æ¯ (AMI)**
       - è¡¡é‡ä¸¤ä¸ªèšç±»åˆ†å¸ƒçš„ä¸€è‡´æ€§
       - èŒƒå›´ï¼š[0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨ä¸€è‡´""")
        
    col1,col2 = st.columns(2)
    with col1:
        st.info("""    
    3. **åŒè´¨æ€§ (Homogeneity)**
       - æ¯ä¸ªç°‡æ˜¯å¦åªåŒ…å«å•ä¸€ç±»åˆ«çš„æ ·æœ¬
       - èŒƒå›´ï¼š[0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨åŒè´¨""")
    with col2:
        st.info("""      
    4. **å®Œæ•´æ€§ (Completeness)**
       - åŒä¸€ç±»åˆ«çš„æ ·æœ¬æ˜¯å¦è¢«åˆ†é…åˆ°åŒä¸€ä¸ªç°‡
       - èŒƒå›´ï¼š[0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨å®Œæ•´""")
        
    k = st.slider("é€‰æ‹©èšç±»æ•°é‡K", 2, 6, 3)
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)    
    # å¯¼å…¥æ‰€éœ€çš„è¯„ä¼°æŒ‡æ ‡å‡½æ•°
    from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_score, completeness_score
    
    col1,col2 = st.columns(2)
    with col1:
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        inertia = kmeans.inertia_
        silhouette = silhouette_score(X, labels)
        calinski = calinski_harabasz_score(X, labels)
        davies = davies_bouldin_score(X, labels)
        
        st.write("### ğŸ’¡ å†…éƒ¨æŒ‡æ ‡è¯„ä¼°ç»“æœ:")
        st.success(f"""
                    - æƒ¯æ€§: {inertia:.2f}
                    - è½®å»“ç³»æ•°: {silhouette:.4f}
                    - Calinski-HarabaszæŒ‡æ•°: {calinski:.2f}
                    - Davies-BouldinæŒ‡æ•°: {davies:.4f}""")        
    with col2:
        # è®¡ç®—å¤–éƒ¨è¯„ä¼°æŒ‡æ ‡
        ari = adjusted_rand_score(y_true, labels)
        ami = adjusted_mutual_info_score(y_true, labels)
        homogeneity = homogeneity_score(y_true, labels)
        completeness = completeness_score(y_true, labels)
        
        st.write("### ğŸ’¡ å¤–éƒ¨æŒ‡æ ‡è¯„ä¼°ç»“æœ:")
        st.success(f"""
                    - è°ƒæ•´å…°å¾·æŒ‡æ•°: {ari:.4f}
                    - è°ƒæ•´äº’ä¿¡æ¯: {ami:.4f}
                    - åŒè´¨æ€§: {homogeneity:.4f}
                    - å®Œæ•´æ€§: {completeness:.4f}""")
        
    # è®°å½•å‚æ•°è°ƒæ•´æ“ä½œ
    st.session_state.kmeans_records["evaluation_metrics_section"].append({
        "k_value": k,
        "timestamp": datetime.now().timestamp()
    })

    col1,col2 = st.columns(2)
    with col1:
        # æ˜¾ç¤ºå¸¦çœŸå®æ ‡ç­¾çš„æ•°æ®
        fig_true = plot_cluster_data(X, y_true, title="çœŸå®èšç±»åˆ†å¸ƒ")
        st.pyplot(fig_true)
    with col2:
        # æ˜¾ç¤ºèšç±»ç»“æœ
        fig_pred = plot_cluster_data(X, labels, kmeans.cluster_centers_, title=f"K={k}çš„èšç±»ç»“æœ")
        st.pyplot(fig_pred)
        
    st.info("""
    **è¯„ä¼°æŒ‡æ ‡é€‰æ‹©æŒ‡å—:**
    - æ— çœŸå®æ ‡ç­¾: ä¸»è¦ä½¿ç”¨è½®å»“ç³»æ•°å’ŒCalinski-HarabaszæŒ‡æ•°
    - æœ‰çœŸå®æ ‡ç­¾: ä¼˜å…ˆä½¿ç”¨è°ƒæ•´å…°å¾·æŒ‡æ•°å’Œè°ƒæ•´äº’ä¿¡æ¯
    - å•ä¸€æŒ‡æ ‡ä¸è¶³ä»¥è¯„ä¼°èšç±»è´¨é‡ï¼Œåº”ç»¼åˆå¤šä¸ªæŒ‡æ ‡
    - æœ€é‡è¦çš„è¯„ä¼°æ˜¯èšç±»ç»“æœæ˜¯å¦æœ‰å®é™…ä¸šåŠ¡æ„ä¹‰
    """)
    
    return f"èšç±»è¯„ä¼°æ¨¡å—: è¯„ä¼°äº†K={k}æ—¶çš„èšç±»ç»“æœ"

# æ¦‚å¿µæµ‹éªŒæ¨¡å—
def quiz_section():
    st.header("ğŸ¯ KMeansèšç±»æ¦‚å¿µæµ‹éªŒ")
    st.write("è¯·å®Œæˆä»¥ä¸‹5é“å•é€‰é¢˜ï¼Œå…¨éƒ¨ç­”å®Œåå¯æäº¤æŸ¥çœ‹ç»“æœ")
    
    # å®šä¹‰æµ‹éªŒé¢˜ç›®ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆåŠè§£æ
    quiz_data = [
        {
            "question": "1. KMeansä¸­çš„Kä»£è¡¨ä»€ä¹ˆ?",
            "options": [
                "A. è¿­ä»£æ¬¡æ•°",
                "B. èšç±»çš„æ•°é‡",
                "C. ç‰¹å¾çš„ç»´åº¦",
                "D. æ ·æœ¬çš„æ•°é‡"
            ],
            "correct": "B",
            "explanation": "KMeansä¸­çš„Kä»£è¡¨æˆ‘ä»¬å¸Œæœ›å°†æ•°æ®åˆ†æˆçš„èšç±»æ•°é‡ï¼Œå³æœ€ç»ˆå¾—åˆ°çš„ç°‡çš„ä¸ªæ•°ã€‚"
        },
        {
            "question": "2. KMeansçš„ç›®æ ‡æ˜¯ä»€ä¹ˆ?",
            "options": [
                "A. æœ€å¤§åŒ–ç°‡é—´è·ç¦»ï¼Œæœ€å°åŒ–ç°‡å†…è·ç¦»",
                "B. æœ€å°åŒ–æ‰€æœ‰æ•°æ®ç‚¹åˆ°å…¶ç°‡ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œ",
                "C. ä½¿æ¯ä¸ªç°‡çš„æ ·æœ¬æ•°é‡å°½å¯èƒ½ç›¸ç­‰",
                "D. æœ€å¤§åŒ–ä¸åŒç°‡ä¹‹é—´çš„ç›¸ä¼¼åº¦"
            ],
            "correct": "B",
            "explanation": "KMeansçš„æ ¸å¿ƒç›®æ ‡æ˜¯æœ€å°åŒ–æƒ¯æ€§ï¼ˆinertiaï¼‰ï¼Œå³æ‰€æœ‰æ ·æœ¬åˆ°å…¶æœ€è¿‘ç°‡ä¸­å¿ƒçš„è·ç¦»å¹³æ–¹å’Œã€‚"
        },
        {
            "question": "3. ä¸ºä»€ä¹ˆKMeanså¯¹åˆå§‹ä¸­å¿ƒç‚¹æ•æ„Ÿ?",
            "options": [
                "A. å› ä¸ºç®—æ³•ä¼šæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è€Œéå…¨å±€æœ€ä¼˜",
                "B. å› ä¸ºåˆå§‹ç‚¹å†³å®šäº†ç‰¹å¾æƒé‡",
                "C. å› ä¸ºè®¡ç®—ç²¾åº¦æœ‰é™",
                "D. å› ä¸ºåˆå§‹ç‚¹ä¼šå½±å“ç‰¹å¾æ ‡å‡†åŒ–ç»“æœ"
            ],
            "correct": "A",
            "explanation": "KMeansä½¿ç”¨è´ªå©ªç®—æ³•ï¼Œä¸åŒçš„åˆå§‹ç‚¹å¯èƒ½å¯¼è‡´æ”¶æ•›åˆ°ä¸åŒçš„å±€éƒ¨æœ€ä¼˜è§£ï¼Œè€Œéå…¨å±€æœ€ä¼˜è§£ã€‚"
        },
        {
            "question": "4. KMeansé€‚åˆå¤„ç†ä»€ä¹ˆæ ·çš„æ•°æ®?",
            "options": [
                "A. é«˜ç»´ç¨€ç–æ•°æ®",
                "B. éå‡¸å½¢çŠ¶çš„èšç±»æ•°æ®",
                "C. çƒå½¢ã€å¯†åº¦ç›¸è¿‘çš„èšç±»æ•°æ®",
                "D. ç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®"
            ],
            "correct": "C",
            "explanation": "KMeanså¯¹çƒå½¢ã€å‡¸å½¢ä¸”å¯†åº¦ç›¸è¿‘çš„èšç±»æ•°æ®æ•ˆæœæœ€å¥½ï¼Œå¯¹éå‡¸å½¢çŠ¶å’Œå¯†åº¦å·®å¼‚å¤§çš„æ•°æ®è¡¨ç°è¾ƒå·®ã€‚"
        },
        {
            "question": "5. è‚˜éƒ¨æ³•åˆ™çš„åŸç†æ˜¯ä»€ä¹ˆ?",
            "options": [
                "A. æ‰¾åˆ°è½®å»“ç³»æ•°æœ€å¤§çš„Kå€¼",
                "B. æ‰¾åˆ°æƒ¯æ€§å¼€å§‹ç¼“æ…¢ä¸‹é™çš„Kå€¼ç‚¹",
                "C. æ‰¾åˆ°ä¸çœŸå®æ ‡ç­¾æœ€åŒ¹é…çš„Kå€¼",
                "D. æ‰¾åˆ°ç°‡å†…æ–¹å·®æœ€å¤§çš„Kå€¼"
            ],
            "correct": "B",
            "explanation": "è‚˜éƒ¨æ³•åˆ™é€šè¿‡è§‚å¯Ÿæƒ¯æ€§éšKå€¼å¢åŠ çš„å˜åŒ–ï¼Œé€‰æ‹©æƒ¯æ€§å¼€å§‹ç¼“æ…¢ä¸‹é™çš„'è‚˜éƒ¨'ä½ç½®ä½œä¸ºæœ€ä½³Kå€¼ã€‚"
        }
    ]
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å­˜å‚¨ç”¨æˆ·ç­”æ¡ˆ
    if "kmeans_user_answers" not in st.session_state:
        st.session_state.kmeans_user_answers = [None] * len(quiz_data)
    
    # æ˜¾ç¤ºæ‰€æœ‰é¢˜ç›®å’Œé€‰é¡¹ï¼ˆåˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼‰
    for i, item in enumerate(quiz_data):
        st.markdown(f"**{item['question']}**")
        # è®¾ç½®é»˜è®¤å€¼ä¸ºNoneå®ç°åˆå§‹æ— é€‰ä¸­çŠ¶æ€ï¼Œé€šè¿‡ä¼šè¯çŠ¶æ€ä¿å­˜ç­”æ¡ˆ
        answer = st.radio(
            "é€‰æ‹©ç­”æ¡ˆ:",
            item["options"],
            key=f"kmeans_quiz_{i}",
            index=None,  # å…³é”®ï¼šåˆå§‹æ— é€‰ä¸­é¡¹
            label_visibility="collapsed"
        )
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„ç­”æ¡ˆï¼ˆæå–é€‰é¡¹å­—æ¯A/B/Cï¼‰
        if answer is not None:
            st.session_state.kmeans_user_answers[i] = answer[0]
        
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢˜ç›®éƒ½å·²ä½œç­”
    all_answered = all(ans is not None for ans in st.session_state.kmeans_user_answers)
    
    # æäº¤æŒ‰é’®ï¼šåªæœ‰å…¨éƒ¨ç­”å®Œæ‰å¯ç”¨
    submit_btn = st.button(
        "æäº¤ç­”æ¡ˆ", 
        key="submit_kmeans_quiz",
        disabled=not all_answered  # æœªç­”å®Œæ—¶ç¦ç”¨
    )
    
    # æœªç­”å®Œæ—¶æ˜¾ç¤ºæç¤º
    if not all_answered:
        st.info("è¯·å®Œæˆæ‰€æœ‰5é“é¢˜ç›®åå†æäº¤")
    
    # å¤„ç†æäº¤
    if submit_btn and all_answered:
        # è®¡ç®—å¾—åˆ†å’Œé”™è¯¯é¢˜ç›®
        score = 0
        results = []
        incorrect_questions = []
        for i, item in enumerate(quiz_data):
            is_correct = st.session_state.kmeans_user_answers[i] == item["correct"]
            if is_correct:
                score += 20  # æ¯é¢˜20åˆ†
            else:
                incorrect_questions.append({
                    "topic": item["question"], 
                    "user_answer": st.session_state.kmeans_user_answers[i]
                })

            results.append({
                "question": item["question"],
                "user_answer": st.session_state.kmeans_user_answers[i],
                "correct_answer": item["correct"],
                "is_correct": is_correct,
                "explanation": item["explanation"]
            })
            
        # è®°å½•æµ‹éªŒç»“æœ
        st.session_state.kmeans_records["kmeans_quiz"] = {
            "score": score,
            "incorrect_questions": incorrect_questions,
            "timestamp": datetime.now().timestamp()
        }
       
        # æ˜¾ç¤ºå¾—åˆ†
        st.success(f"ğŸ“Š æµ‹éªŒå®Œæˆï¼ä½ çš„å¾—åˆ†æ˜¯ï¼š{score}åˆ†")
        st.write("### ç­”æ¡ˆè§£æï¼š")
        
        # æ˜¾ç¤ºæ¯é¢˜ç»“æœ
        for res in results:
            # ä½¿ç”¨emojiå’Œæ–‡å­—æ ‡è®°æ­£ç¡®/é”™è¯¯çŠ¶æ€
            if res["is_correct"]:
                status_text = "âœ… æ­£ç¡®"
            else:
                status_text = "âŒ é”™è¯¯"
            
            with st.expander(f"{res['question']} {status_text}"):
                if res["is_correct"]:
                    st.success(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆæ­£ç¡®ï¼‰")
                else:
                    st.error(f"ä½ çš„ç­”æ¡ˆï¼š{res['user_answer']}ï¼ˆé”™è¯¯ï¼‰")
                    st.info(f"æ­£ç¡®ç­”æ¡ˆï¼š{res['correct_answer']}")
                st.write(f"è§£æï¼š{res['explanation']}")

        # å‡†å¤‡AIåˆ†æçš„è¾“å…¥
        incorrect_topics = [
            res["question"] for res in results if not res["is_correct"]
        ]
        
        analysis_prompt = f"""
        ä»¥ä¸‹æ˜¯å­¦ç”Ÿåœ¨KMeansèšç±»æµ‹éªŒä¸­çš„ç­”é¢˜æƒ…å†µï¼š
        - æ€»å¾—åˆ†ï¼š{score}åˆ†
        - é”™è¯¯é¢˜ç›®ï¼š{len(incorrect_topics)}é“
        - é”™è¯¯çŸ¥è¯†ç‚¹ï¼š{'; '.join(incorrect_topics) if incorrect_topics else 'æ— '}
        
        è¯·åˆ†æè¯¥å­¦ç”Ÿçš„çŸ¥è¯†æŒæ¡æƒ…å†µï¼ŒæŒ‡å‡ºæœªæŒæ¡çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶ç»™å‡ºå…·ä½“çš„å­¦ä¹ å»ºè®®å’ŒæŒ‡å¯¼æ–¹å‘ï¼Œå¸®åŠ©å­¦ç”Ÿé’ˆå¯¹æ€§æå‡ã€‚
        ç­”æ¡ˆå¿…é¡»æ§åˆ¶åœ¨450å­—ä»¥å†…
        """
        
        # è°ƒç”¨AIåˆ†æ
        with st.spinner("AIæ­£åœ¨åˆ†æä½ çš„ç­”é¢˜æƒ…å†µ..."):
            ai_analysis = ask_ai_assistant(analysis_prompt, "KMeansèšç±»æµ‹éªŒåˆ†æ")
        
        # æ˜¾ç¤ºAIåˆ†æç»“æœ
        st.write("### ğŸ¤– AIå­¦ä¹ è¯Šæ–­ï¼š")
        st.info(ai_analysis)       
  
    return "æ¦‚å¿µæµ‹éªŒæ¨¡å—ï¼šå®Œæˆ5é¢˜å•é€‰é¢˜æµ‹è¯•"

# å®é™…åº”ç”¨æ¡ˆä¾‹æ¨¡å—
def real_world_example_section():
    st.header("ğŸŒ KMeansèšç±»å®é™…åº”ç”¨æ¡ˆä¾‹")
    
    example = st.selectbox(
        "é€‰æ‹©å®é™…åº”ç”¨æ¡ˆä¾‹:",
        ["å®¢æˆ·åˆ†ç¾¤åˆ†æ", "å›¾åƒå‹ç¼©", "å¼‚å¸¸æ£€æµ‹", "æ–‡æœ¬èšç±»", "ä¸Šä¼ è‡ªå·±çš„æ•°æ®"]
    )
    
    if example == "ä¸Šä¼ è‡ªå·±çš„æ•°æ®":
        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file:
            data = pd.read_csv(uploaded_file)
            st.write("æ•°æ®é¢„è§ˆ:", data.head())
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ç±»å˜é‡
            categorical_cols = data.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                st.warning("æ£€æµ‹åˆ°åˆ†ç±»å˜é‡ï¼Œæœ¬æ¼”ç¤ºå°†è‡ªåŠ¨å¿½ç•¥è¿™äº›åˆ—ã€‚")
                data = data.select_dtypes(exclude=['object'])
            
            if len(data.columns) < 2:
                st.error("æ•°æ®è‡³å°‘éœ€è¦åŒ…å«ä¸¤ä¸ªç‰¹å¾åˆ—!")
                return
            
            # æ ‡å‡†åŒ–æ•°æ®
            scaler = StandardScaler()
            X = scaler.fit_transform(data)
            
            analyze_custom_data(X, data.columns)
            return f"å®é™…åº”ç”¨æ¨¡å—: ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®"
    else:
        # ç”Ÿæˆæˆ–åŠ è½½ç¤ºä¾‹æ•°æ®
        X, feature_names, description = load_example_dataset(example)
        st.write(description)        
        analyze_custom_data(X, feature_names)

    # è®°å½•å‚æ•°è°ƒæ•´æ“ä½œ
    st.session_state.kmeans_records["real_world_example_section"].append({
        "example": example,
        "timestamp": datetime.now().timestamp()
    }) 

    return f"å®é™…åº”ç”¨æ¨¡å—: ä½¿ç”¨{example}æ•°æ®é›†"

# åŠ è½½ç¤ºä¾‹æ•°æ®é›†
def load_example_dataset(example_name):
    np.random.seed(42)
    
    if example_name == "å®¢æˆ·åˆ†ç¾¤åˆ†æ":
        # ç”Ÿæˆå®¢æˆ·åˆ†ç¾¤æ•°æ®ï¼šRFMæ¨¡å‹ç›¸å…³ç‰¹å¾
        n_samples = 500
        
        # ç‰¹å¾ï¼šæ¶ˆè´¹é¢‘ç‡ã€å¹³å‡æ¶ˆè´¹é‡‘é¢ã€æœ€è¿‘æ¶ˆè´¹æ—¶é—´ï¼ˆå¤©ï¼‰
        freq = np.random.normal(15, 8, n_samples)
        amount = np.random.normal(500, 300, n_samples)
        recency = np.random.normal(30, 20, n_samples)
        
        # ç¡®ä¿å€¼ä¸ºæ­£æ•°
        freq = np.abs(freq)
        amount = np.abs(amount)
        recency = np.abs(recency)
        
        X = np.column_stack((freq, amount, recency))
        
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        feature_names = ["æ¶ˆè´¹é¢‘ç‡", "å¹³å‡æ¶ˆè´¹é‡‘é¢", "æœ€è¿‘æ¶ˆè´¹æ—¶é—´(å¤©)"]
        description = "å®¢æˆ·åˆ†ç¾¤åˆ†æ: åŸºäºRFMæ¨¡å‹çš„å®¢æˆ·ä»·å€¼åˆ†æï¼Œå¸®åŠ©ä¼ä¸šè¯†åˆ«é«˜ä»·å€¼å®¢æˆ·ç¾¤ä½“"
        return X, feature_names, description
    
    elif example_name == "å›¾åƒå‹ç¼©":
        # ç”Ÿæˆç®€å•çš„å›¾åƒæ•°æ®ï¼ˆ2Dåƒç´ ï¼‰
        from sklearn.datasets import load_sample_image
        
        # åŠ è½½ç¤ºä¾‹å›¾åƒå¹¶ç®€åŒ–
        china = load_sample_image("china.jpg")
        # ç¼©å°å›¾åƒå°ºå¯¸
        china = china[::10, ::10]
        # è½¬æ¢ä¸ºäºŒç»´æ•°ç»„
        X = china.reshape(-1, 3)
        # åªå–å‰5000ä¸ªåƒç´ åŠ é€Ÿå¤„ç†
        X = X[:5000]
        
        feature_names = ["R", "G", "B"]
        description = "å›¾åƒå‹ç¼©: ä½¿ç”¨KMeanså°†å›¾åƒé¢œè‰²èšç±»ï¼Œç”¨è¾ƒå°‘çš„é¢œè‰²è¡¨ç¤ºå›¾åƒï¼Œå®ç°å‹ç¼©æ•ˆæœ"
        return X, feature_names, description
    
    elif example_name == "å¼‚å¸¸æ£€æµ‹":
        # ç”Ÿæˆæ­£å¸¸æ•°æ®å’Œå¼‚å¸¸æ•°æ®
        n_normal = 450
        n_anomalies = 50
        
        # æ­£å¸¸æ•°æ®ï¼ˆä¸‰ä¸ªç°‡ï¼‰
        normal1 = np.random.normal(loc=(0, 0), scale=0.5, size=(n_normal//3, 2))
        normal2 = np.random.normal(loc=(3, 3), scale=0.7, size=(n_normal//3, 2))
        normal3 = np.random.normal(loc=(-3, 3), scale=0.6, size=(n_normal//3, 2))
        
        # å¼‚å¸¸æ•°æ®ï¼ˆè¿œç¦»æ­£å¸¸ç°‡ï¼‰
        anomalies = np.random.uniform(low=-6, high=6, size=(n_anomalies, 2))
        # è¿‡æ»¤æ‰å¯èƒ½æ··å…¥æ­£å¸¸ç°‡çš„å¼‚å¸¸ç‚¹
        anomalies = anomalies[np.linalg.norm(anomalies, axis=1) > 4]
        
        X = np.vstack([normal1, normal2, normal3, anomalies])
        
        feature_names = ["ç‰¹å¾1", "ç‰¹å¾2"]
        description = "å¼‚å¸¸æ£€æµ‹: é€šè¿‡KMeansè¯†åˆ«è¿œç¦»æ‰€æœ‰ç°‡ä¸­å¿ƒçš„ç‚¹ï¼Œè¿™äº›ç‚¹å¯èƒ½æ˜¯å¼‚å¸¸å€¼"
        return X, feature_names, description
    
    elif example_name == "æ–‡æœ¬èšç±»":
        # ç”Ÿæˆæ–‡æœ¬æ•°æ®ï¼ˆä½¿ç”¨TF-IDFç‰¹å¾ï¼‰
        from sklearn.feature_extraction.text import TfidfVectorizer
        
        # ç”Ÿæˆä¸€äº›ç¤ºä¾‹æ–‡æœ¬
        texts = [
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
            "ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€",
            "å·ç§¯ç¥ç»ç½‘ç»œé€‚ç”¨äºå›¾åƒè¯†åˆ«",
            "å¾ªç¯ç¥ç»ç½‘ç»œé€‚ç”¨äºåºåˆ—æ•°æ®",
            "æ”¯æŒå‘é‡æœºæ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•",
            "å†³ç­–æ ‘æ˜¯ä¸€ç§ç®€å•çš„æœºå™¨å­¦ä¹ æ¨¡å‹",
            "éšæœºæ£®æ—æ˜¯å¤šä¸ªå†³ç­–æ ‘çš„é›†æˆ",
            "èšç±»ç®—æ³•å±äºæ— ç›‘ç£å­¦ä¹ ",
            "KMeansæ˜¯ä¸€ç§å¸¸ç”¨çš„èšç±»ç®—æ³•",
            "è¶³çƒæ˜¯ä¸–ç•Œä¸Šæœ€å—æ¬¢è¿çš„è¿åŠ¨",
            "ç¯®çƒåœ¨ç¾å›½éå¸¸æµè¡Œ",
            "ç½‘çƒæ˜¯ä¸€é¡¹ä¼˜é›…çš„è¿åŠ¨",
            "å¥¥è¿ä¼šæ¯å››å¹´ä¸¾åŠä¸€æ¬¡",
            "ä¸–ç•Œæ¯æ˜¯è¶³çƒç•Œçš„æœ€é«˜èµ›äº‹",
            "Pythonæ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€",
            "Javaæ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€",
            "C++è¿è¡Œé€Ÿåº¦å¾ˆå¿«",
            "JavaScriptç”¨äºç½‘é¡µå¼€å‘",
            "Rè¯­è¨€å¸¸ç”¨äºæ•°æ®åˆ†æ"
        ]
        
        # é‡å¤æ–‡æœ¬ä»¥å¢åŠ æ ·æœ¬é‡
        texts = texts * 10
        
        # æå–TF-IDFç‰¹å¾
        vectorizer = TfidfVectorizer(max_features=10)
        X = vectorizer.fit_transform(texts).toarray()
        
        feature_names = vectorizer.get_feature_names_out()
        description = "æ–‡æœ¬èšç±»: å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºåä½¿ç”¨KMeansè¿›è¡Œèšç±»ï¼Œè¯†åˆ«ä¸»é¢˜ç›¸ä¼¼çš„æ–‡æœ¬"
        return X, feature_names, description   
   
    return None, None, ""

# åˆ†æè‡ªå®šä¹‰æ•°æ®
def analyze_custom_data(X, feature_names):
    if X.shape[0] < 10:
        st.error("æ•°æ®ç‚¹å¤ªå°‘ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬!")
        return
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®è¡¨
    st.subheader("åŸå§‹æ•°æ®é¢„è§ˆï¼ˆæ˜¾ç¤ºå‰10è¡Œæ•°æ®ï¼‰")
    data_df = pd.DataFrame(X, columns=feature_names)
    st.dataframe(data_df.head(10))  # æ˜¾ç¤ºå‰10è¡Œæ•°æ®
    st.write(f"å…± {X.shape[0]} è¡Œæ•°æ®ï¼Œ{X.shape[1]} ä¸ªç‰¹å¾")
    
    # é™ç»´ä»¥ä¾¿å¯è§†åŒ–ï¼ˆå¦‚æœç‰¹å¾æ•°å¤§äº2ï¼‰
    if X.shape[1] > 2:
        from sklearn.decomposition import PCA
        pca = PCA(n_components=2)
        X_vis = pca.fit_transform(X)
        st.info(f"""ä¸ºäº†èƒ½åœ¨å¹³é¢ä¸Šç”»å‡ºèšç±»ç»“æœï¼Œæˆ‘ä»¬ç”¨ PCA æŠŠåŸå§‹çš„é«˜ç»´æ•°æ®å‹ç¼©æˆäº† 2 ç»´ï¼›
                å‹ç¼©åçš„æ•°æ®è™½ç„¶ç»´åº¦å˜å°‘äº†ï¼Œä½†ä¾ç„¶ä¿ç•™äº†åŸå§‹æ•°æ®{sum(pca.explained_variance_ratio_)*100:.1f}
                %çš„æ ¸å¿ƒä¿¡æ¯ï¼Œæ‰€ä»¥ä½ çœ‹åˆ°çš„ 2 ç»´èšç±»å¯è§†åŒ–å›¾ï¼Œ
                èƒ½çœŸå®åæ˜ åŸå§‹æ•°æ®çš„èšç±»è§„å¾‹ï¼ˆæ¯”å¦‚ç°‡çš„åˆ†å¸ƒã€ç°‡ä¸ç°‡çš„è·ç¦»ï¼‰ã€‚""")
    else:
        X_vis = X
     
    # é€‰æ‹©Kå€¼
    st.subheader("é€‰æ‹©èšç±»æ•°é‡K")
    k = st.slider("Kå€¼", 2, min(10, X.shape[0]//5), 3)
    
    # è¿è¡ŒKMeans
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    col1, col2 = st.columns([2,3])
    with col1:
        # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
        st.subheader("èšç±»è¯„ä¼°æŒ‡æ ‡")
        silhouette = silhouette_score(X, labels)
        calinski = calinski_harabasz_score(X, labels)
        davies = davies_bouldin_score(X, labels)
        
        st.write(f"- è½®å»“ç³»æ•°: {silhouette:.4f}")
        st.write(f"- Calinski-HarabaszæŒ‡æ•°: {calinski:.2f}")
        st.write(f"- Davies-BouldinæŒ‡æ•°: {davies:.4f}")
    with col2:
    # æ˜¾ç¤ºèšç±»ç»“æœ
        st.subheader("èšç±»ç»“æœå¯è§†åŒ–")
        fig = plot_cluster_data(X_vis, labels, kmeans.cluster_centers_ if X.shape[1] <= 2 else pca.transform(kmeans.cluster_centers_))
        st.pyplot(fig)
    

    
    # æ˜¾ç¤ºç°‡ä¸­å¿ƒç‰¹å¾ï¼ˆå¦‚æœç‰¹å¾æ•°è¾ƒå°‘ï¼‰
    if X.shape[1] <= 10:
        st.subheader("å„ç°‡ä¸­å¿ƒç‰¹å¾å€¼")
        centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=feature_names)
        centers_df.index = [f'ç°‡ {i}' for i in range(k)]
        st.dataframe(centers_df.style.highlight_max(axis=0))
       
        st.info("""
        **ç°‡ä¸­å¿ƒè§£é‡Š:**
        è¡¨æ ¼æ˜¾ç¤ºäº†æ¯ä¸ªç°‡åœ¨å„ä¸ªç‰¹å¾ä¸Šçš„ä¸­å¿ƒå€¼ï¼Œå¯ç”¨äºè§£é‡Šä¸åŒç°‡çš„ç‰¹å¾ï¼š
        - æ•°å€¼è¾ƒé«˜çš„ç‰¹å¾è¡¨ç¤ºè¯¥ç°‡åœ¨è¯¥ç‰¹å¾ä¸Šæœ‰æ˜æ˜¾å€¾å‘
        - é€šè¿‡æ¯”è¾ƒä¸åŒç°‡çš„ä¸­å¿ƒå€¼ï¼Œå¯ä»¥å‘ç°ç°‡ä¹‹é—´çš„ä¸»è¦å·®å¼‚
        """)

# ä¸»ç¨‹åº
def main():
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    if 'section' not in st.session_state:
        st.session_state.section = "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢"

    # è®°å½•æ¨¡å—è®¿é—®é¡ºåº
    current_section = st.session_state.section
    st.session_state.kmeans_records["module_sequence"].append(current_section)
    if current_section not in st.session_state.kmeans_records["module_timestamps"]:
        st.session_state.kmeans_records["module_timestamps"][current_section] = {
            "enter_time": time.time()
        } 
    
    st.sidebar.title("å¯¼èˆªèœå•")
    section = st.sidebar.radio("é€‰æ‹©å­¦ä¹ æ¨¡å—", [
        "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢",
        "KMeansåŸºæœ¬åŸç†",
        "Kå€¼é€‰æ‹©æ–¹æ³•",
        "KMeansçš„å±€é™æ€§",
        "èšç±»è¯„ä¼°æŒ‡æ ‡",
        "æ¦‚å¿µæµ‹éªŒ",
        "å®é™…åº”ç”¨æ¡ˆä¾‹",
        "ç¼–ç¨‹å®ä¾‹ï¼ˆè‘¡è„é…’æ•°æ®é›†ï¼‰"
    ])
  
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.section = section
    
    context = ""
    if section == "æ•°æ®ç”Ÿæˆä¸æ¢ç´¢":
        context = data_generation_section()
    elif section == "KMeansåŸºæœ¬åŸç†":
        context = kmeans_basics_section()
    elif section == "Kå€¼é€‰æ‹©æ–¹æ³•":
        context = k_selection_section()
    elif section == "KMeansçš„å±€é™æ€§":
        context = kmeans_limitations_section()
    elif section == "èšç±»è¯„ä¼°æŒ‡æ ‡":
        context = evaluation_metrics_section()
    elif section == "æ¦‚å¿µæµ‹éªŒ":
        context = quiz_section()
    elif section == "å®é™…åº”ç”¨æ¡ˆä¾‹":
        context = real_world_example_section()
    elif section == "ç¼–ç¨‹å®ä¾‹ï¼ˆè‘¡è„é…’æ•°æ®é›†ï¼‰":
        # åˆå§‹åŒ–stepå˜é‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'step' not in st.session_state:
            st.session_state.step = 0
        KMeans_step_by_step.main()
        context = "ç¼–ç¨‹å®ä¾‹æ¨¡å—: ç¼–ç¨‹å®ä¾‹ï¼ˆè‘¡è„é…’æ•°æ®é›†ï¼‰åˆ†æ­¥ç¼–ç¨‹è®­ç»ƒ"
    
    display_chat_interface(context)

    # è®°å½•æ¨¡å—é€€å‡ºæ—¶é—´
    if current_section in st.session_state.kmeans_records["module_timestamps"]:
        st.session_state.kmeans_records["module_timestamps"][current_section]["exit_time"] = datetime.now().timestamp()
    
    if section != "ç¼–ç¨‹å®ä¾‹ï¼ˆè‘¡è„é…’æ•°æ®é›†ï¼‰":
        # ä¾§è¾¹æ æ·»åŠ å­¦ä¹ æŠ¥å‘ŠæŒ‰é’®ï¼ˆè°ƒç”¨ç‹¬ç«‹æ¨¡å—ï¼‰
        st.sidebar.markdown("---")
        if st.sidebar.button("KMeansæ¨¡å—å­¦ä¹ æŠ¥å‘Š"):
            report = generate_evaluation(
                module_type="kmeans",
                raw_records=st.session_state.kmeans_records
            )
            st.write("### KMeanså­¦ä¹ æƒ…å†µæŠ¥å‘Š")
            st.info(report)
    
    # ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **KMeansèšç±»äº¤äº’å¼å­¦ä¹ å¹³å°**
    
    è®¾è®¡ç”¨äºæœºå™¨å­¦ä¹ æ•™å­¦ï¼Œå¸®åŠ©å­¦ç”Ÿç†è§£:
    - KMeansèšç±»çš„åŸºæœ¬åŸç†ä¸æ­¥éª¤
    - KMeansèšç±»çš„åŸºæœ¬åŸç†ä¸æ­¥éª¤
    - Kå€¼é€‰æ‹©çš„æ–¹æ³•ä¸æŠ€å·§
    - èšç±»ç»“æœçš„è¯„ä¼°æŒ‡æ ‡
    - KMeansç®—æ³•çš„ä¼˜ç¼ºç‚¹ä¸é€‚ç”¨åœºæ™¯
    """)


if __name__ == "__main__":
    main()
